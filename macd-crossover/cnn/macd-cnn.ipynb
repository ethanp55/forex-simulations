{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"-3XsA6wafwLf"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","import seaborn as sns\n","import math\n","from pyts.image import RecurrencePlot, GramianAngularField\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.models import load_model, Sequential\n","import json\n","import time\n","from collections import deque\n","import warnings\n","from pickle import dump, load\n","\n","file_path = '/Users/mymac/Google Drive/My Drive/Forex_Robot/'"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def apply_impact(val, impact):\n","    return float(val) * float(impact)\n","\n","def clean_value(val):\n","    return float(val)\n","    # if isinstance(val, float) or isinstance(val, int):\n","    #     return float(val)\n","    \n","    # new_val = val.replace(',', '')\n","\n","    # if 'M' in new_val:\n","    #     num, _ = new_val.split('M')\n","\n","    #     return float(num) * 1000000\n","\n","    # elif 'B' in new_val:\n","    #     num, _ = new_val.split('B')\n","\n","    #     return float(num) * 1000000000\n","\n","    # elif 'k' in new_val:\n","    #     num, _ = new_val.split('k')\n","\n","    #     return float(num) * 1000\n","\n","    # elif '%' in new_val:\n","    #     num, _ = new_val.split('%')\n","\n","    #     return float(num) / 100\n","\n","    # else:\n","    #     return float(new_val)\n","\n","def forecast_ratio(forecast, actual):\n","    if str(forecast) == 'nan' or str(actual) == 'nan':\n","        return 0.0\n","\n","    forecast_clean = clean_value(forecast)\n","    actual_clean = clean_value(actual)\n","    \n","    if actual_clean == 0:\n","        return 0\n","\n","    return forecast_clean / actual_clean\n","\n","def previous_ratio(previous, actual):\n","    if str(previous) == 'nan' or str(actual) == 'nan':\n","        return 0.0\n","\n","    previous_clean = clean_value(previous)\n","    actual_clean = clean_value(actual)\n","    \n","    if actual_clean == 0:\n","        return 0\n","\n","    return previous_clean / actual_clean\n","\n","\n","# news = pd.read_csv(file_path + 'events.csv')\n","# news.Date = pd.to_datetime(news.Date, utc=True)\n","# news = news.loc[(news['Currency_Code'] == 'AUD') | (news['Currency_Code'] == 'USD')]\n","# news.drop(news[(news['Impact'] != 'low') & (news['Impact'] != 'med') & (news['Impact'] != 'high')].index, inplace=True)\n","# news.loc[news['Impact'] == 'low', 'Impact'] = 1\n","# news.loc[news['Impact'] == 'med', 'Impact'] = 2\n","# news.loc[news['Impact'] == 'high', 'Impact'] = 3\n","# news['Forecast_Ratio'] = news.apply(lambda row: forecast_ratio(row['Forecast'], row['Actual']), axis=1)\n","# news['Previous_Ratio'] = news.apply(lambda row: previous_ratio(row['Previous'], row['Actual']), axis=1)\n","# news.drop(['Currency_Code', 'Actual', 'Forecast', 'Previous'], axis=1, inplace=True)\n","# by_date = news.groupby('Date')\n","# impact, all_day, forecast_r, previous_r = by_date['Impact'].mean().reset_index(), by_date['All_Day'].mean().reset_index(), by_date['Forecast_Ratio'].mean().reset_index(), by_date['Previous_Ratio'].mean().reset_index()\n","# news = news.iloc[0:0]\n","# news['Date'], news['Impact'], news['All_Day'], news['Forecast_Ratio'], news['Previous_Ratio'] = impact['Date'], impact['Impact'], all_day['All_Day'], forecast_r['Forecast_Ratio'], previous_r['Previous_Ratio']\n","# news.tail()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/mymac/miniforge3/envs/forex/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  return super().drop(\n","<ipython-input-3-bb255503ac2d>:35: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  news_base['Date'], news_base['Impact'], news_base['Actual_Class'], news_base['Previous_Class'] = impact1['Date'], impact1['Impact'], actual1['Actual_Class'], previous1['Previous_Class']\n","<ipython-input-3-bb255503ac2d>:39: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  news_counter['Date'], news_counter['Impact'], news_counter['Actual_Class'], news_counter['Previous_Class'] = impact2['Date'], impact2['Impact'], actual2['Actual_Class'], previous2['Previous_Class']\n"]}],"source":["# currencies = ['Usd_Chf', 'Gbp_Usd', 'Usd_Cad', 'Aud_Usd', 'Eur_Usd', 'Usd_Jpy', 'Nzd_Usd']\n","# GBP_JPY, CAD_JPY, EUR_JPY, GBP_CAD, EUR_GBP\n","# 'Gbp_Usd', 'Eur_Usd', 'Usd_Cad', 'Usd_Jpy', 'Aud_Usd'\n","currencies = ['Eur_Gbp']\n","years = '2012-2022'\n","\n","dfs, df_longs = [], []\n","\n","# news = pd.read_csv(file_path + 'events_2016-2022.csv')\n","# news = news.rename(columns={'Start': 'Date'})\n","# news.Date = pd.to_datetime(news.Date)\n","\n","for currency_pair in currencies:\n","    currency1, currency2 = currency_pair.split('_')\n","    currency1, currency2 = currency1.upper(), currency2.upper()\n","\n","    news = pd.read_csv(file_path + 'events.csv')\n","    news.Date = pd.to_datetime(news.Date, utc=True)\n","    news.drop(news[(news['Impact'] != 'low') & (news['Impact'] != 'med') & (news['Impact'] != 'high')].index, inplace=True)\n","    news.loc[news['Impact'] == 'low', 'Impact'] = 1\n","    news.loc[news['Impact'] == 'med', 'Impact'] = 2\n","    news.loc[news['Impact'] == 'high', 'Impact'] = 3\n","    # news['Forecast_Ratio'] = news.apply(lambda row: forecast_ratio(row['Forecast_Val'], row['Actual_Val']), axis=1)\n","    # news['Previous_Ratio'] = news.apply(lambda row: previous_ratio(row['Previous_Val'], row['Actual_Val']), axis=1)\n","    news['Impact'] = pd.to_numeric(news['Impact'])\n","    news['Actual_Class'] = news.apply(lambda row: clean_value(row['Actual']), axis=1)\n","    news['Previous_Class'] = news.apply(lambda row: clean_value(row['Previous']), axis=1)\n","    news_base = news.loc[news['Currency_Code'] == currency1]\n","    news_counter = news.loc[news['Currency_Code'] == currency2]\n","    news_base.drop(['Currency_Code', 'Actual', 'Previous', 'Actual_Val', 'Forecast_Val', 'Previous_Val'], axis=1, inplace=True)\n","    news_counter.drop(['Currency_Code', 'Actual', 'Previous', 'Actual_Val', 'Forecast_Val', 'Previous_Val'], axis=1, inplace=True)\n","    by_date1 = news_base.groupby('Date')\n","    impact1, actual1, previous1 = by_date1['Impact'].mean().reset_index(), by_date1['Actual_Class'].mean().reset_index(), by_date1['Previous_Class'].mean().reset_index()\n","    news_base = news_base.iloc[0:0]\n","    news_base['Date'], news_base['Impact'], news_base['Actual_Class'], news_base['Previous_Class'] = impact1['Date'], impact1['Impact'], actual1['Actual_Class'], previous1['Previous_Class']\n","    by_date2 = news_counter.groupby('Date')\n","    impact2, actual2, previous2 = by_date2['Impact'].mean().reset_index(), by_date2['Actual_Class'].mean().reset_index(), by_date2['Previous_Class'].mean().reset_index()\n","    news_counter = news_counter.iloc[0:0]\n","    news_counter['Date'], news_counter['Impact'], news_counter['Actual_Class'], news_counter['Previous_Class'] = impact2['Date'], impact2['Impact'], actual2['Actual_Class'], previous2['Previous_Class']\n","\n","    df = pd.read_csv(file_path + f'Oanda_{currency_pair}_M5_{years}.csv')\n","    df.Date = pd.to_datetime(df.Date, utc=True)\n","    df.reset_index(drop=True, inplace=True)\n","    df = pd.merge(df, news_base, how='left', on='Date')\n","    df = pd.merge(df, news_counter, how='left', on='Date')\n","    df.reset_index(drop=True, inplace=True)\n","    df = df.fillna(method='ffill')\n","    df.dropna(inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","    dfs.append(df)\n","\n","    df_long = pd.read_csv(file_path + f'Oanda_{currency_pair}_M30_{years}.csv')\n","    df_long.Date = pd.to_datetime(df_long.Date, utc=True)\n","    df_long.dropna(inplace=True)\n","    df_long.reset_index(drop=True, inplace=True)\n","    df_longs.append(df_long)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["Date              datetime64[ns, UTC]\n","Currency_Code                  object\n","Impact                          int64\n","Actual                          int64\n","Previous                        int64\n","Actual_Val                     object\n","Forecast_Val                   object\n","Previous_Val                   object\n","Actual_Class                  float64\n","Previous_Class                float64\n","dtype: object"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["news.dtypes"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def add_fractal(df, i, look_back=3):\n","    if i >= look_back and i < df.shape[0] - look_back:\n","        lows = []\n","        highs = []\n","\n","        for j in range(1, look_back + 1):\n","            prev_mid_low, prev_mid_high = df.loc[df.index[i - j], ['Mid_Low', 'Mid_High']]\n","            future_mid_low, future_mid_high = df.loc[df.index[i + j], ['Mid_Low', 'Mid_High']]\n","\n","            lows.append(float(prev_mid_low))\n","            lows.append(float(future_mid_low))\n","            highs.append(float(prev_mid_high))\n","            highs.append(float(future_mid_high))\n","\n","        mid_low, mid_high = df.loc[df.index[i], ['Mid_Low', 'Mid_High']]\n","\n","        if float(mid_low) < min(lows):\n","            return float(mid_low), 1.0\n","\n","        elif float(mid_high) > max(highs):\n","            return float(mid_high), 0.0\n","\n","        else:\n","            return np.nan, np.nan\n","\n","    else:\n","        return np.nan, np.nan\n","\n","def psar(barsdata, iaf=0.02, maxaf=0.2):\n","    length = len(barsdata)\n","    high = list(barsdata['Mid_High'])\n","    low = list(barsdata['Mid_Low'])\n","    close = list(barsdata['Mid_Close'])\n","    psar = close[0:len(close)]\n","    bull = True\n","    af = iaf\n","    hp = high[0]\n","    lp = low[0]\n","    for i in range(2, length):\n","        if bull:\n","            psar[i] = psar[i - 1] + af * (hp - psar[i - 1])\n","        else:\n","            psar[i] = psar[i - 1] + af * (lp - psar[i - 1])\n","        reverse = False\n","        if bull:\n","            if low[i] < psar[i]:\n","                bull = False\n","                reverse = True\n","                psar[i] = hp\n","                lp = low[i]\n","                af = iaf\n","        else:\n","            if high[i] > psar[i]:\n","                bull = True\n","                reverse = True\n","                psar[i] = lp\n","                hp = high[i]\n","                af = iaf\n","        if not reverse:\n","            if bull:\n","                if high[i] > hp:\n","                    hp = high[i]\n","                    af = min(af + iaf, maxaf)\n","                if low[i - 1] < psar[i]:\n","                    psar[i] = low[i - 1]\n","                if low[i - 2] < psar[i]:\n","                    psar[i] = low[i - 2]\n","            else:\n","                if low[i] < lp:\n","                    lp = low[i]\n","                    af = min(af + iaf, maxaf)\n","                if high[i - 1] > psar[i]:\n","                    psar[i] = high[i - 1]\n","                if high[i - 2] > psar[i]:\n","                    psar[i] = high[i - 2]\n","    return psar\n","\n","\n","def atr(high, low, close, lookback=14):\n","    high_low = high - low\n","    high_close = np.abs(high - close.shift())\n","    low_close = np.abs(low - close.shift())\n","    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n","    true_range = np.max(ranges, axis=1)\n","\n","    return true_range.rolling(lookback).sum() / lookback\n","\n","\n","def rsi(closes, periods=14):\n","    close_delta = closes.diff()\n","\n","    up = close_delta.clip(lower=0)\n","    down = -1 * close_delta.clip(upper=0)\n","    ma_up = up.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n","    ma_down = down.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n","        \n","    rsi = ma_up / ma_down\n","    rsi = 100 - (100/(1 + rsi))\n","\n","    return rsi\n","\n","  \n","def adx(high, low, close, lookback=14):\n","    plus_dm = high.diff()\n","    minus_dm = low.diff()\n","    plus_dm[plus_dm < 0] = 0\n","    minus_dm[minus_dm > 0] = 0\n","    \n","    tr1 = pd.DataFrame(high - low)\n","    tr2 = pd.DataFrame(abs(high - close.shift(1)))\n","    tr3 = pd.DataFrame(abs(low - close.shift(1)))\n","    frames = [tr1, tr2, tr3]\n","    tr = pd.concat(frames, axis = 1, join = 'inner').max(axis = 1)\n","    atr = tr.rolling(lookback).mean()\n","    \n","    plus_di = 100 * (plus_dm.ewm(alpha = 1/lookback).mean() / atr)\n","    minus_di = abs(100 * (minus_dm.ewm(alpha = 1/lookback).mean() / atr))\n","    dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n","    adx = ((dx.shift(1) * (lookback - 1)) + dx) / lookback\n","    adx_smooth = adx.ewm(alpha = 1/lookback).mean()\n","\n","    return adx_smooth\n","\n","\n","def stoch(high, low, close, lookback=14):\n","    high_lookback = high.rolling(lookback).max()\n","    low_lookback = low.rolling(lookback).min()\n","    slow_k = (close - low_lookback) * 100 / (high_lookback - low_lookback)\n","    slow_d = slow_k.rolling(3).mean()\n","\n","    return slow_k, slow_d\n","\n","def stoch_rsi(data, k_window=3, d_window=3, window=14):\n","    min_val = data.rolling(window=window, center=False).min()\n","    max_val = data.rolling(window=window, center=False).max()\n","\n","    stoch = ((data - min_val) / (max_val - min_val)) * 100\n","\n","    slow_k = stoch.rolling(window=k_window, center=False).mean()\n","\n","    slow_d = slow_k.rolling(window=d_window, center=False).mean()\n","\n","    return slow_k, slow_d\n","\n","def n_macd(macd, macdsignal, lookback=50):\n","    n_macd = 2 * (((macd - macd.rolling(lookback).min()) / (macd.rolling(lookback).max() - macd.rolling(lookback).min()))) - 1\n","    n_macdsignal = 2 * (((macdsignal - macdsignal.rolling(lookback).min()) / (macdsignal.rolling(lookback).max() - macdsignal.rolling(lookback).min()))) - 1\n","\n","    return n_macd, n_macdsignal\n","\n","def chop(df, lookback=14):\n","    atr1 = atr(df, lookback=1)\n","    high, low = df['Mid_High'], df['Mid_Low']\n","\n","    chop = np.log10(atr1.rolling(lookback).sum() / (high.rolling(lookback).max() - low.rolling(lookback).min())) / np.log10(lookback)\n","\n","    return chop\n","\n","def vo(volume, short_lookback=5, long_lookback=10):\n","    short_ema =  pd.Series.ewm(volume, span=short_lookback).mean()\n","    long_ema = pd.Series.ewm(volume, span=long_lookback).mean()\n","\n","    volume_oscillator = (short_ema - long_ema) / long_ema\n","\n","    return volume_oscillator\n","\n","def bar_lengths(bar_lens, window=36):\n","    return bar_lens.rolling(window=window).mean(), bar_lens.rolling(window=window).std()\n","\n","def sar_lengths(opens, sars, window=36):\n","    diffs = abs(opens - sars.shift(1))\n","\n","    return diffs.rolling(window=window).mean(), diffs.rolling(window=window).std()\n","\n","def supertrend(barsdata, atr_len=3, mult=3):\n","    curr_atr = atr(barsdata['Mid_High'], barsdata['Mid_Low'], barsdata['Mid_Close'], lookback=atr_len)\n","    highs, lows = barsdata['Mid_High'], barsdata['Mid_Low']\n","    hl2 = (highs + lows) / 2\n","    final_upperband = upper_band = hl2 + mult * curr_atr\n","    final_lowerband = lower_band = hl2 - mult * curr_atr\n","\n","    # initialize Supertrend column to True\n","    supertrend = [True] * len(df)\n","\n","    close = barsdata['Mid_Close']\n","    \n","    for i in range(1, len(df.index)):\n","        curr, prev = i, i - 1\n","        \n","        # if current close price crosses above upperband\n","        if close[curr] > final_upperband[prev]:\n","            supertrend[curr] = True\n","\n","        # if current close price crosses below lowerband\n","        elif close[curr] < final_lowerband[prev]:\n","            supertrend[curr] = False\n","\n","        # else, the trend continues\n","        else:\n","            supertrend[curr] = supertrend[prev]\n","            \n","            # adjustment to the final bands\n","            if supertrend[curr] == True and final_lowerband[curr] < final_lowerband[prev]:\n","                final_lowerband[curr] = final_lowerband[prev]\n","\n","            if supertrend[curr] == False and final_upperband[curr] > final_upperband[prev]:\n","                final_upperband[curr] = final_upperband[prev]\n","\n","    return supertrend, final_upperband, final_lowerband\n","\n","def heikin_ashi(opens, highs, lows, closes):\n","    ha_close = list((opens + highs + lows + closes) / 4)\n","    ha_opens = []\n","\n","    opens_list, closes_list = list(opens), list(closes)\n","\n","    for i in range(len(ha_close)):\n","        if i == 0:\n","            ha_opens.append((opens_list[i] + closes_list[i]) / 2)\n","\n","        else:\n","            ha_opens.append((ha_opens[i - 1] + ha_close[i - 1]) / 2)\n","\n","    ha_highs = list(pd.DataFrame({'ha_open': ha_opens, 'ha_close': ha_close, 'high': list(highs)}).max(axis=1))\n","    ha_lows = list(pd.DataFrame({'ha_open': ha_opens, 'ha_close': ha_close, 'low': list(lows)}).min(axis=1))\n","\n","    return ha_opens, ha_highs, ha_lows, ha_close\n","\n","def trend_indicator(opens, highs, lows, closes, ema_period=50, smoothing_period=10):\n","    ha_open, ha_high, ha_low, ha_close = heikin_ashi(opens, highs, lows, closes)\n","\n","    ha_o_ema = pd.Series.ewm(pd.DataFrame({'ha_open': ha_open}), span=ema_period).mean()\n","    ha_h_ema = pd.Series.ewm(pd.DataFrame({'ha_high': ha_high}), span=ema_period).mean()\n","    ha_l_ema = pd.Series.ewm(pd.DataFrame({'ha_low': ha_low}), span=ema_period).mean()\n","    ha_c_ema = pd.Series.ewm(pd.DataFrame({'ha_close': ha_close}), span=ema_period).mean()\n","\n","    return pd.Series.ewm(ha_o_ema, span=smoothing_period).mean(), pd.Series.ewm(ha_h_ema, span=smoothing_period).mean(), pd.Series.ewm(ha_l_ema, span=smoothing_period).mean(), pd.Series.ewm(ha_c_ema, span=smoothing_period).mean()\n","\n","def qqe_mod(barsdata, rsi_period=6, smoothing=5, qqe_factor=5, qqe2_factor=1.61, threshold=3, mult=0.35, sma_length=50):\n","    wilders_period = rsi_period * 2 - 1\n","\n","    curr_rsi = rsi(barsdata, periods=rsi_period)\n","    rsi_ema = pd.Series.ewm(curr_rsi, span=smoothing).mean()\n","    atr_rsi = abs(rsi_ema.shift(1) - rsi_ema)\n","    atr_rsi_ema = pd.Series.ewm(atr_rsi, span=wilders_period).mean()\n","    dar = pd.Series.ewm(atr_rsi_ema, span=wilders_period).mean() * qqe_factor\n","\n","    newshortband = rsi_ema + dar\n","    newlongband = rsi_ema - dar\n","\n","    rsi_ema_list = list(rsi_ema)\n","\n","    longband = [0]\n","    for i in range(1, len(rsi_ema_list)):\n","        if rsi_ema_list[i - 1] > longband[i - 1] and rsi_ema_list[i] > longband[i - 1]:\n","            longband.append(max(longband[i - 1],newlongband[i]))\n","\n","        else:\n","            longband.append(newlongband[i])\n","\n","    shortband = [0]\n","    for i in range(1,len(rsi_ema_list)):\n","        if rsi_ema_list[i - 1] < shortband[i - 1] and rsi_ema_list[i] < shortband[i - 1]:\n","            shortband.append(min(shortband[i - 1],newshortband[i]))\n","            \n","        else:\n","            shortband.append(newshortband[i])\n","\n","    longband = pd.Series(longband)\n","    shortband = pd.Series(shortband)\n","\n","    trend = np.where(rsi_ema > longband.shift(1), 1, -1)    \n","    fastatrrsitl = pd.Series(np.where(trend == 1, longband, shortband))\n","\n","    basis = (fastatrrsitl - 50).rolling(window=sma_length).mean()\n","    dev = (fastatrrsitl - 50).rolling(window=sma_length).std() * mult\n","    upper = basis + dev\n","    lower = basis - dev\n","\n","    greenbar1 = rsi_ema - 50 > threshold\n","    greenbar2 = rsi_ema - 50 > upper\n","    redbar1 = rsi_ema - 50 < threshold\n","    redbar2 = rsi_ema - 50 < lower\n","\n","    # uptrend = np.where((greenbar1 & greenbar2), True, False)\n","    # downtrend = np.where((redbar1 & redbar2), True, False)\n","\n","    uptrend = np.where((greenbar2), True, False)\n","    downtrend = np.where((redbar2), True, False)\n","\n","    return uptrend, downtrend\n","\n","def williams_r(highs, lows, closes, length=21, ema_length=15):\n","    highest_highs = highs.rolling(window=length).max()\n","    lowest_lows = lows.rolling(window=length).min()\n","\n","    willy = 100 * (closes - highest_highs) / (highest_highs - lowest_lows)\n","    willy_ema = pd.Series.ewm(willy, span=ema_length).mean()\n","\n","    return willy, willy_ema\n","\n","def squeeze(barsdata, length=20, length_kc=20, mult=1.5):\n","    # Bollinger bands\n","    m_avg = barsdata['Mid_Close'].rolling(window=length).mean()\n","    m_std = barsdata['Mid_Close'].rolling(window=length).std(ddof=0)\n","    upper_bb = m_avg + mult * m_std\n","    lower_bb = m_avg - mult * m_std\n","\n","    # Keltner channel\n","    tr0 = abs(barsdata['Mid_High'] - barsdata['Mid_Low'])\n","    tr1 = abs(barsdata['Mid_High'] - barsdata['Mid_Close'].shift())\n","    tr2 = abs(barsdata['Mid_Low'] - barsdata['Mid_Close'].shift())\n","    tr = pd.concat([tr0, tr1, tr2], axis=1).max(axis=1)\n","    range_ma = tr.rolling(window=length_kc).mean()\n","    upper_kc = m_avg + range_ma * mult\n","    lower_kc = m_avg - range_ma * mult\n","\n","    # Squeeze\n","    squeeze_on = (lower_bb > lower_kc) & (upper_bb < upper_kc)\n","\n","    return squeeze_on"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1639361446900,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":420},"id":"5Ttafp9WxjAe","outputId":"92fd8ae2-3721-4852-eb4d-6fa6c6226a50"},"outputs":[],"source":["bid_ask_mid_prices_list = []\n","\n","for df in dfs:\n","    # Add technical indicators (for additional features)\n","    df['ema200'] = pd.Series.ewm(df['Mid_Close'], span=200).mean()\n","    df['ema100'] = pd.Series.ewm(df['Mid_Close'], span=100).mean()\n","\n","    df['rsi'] = rsi(df['Mid_Close'])\n","    df['rsi_sma'] = df['rsi'].rolling(50).mean()\n","    df['adx'] = adx(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","    df['macd'] = pd.Series.ewm(df['Mid_Close'], span=12).mean() - pd.Series.ewm(df['Mid_Close'], span=26).mean()\n","    df['macdsignal'] = pd.Series.ewm(df['macd'], span=9).mean()\n","    df['slowk_rsi'], df['slowd_rsi'] = stoch_rsi(df['rsi'])\n","\n","    df['squeeze_on'] = squeeze(df)\n","\n","    # tups = [add_fractal(df, i) for i in range(df.shape[0])]\n","    # key_levels, is_supports = [tup[0] for tup in tups], [tup[1] for tup in tups]\n","    # df['key_level'], df['is_support'] = key_levels, is_supports\n","    # df = df.fillna(method='ffill')\n","\n","    df.dropna(inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","    # Extract the bid and ask prices and fractals and remove them from the df\n","    bid_ask_mid_prices = df[['Date','Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close']]\n","    df.drop(['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume'], axis=1, inplace=True)\n","    bid_ask_mid_prices_list.append(bid_ask_mid_prices)\n","\n","    df.dropna(inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","for df_long in df_longs:\n","    df_long['ema200'] = pd.Series.ewm(df_long['Mid_Close'], span=200).mean()\n","    df_long['ema100'] = pd.Series.ewm(df_long['Mid_Close'], span=100).mean()\n","\n","    df_long['rsi'] = rsi(df_long['Mid_Close'])\n","    df_long['rsi_sma'] = df_long['rsi'].rolling(50).mean()\n","    df_long['adx'] = adx(df_long['Mid_High'], df_long['Mid_Low'], df_long['Mid_Close'])\n","    df_long['macd'] = pd.Series.ewm(df_long['Mid_Close'], span=12).mean() - pd.Series.ewm(df_long['Mid_Close'], span=26).mean()\n","    df_long['macdsignal'] = pd.Series.ewm(df_long['macd'], span=9).mean()\n","    df_long['slowk_rsi'], df_long['slowd_rsi'] = stoch_rsi(df_long['rsi'])\n","\n","    df_long['squeeze_on'] = squeeze(df_long)\n","\n","    # tups = [add_fractal(df_long, i) for i in range(df_long.shape[0])]\n","    # key_levels, is_supports = [tup[0] for tup in tups], [tup[1] for tup in tups]\n","    # df_long['key_level'], df_long['is_support'] = key_levels, is_supports\n","    # df_long = df_long.fillna(method='ffill')\n","\n","    df_long.dropna(inplace=True)\n","    df_long.reset_index(drop=True, inplace=True)\n","\n","    df_long.drop(['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume'], axis=1, inplace=True)\n","\n","    df_long.dropna(inplace=True)\n","    df_long.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# for i in range(len(dfs)):\n","#     df, df_long = dfs[i], df_longs[i]\n","\n","#     df = pd.merge(df, df_long, how='left', on='Date')\n","#     df.reset_index(drop=True, inplace=True)\n","#     df = df.fillna(method='ffill')\n","#     df.dropna(inplace=True)\n","#     df.reset_index(drop=True, inplace=True)\n","\n","#     dfs[i] = df"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# for df in dfs:\n","#     df.drop(['Bid_Open_x', 'Bid_High_x', 'Bid_Low_x', 'Bid_Close_x', 'Ask_Open_x', 'Ask_High_x', 'Ask_Low_x', 'Ask_Close_x', 'Mid_Open_x', 'Mid_High_x', 'Mid_Low_x', 'Mid_Close_x', 'Volume_x'], axis=1, inplace=True)\n","#     df.drop(['Bid_Open_y', 'Bid_High_y', 'Bid_Low_y', 'Bid_Close_y', 'Ask_Open_y', 'Ask_High_y', 'Ask_Low_y', 'Ask_Close_y', 'Mid_Open_y', 'Mid_High_y', 'Mid_Low_y', 'Mid_Close_y', 'Volume_y'], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Impact_x</th>\n","      <th>Actual_Class_x</th>\n","      <th>Previous_Class_x</th>\n","      <th>Impact_y</th>\n","      <th>Actual_Class_y</th>\n","      <th>Previous_Class_y</th>\n","      <th>ema200</th>\n","      <th>ema100</th>\n","      <th>rsi</th>\n","      <th>rsi_sma</th>\n","      <th>adx</th>\n","      <th>macd</th>\n","      <th>macdsignal</th>\n","      <th>slowk_rsi</th>\n","      <th>slowd_rsi</th>\n","      <th>squeeze_on</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-01-02 14:45:00+00:00</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>0.889768</td>\n","      <td>0.889678</td>\n","      <td>35.716144</td>\n","      <td>45.895288</td>\n","      <td>28.594567</td>\n","      <td>-0.000250</td>\n","      <td>-0.000213</td>\n","      <td>34.896807</td>\n","      <td>36.578801</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2018-01-02 14:50:00+00:00</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>0.889742</td>\n","      <td>0.889646</td>\n","      <td>32.561289</td>\n","      <td>44.913707</td>\n","      <td>29.045242</td>\n","      <td>-0.000274</td>\n","      <td>-0.000225</td>\n","      <td>28.664493</td>\n","      <td>36.331599</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2018-01-02 14:55:00+00:00</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>0.889719</td>\n","      <td>0.889619</td>\n","      <td>36.202569</td>\n","      <td>44.143251</td>\n","      <td>29.909318</td>\n","      <td>-0.000279</td>\n","      <td>-0.000236</td>\n","      <td>26.836193</td>\n","      <td>30.132497</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2018-01-02 15:00:00+00:00</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>0.889693</td>\n","      <td>0.889587</td>\n","      <td>33.298263</td>\n","      <td>43.735749</td>\n","      <td>30.813446</td>\n","      <td>-0.000294</td>\n","      <td>-0.000248</td>\n","      <td>23.946201</td>\n","      <td>26.482296</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2018-01-02 15:05:00+00:00</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>0.889679</td>\n","      <td>0.889571</td>\n","      <td>47.428604</td>\n","      <td>43.694649</td>\n","      <td>31.669741</td>\n","      <td>-0.000259</td>\n","      <td>-0.000250</td>\n","      <td>53.811004</td>\n","      <td>34.864466</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       Date  Impact_x  Actual_Class_x  Previous_Class_x  \\\n","0 2018-01-02 14:45:00+00:00       2.0             0.0               0.0   \n","1 2018-01-02 14:50:00+00:00       2.0             0.0               0.0   \n","2 2018-01-02 14:55:00+00:00       2.0             0.0               0.0   \n","3 2018-01-02 15:00:00+00:00       2.0             0.0               0.0   \n","4 2018-01-02 15:05:00+00:00       2.0             0.0               0.0   \n","\n","   Impact_y  Actual_Class_y  Previous_Class_y    ema200    ema100        rsi  \\\n","0       2.0            -1.0               0.0  0.889768  0.889678  35.716144   \n","1       2.0            -1.0               0.0  0.889742  0.889646  32.561289   \n","2       2.0            -1.0               0.0  0.889719  0.889619  36.202569   \n","3       2.0            -1.0               0.0  0.889693  0.889587  33.298263   \n","4       2.0            -1.0               0.0  0.889679  0.889571  47.428604   \n","\n","     rsi_sma        adx      macd  macdsignal  slowk_rsi  slowd_rsi  \\\n","0  45.895288  28.594567 -0.000250   -0.000213  34.896807  36.578801   \n","1  44.913707  29.045242 -0.000274   -0.000225  28.664493  36.331599   \n","2  44.143251  29.909318 -0.000279   -0.000236  26.836193  30.132497   \n","3  43.735749  30.813446 -0.000294   -0.000248  23.946201  26.482296   \n","4  43.694649  31.669741 -0.000259   -0.000250  53.811004  34.864466   \n","\n","   squeeze_on  \n","0       False  \n","1       False  \n","2       False  \n","3       False  \n","4       False  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dfs[0].head()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Impact_x</th>\n","      <th>Actual_Class_x</th>\n","      <th>Previous_Class_x</th>\n","      <th>Impact_y</th>\n","      <th>Actual_Class_y</th>\n","      <th>Previous_Class_y</th>\n","      <th>ema200</th>\n","      <th>ema100</th>\n","      <th>rsi</th>\n","      <th>rsi_sma</th>\n","      <th>adx</th>\n","      <th>macd</th>\n","      <th>macdsignal</th>\n","      <th>slowk_rsi</th>\n","      <th>slowd_rsi</th>\n","      <th>squeeze_on</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>334806</th>\n","      <td>2022-07-01 05:35:00+00:00</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.714286</td>\n","      <td>-0.571429</td>\n","      <td>0.0</td>\n","      <td>0.861306</td>\n","      <td>0.861805</td>\n","      <td>54.009643</td>\n","      <td>62.145930</td>\n","      <td>38.274407</td>\n","      <td>0.000091</td>\n","      <td>0.000135</td>\n","      <td>13.434464</td>\n","      <td>6.763344</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>334807</th>\n","      <td>2022-07-01 05:40:00+00:00</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.714286</td>\n","      <td>-0.571429</td>\n","      <td>0.0</td>\n","      <td>0.861319</td>\n","      <td>0.861821</td>\n","      <td>55.658333</td>\n","      <td>62.226793</td>\n","      <td>35.635032</td>\n","      <td>0.000089</td>\n","      <td>0.000126</td>\n","      <td>28.878254</td>\n","      <td>14.865969</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>334808</th>\n","      <td>2022-07-01 05:45:00+00:00</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.714286</td>\n","      <td>-0.571429</td>\n","      <td>0.0</td>\n","      <td>0.861332</td>\n","      <td>0.861838</td>\n","      <td>59.129603</td>\n","      <td>62.270160</td>\n","      <td>33.703193</td>\n","      <td>0.000095</td>\n","      <td>0.000120</td>\n","      <td>48.552627</td>\n","      <td>30.288448</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>334809</th>\n","      <td>2022-07-01 05:50:00+00:00</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.714286</td>\n","      <td>-0.571429</td>\n","      <td>0.0</td>\n","      <td>0.861346</td>\n","      <td>0.861854</td>\n","      <td>57.370792</td>\n","      <td>62.250049</td>\n","      <td>32.485482</td>\n","      <td>0.000096</td>\n","      <td>0.000115</td>\n","      <td>52.649000</td>\n","      <td>43.359961</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>334810</th>\n","      <td>2022-07-01 05:55:00+00:00</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.714286</td>\n","      <td>-0.571429</td>\n","      <td>0.0</td>\n","      <td>0.861357</td>\n","      <td>0.861867</td>\n","      <td>51.218245</td>\n","      <td>62.210486</td>\n","      <td>31.376347</td>\n","      <td>0.000083</td>\n","      <td>0.000109</td>\n","      <td>47.237679</td>\n","      <td>49.479769</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            Date  Impact_x  Actual_Class_x  Previous_Class_x  \\\n","334806 2022-07-01 05:35:00+00:00       3.0             0.0               0.0   \n","334807 2022-07-01 05:40:00+00:00       3.0             0.0               0.0   \n","334808 2022-07-01 05:45:00+00:00       3.0             0.0               0.0   \n","334809 2022-07-01 05:50:00+00:00       3.0             0.0               0.0   \n","334810 2022-07-01 05:55:00+00:00       3.0             0.0               0.0   \n","\n","        Impact_y  Actual_Class_y  Previous_Class_y    ema200    ema100  \\\n","334806  1.714286       -0.571429               0.0  0.861306  0.861805   \n","334807  1.714286       -0.571429               0.0  0.861319  0.861821   \n","334808  1.714286       -0.571429               0.0  0.861332  0.861838   \n","334809  1.714286       -0.571429               0.0  0.861346  0.861854   \n","334810  1.714286       -0.571429               0.0  0.861357  0.861867   \n","\n","              rsi    rsi_sma        adx      macd  macdsignal  slowk_rsi  \\\n","334806  54.009643  62.145930  38.274407  0.000091    0.000135  13.434464   \n","334807  55.658333  62.226793  35.635032  0.000089    0.000126  28.878254   \n","334808  59.129603  62.270160  33.703193  0.000095    0.000120  48.552627   \n","334809  57.370792  62.250049  32.485482  0.000096    0.000115  52.649000   \n","334810  51.218245  62.210486  31.376347  0.000083    0.000109  47.237679   \n","\n","        slowd_rsi  squeeze_on  \n","334806   6.763344        True  \n","334807  14.865969        True  \n","334808  30.288448        True  \n","334809  43.359961        True  \n","334810  49.479769        True  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["dfs[0].tail()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["for i in range(len(dfs)):\n","    df, bid_ask_mid_prices = dfs[i], bid_ask_mid_prices_list[i]\n","\n","    stard_idx = len(bid_ask_mid_prices) - len(df)\n","\n","    bid_ask_mid_prices = bid_ask_mid_prices.iloc[stard_idx:, :]\n","    bid_ask_mid_prices.dropna(inplace=True)\n","    bid_ask_mid_prices.reset_index(drop=True, inplace=True)\n","\n","    assert len(bid_ask_mid_prices) == len(df)\n","\n","    bid_ask_mid_prices_list[i] = bid_ask_mid_prices"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Qp5VKTj7ujLO"},"outputs":[],"source":["look_back_size = 150"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"LNUGMb0RR18a"},"outputs":[],"source":["def grab_image_data(subset):\n","  # rp_transformer = RecurrencePlot()\n","  # rp_subset = rp_transformer.transform(subset)\n","\n","  # return rp_subset\n","\n","  gasf_transformer = GramianAngularField(method='summation')\n","  gasf_subset = gasf_transformer.transform(subset)\n","\n","  return gasf_subset\n","\n","  # gadf_transformer = GramianAngularField(method='difference')\n","  # gadf_subset = gadf_transformer.transform(subset)\n","\n","  # return gadf_subset\n","\n","  # image_data = np.append(rp_subset, gasf_subset, axis=-1)\n","  # image_data = np.append(image_data, gadf_subset ,axis=-1)\n","  \n","  # return image_data"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RUNNING SIMULATION FOR Eur_Gbp...\n","2018\n","Buys: 0\n","Sells: 0\n","Nones: 0\n","\n","2019\n","Buys: 30\n","Sells: 37\n","Nones: 130\n","\n","2020\n","Buys: 77\n","Sells: 87\n","Nones: 324\n","\n","2021\n","Buys: 141\n","Sells: 131\n","Nones: 520\n","\n","2022\n","Buys: 165\n","Sells: 148\n","Nones: 596\n","\n","Buys: 199\n","Sells: 178\n","Nones: 704\n","\n"]}],"source":["# buys_list = []\n","# sells_list = []\n","# nones_list = []\n","\n","# value_per_pip = 1.0\n","# amounts_per_day = [-0.00008, -0.0001, -0.00012]\n","# spread_cutoff = 0.10\n","# risk_reward_ratio = 1.5\n","\n","# def get_n_units(trade_type, stop_loss, ask_open, bid_open, mid_open, currency_pair):\n","#     _, second = currency_pair.split('_')\n","  \n","#     pips_to_risk = ask_open - stop_loss if trade_type == 'buy' else stop_loss - bid_open\n","#     pips_to_risk_calc = pips_to_risk * 10000 if second != 'Jpy' else pips_to_risk * 100\n","\n","#     if second == 'Usd':\n","#         per_pip = 0.0001\n","\n","#     else:\n","#         per_pip = 0.0001 / mid_open if second != 'Jpy' else 0.01 / mid_open\n","\n","#     n_units = int(50 / (pips_to_risk_calc * per_pip))\n","\n","#     return n_units\n","\n","# def calculate_day_fees(start_date, end_date, n_units):\n","#     curr_fee = np.random.choice(amounts_per_day, p=[0.25, 0.50, 0.25]) * n_units\n","#     num_days = np.busday_count(start_date.date(), end_date.date())\n","\n","#     return num_days * curr_fee\n","\n","# for idx in range(len(currencies)):\n","#     currency_pair, df, df_long, bid_ask_mid_prices = currencies[idx], dfs[idx], df_longs[idx], bid_ask_mid_prices_list[idx]\n","#     rounding = 3 if 'Jpy' in currency_pair else 5\n","#     buys, sells, nones = [], [], []\n","#     trade, prev_year = None, None\n","\n","#     print(f'RUNNING SIMULATION FOR {currency_pair}...')\n","\n","#     for i in range(look_back_size, len(df)):\n","#         curr_date = df.loc[df.index[i], 'Date']\n","#         if prev_year is None or curr_date.year > prev_year:\n","#             prev_year = curr_date.year\n","#             print(prev_year)\n","#             print(f'Buys: {len(buys)}')\n","#             print(f'Sells: {len(sells)}')\n","#             print(f'Nones: {len(nones)}\\n')\n","#         curr_long = df_long.loc[df_long['Date'] < curr_date]\n","#         if len(curr_long) < look_back_size + 1:\n","#             continue\n","#         ema200_2, ema100_2, atr2, rsi2, rsi_sma2, vo2, macd2, macdsignal2 = df.loc[df.index[i - 2], ['ema200', 'ema100', 'atr', 'rsi', 'rsi_sma', 'vo', 'macd', 'macdsignal']]\n","#         ema200_1, ema100_1, atr1, rsi1, rsi_sma1, vo1, adx1, atr_sma1, macd1, macdsignal1 = df.loc[df.index[i - 1], ['ema200', 'ema100', 'atr', 'rsi', 'rsi_sma', 'vo', 'adx', 'atr_sma', 'macd', 'macdsignal']]\n","#         mid_open2, mid_close2, mid_low2, mid_high2 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 2], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","#         mid_open1, mid_close1, mid_low1, mid_high1 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 1], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","#         curr_ao, curr_bo, curr_mid_open, curr_ask_low, curr_bid_high = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i], ['Ask_Open', 'Bid_Open', 'Mid_Open', 'Ask_Low', 'Bid_High']]\n","#         spread = abs(curr_ao - curr_bo)\n","\n","#         emas_buy_signal = ema200_1 < ema100_1\n","#         emas_sell_signal = ema200_1 > ema100_1\n","\n","#         # sideways = adx1 < 20 or atr1 < atr_sma1\n","#         sideways = False\n","\n","#         rsi_buy_signal = rsi1 > rsi_sma1\n","#         rsi_sell_signal = rsi1 < rsi_sma1\n","\n","#         macd_vals = [0, macd2, macdsignal2, macd1, macdsignal1]\n","\n","#         macd_buy_signal = macd2 < macdsignal2 and macd1 > macdsignal1 and max(macd_vals) == 0\n","#         macd_sell_signal = macd2 > macdsignal2 and macd1 < macdsignal1 and min(macd_vals) == 0\n","\n","#         if trade is None:\n","#             if macd_buy_signal and emas_buy_signal and rsi_buy_signal and not sideways:\n","#                 lowest_low = min(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_Low']))\n","                \n","#                 open_price = float(curr_ao)\n","#                 pullback = float(lowest_low) - spread\n","\n","#                 stop_loss = round(pullback, rounding)\n","\n","#                 if stop_loss < open_price:\n","#                     curr_pips_to_risk = open_price - stop_loss\n","\n","#                     if spread <= curr_pips_to_risk * spread_cutoff:\n","#                         stop_gain = round(open_price + (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","#                         n_units = get_n_units('buy', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","#                         trade = {'open_price': open_price, 'trade_type': 'buy', 'stop_loss': stop_loss,\n","#                                                         'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","#                                                         'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","#             elif macd_sell_signal and emas_sell_signal and rsi_sell_signal and not sideways:\n","#                 highest_high = max(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_High']))\n","\n","#                 open_price = float(curr_bo)\n","#                 pullback = float(highest_high) + spread\n","\n","#                 stop_loss = round(pullback, rounding)\n","\n","#                 if stop_loss > open_price:\n","#                     curr_pips_to_risk = stop_loss - open_price\n","\n","#                     if spread <= curr_pips_to_risk * spread_cutoff:\n","#                         stop_gain = round(open_price - (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","#                         n_units = get_n_units('sell', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","#                         trade = {'open_price': open_price, 'trade_type': 'sell', 'stop_loss': stop_loss,\n","#                                 'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","#                                 'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","#         if trade is not None:\n","#             for j in range(i, len(df)):\n","#                 curr_date = df.loc[df.index[j], 'Date']\n","#                 curr_bid_open, curr_bid_high, curr_bid_low, curr_bid_close, curr_ask_open, curr_ask_high, curr_ask_low, curr_ask_close = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[j], ['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close']]\n","\n","#                 if trade['trade_type'] == 'buy' and curr_bid_low <= trade['stop_loss']:\n","#                     nones.append(trade['start_date']) \n","\n","#                     trade = None\n","#                     break\n","\n","\n","#                 if trade['trade_type'] == 'buy' and curr_bid_high >= trade['stop_gain']:\n","#                     trade_amount = (trade['stop_gain'] - trade['open_price']) * trade['n_units'] * value_per_pip\n","#                     day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","#                     if trade_amount + day_fees > 0:\n","#                         buys.append(trade['start_date'])\n","\n","#                     trade = None\n","#                     break\n","\n","#                 if trade['trade_type'] == 'sell' and curr_ask_high >= trade['stop_loss']:\n","#                     nones.append(trade['start_date'])\n","\n","#                     trade = None\n","#                     break\n","\n","#                 if trade['trade_type'] == 'sell' and curr_ask_low <= trade['stop_gain']:\n","#                     trade_amount = (trade['open_price'] - trade['stop_gain']) * trade['n_units'] * value_per_pip\n","#                     day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","#                     if trade_amount + day_fees > 0:\n","#                         sells.append(trade['start_date'])\n","\n","#                     trade = None\n","#                     break\n","    \n","#     buys_list.append(buys)\n","#     sells_list.append(sells)\n","#     nones_list.append(nones)\n","\n","#     print(f'Buys: {len(buys)}')\n","#     print(f'Sells: {len(sells)}')\n","#     print(f'Nones: {len(nones)}\\n')\n","\n","\n","\n","\n","\n","buys_list = []\n","sells_list = []\n","nones_list = []\n","\n","value_per_pip = 1.0\n","amounts_per_day = [-0.00008, -0.0001, -0.00012]\n","spread_cutoff = 0.10\n","risk_reward_ratio = 1.5\n","\n","def get_n_units(trade_type, stop_loss, ask_open, bid_open, mid_open, currency_pair):\n","    _, second = currency_pair.split('_')\n","  \n","    pips_to_risk = ask_open - stop_loss if trade_type == 'buy' else stop_loss - bid_open\n","    pips_to_risk_calc = pips_to_risk * 10000 if second != 'Jpy' else pips_to_risk * 100\n","\n","    if second == 'Usd':\n","        per_pip = 0.0001\n","\n","    else:\n","        per_pip = 0.0001 / mid_open if second != 'Jpy' else 0.01 / mid_open\n","\n","    n_units = int(50 / (pips_to_risk_calc * per_pip))\n","\n","    return n_units\n","\n","def calculate_day_fees(start_date, end_date, n_units):\n","    curr_fee = np.random.choice(amounts_per_day, p=[0.25, 0.50, 0.25]) * n_units\n","    num_days = np.busday_count(start_date.date(), end_date.date())\n","\n","    return num_days * curr_fee\n","\n","for idx in range(len(currencies)):\n","    currency_pair, df, df_long, bid_ask_mid_prices = currencies[idx], dfs[idx], df_longs[idx], bid_ask_mid_prices_list[idx]\n","    rounding = 3 if 'Jpy' in currency_pair else 5\n","    buys, sells, nones = [], [], []\n","    trade, prev_year = None, None\n","\n","    print(f'RUNNING SIMULATION FOR {currency_pair}...')\n","\n","    for i in range(look_back_size, len(df)):\n","        curr_date = df.loc[df.index[i], 'Date']\n","        if prev_year is None or curr_date.year > prev_year:\n","            prev_year = curr_date.year\n","            print(prev_year)\n","            print(f'Buys: {len(buys)}')\n","            print(f'Sells: {len(sells)}')\n","            print(f'Nones: {len(nones)}\\n')\n","\n","        if len(df_long.loc[df_long.Date >= curr_date]) == 0:\n","            break\n","\n","        if len(df_long.loc[df_long.Date <= curr_date]) < look_back_size + 1:\n","            continue\n","\n","        ema200_2, ema100_2, rsi2, macd2, macdsignal2 = df.loc[df.index[i - 2], ['ema200', 'ema100', 'rsi', 'macd', 'macdsignal']]\n","        ema200_1, ema100_1, rsi1, adx1, macd1, macdsignal1 = df.loc[df.index[i - 1], ['ema200', 'ema100', 'rsi', 'adx', 'macd', 'macdsignal']]\n","        mid_open2, mid_close2, mid_low2, mid_high2 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 2], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","        mid_open1, mid_close1, mid_low1, mid_high1 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 1], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","        curr_ao, curr_bo, curr_mid_open, curr_ask_low, curr_bid_high = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i], ['Ask_Open', 'Bid_Open', 'Mid_Open', 'Ask_Low', 'Bid_High']]\n","        spread = abs(curr_ao - curr_bo)\n","\n","        macd_vals = [0, macd2, macdsignal2, macd1, macdsignal1]\n","\n","        macd_buy_signal = macd2 < macdsignal2 and macd1 > macdsignal1 and max(macd_vals) == 0\n","        macd_sell_signal = macd2 > macdsignal2 and macd1 < macdsignal1 and min(macd_vals) == 0\n","\n","        if trade is None:\n","            if macd_buy_signal:\n","                lowest_low = min(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_Low']))\n","                \n","                open_price = float(curr_ao)\n","                pullback = float(lowest_low) - spread\n","\n","                stop_loss = round(pullback, rounding)\n","\n","                if stop_loss < open_price:\n","                    curr_pips_to_risk = open_price - stop_loss\n","\n","                    if spread <= curr_pips_to_risk * spread_cutoff:\n","                        stop_gain = round(open_price + (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","                        n_units = get_n_units('buy', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","                        trade = {'open_price': open_price, 'trade_type': 'buy', 'stop_loss': stop_loss,\n","                                                        'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","                                                        'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","            elif macd_sell_signal:\n","                highest_high = max(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_High']))\n","\n","                open_price = float(curr_bo)\n","                pullback = float(highest_high) + spread\n","\n","                stop_loss = round(pullback, rounding)\n","\n","                if stop_loss > open_price:\n","                    curr_pips_to_risk = stop_loss - open_price\n","\n","                    if spread <= curr_pips_to_risk * spread_cutoff:\n","                        stop_gain = round(open_price - (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","                        n_units = get_n_units('sell', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","                        trade = {'open_price': open_price, 'trade_type': 'sell', 'stop_loss': stop_loss,\n","                                'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","                                'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","        if trade is not None:\n","            for j in range(i, len(df)):\n","                curr_date = df.loc[df.index[j], 'Date']\n","                curr_bid_open, curr_bid_high, curr_bid_low, curr_bid_close, curr_ask_open, curr_ask_high, curr_ask_low, curr_ask_close = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[j], ['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close']]\n","\n","                if trade['trade_type'] == 'buy' and curr_bid_low <= trade['stop_loss']:\n","                    nones.append(trade['start_date']) \n","\n","                    trade = None\n","                    break\n","\n","\n","                if trade['trade_type'] == 'buy' and curr_bid_high >= trade['stop_gain']:\n","                    trade_amount = (trade['stop_gain'] - trade['open_price']) * trade['n_units'] * value_per_pip\n","                    day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","                    if trade_amount + day_fees > 0:\n","                        buys.append(trade['start_date'])\n","\n","                    trade = None\n","                    break\n","\n","                if trade['trade_type'] == 'sell' and curr_ask_high >= trade['stop_loss']:\n","                    nones.append(trade['start_date'])\n","\n","                    trade = None\n","                    break\n","\n","                if trade['trade_type'] == 'sell' and curr_ask_low <= trade['stop_gain']:\n","                    trade_amount = (trade['open_price'] - trade['stop_gain']) * trade['n_units'] * value_per_pip\n","                    day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","                    if trade_amount + day_fees > 0:\n","                        sells.append(trade['start_date'])\n","\n","                    trade = None\n","                    break\n","    \n","    buys_list.append(buys)\n","    sells_list.append(sells)\n","    nones_list.append(nones)\n","\n","    print(f'Buys: {len(buys)}')\n","    print(f'Sells: {len(sells)}')\n","    print(f'Nones: {len(nones)}\\n')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# for df in dfs:\n","#     df.drop(['ema200_x', 'ema100_x', 'rsi_x', 'rsi_sma_x', 'adx_x', 'macd_x', 'macdsignal_x', 'slowk_rsi_x', 'slowd_rsi_x', 'squeeze_on_x', 'ema200_y', 'ema100_y', 'rsi_y', 'rsi_sma_y', 'adx_y', 'macd_y', 'macdsignal_y', 'slowk_rsi_y', 'slowd_rsi_y', 'squeeze_on_y'], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["199\n","178\n","704\n"]}],"source":["buy_indices_list = []\n","sell_indices_list = []\n","nones_indices_list = []\n","\n","for i in range(len(dfs)):\n","    buys, sells, nones, df = buys_list[i], sells_list[i], nones_list[i], dfs[i]\n","    \n","    buy_indices = [df.index[df['Date'] == curr_date] - 1 for curr_date in buys]\n","    sell_indices = [df.index[df['Date'] == curr_date] - 1 for curr_date in sells]\n","    nones_indices = [df.index[df['Date'] == curr_date] - 1 for curr_date in nones]\n","\n","    buy_indices_list.append(buy_indices)\n","    sell_indices_list.append(sell_indices)\n","    nones_indices_list.append(nones_indices)\n","\n","    print(len(buy_indices))\n","    print(len(sell_indices))\n","    print(len(nones_indices))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["(150, 26, 26)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["i = 2000\n","foo = dfs[0].iloc[:i + 1, :]\n","foo_long = df_longs[0].loc[df_longs[0].Date <= foo.loc[foo.index[-1], 'Date']].iloc[:-1, :]\n","foo = pd.merge(foo, foo_long, how='left', on='Date').iloc[:, 1:]\n","foo = foo.fillna(method='ffill')\n","foo.dropna(inplace=True)\n","foo = foo.iloc[-look_back_size:, :]\n","correct_shape = grab_image_data(foo).shape\n","correct_shape"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Impact_x</th>\n","      <th>Actual_Class_x</th>\n","      <th>Previous_Class_x</th>\n","      <th>Impact_y</th>\n","      <th>Actual_Class_y</th>\n","      <th>Previous_Class_y</th>\n","      <th>ema200_x</th>\n","      <th>ema100_x</th>\n","      <th>rsi_x</th>\n","      <th>rsi_sma_x</th>\n","      <th>...</th>\n","      <th>ema200_y</th>\n","      <th>ema100_y</th>\n","      <th>rsi_y</th>\n","      <th>rsi_sma_y</th>\n","      <th>adx_y</th>\n","      <th>macd_y</th>\n","      <th>macdsignal_y</th>\n","      <th>slowk_rsi_y</th>\n","      <th>slowd_rsi_y</th>\n","      <th>squeeze_on_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1851</th>\n","      <td>2.0</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.884763</td>\n","      <td>0.884963</td>\n","      <td>49.452913</td>\n","      <td>50.352880</td>\n","      <td>...</td>\n","      <td>0.884810</td>\n","      <td>0.884149</td>\n","      <td>53.212728</td>\n","      <td>61.288255</td>\n","      <td>12.385877</td>\n","      <td>0.000079</td>\n","      <td>0.000123</td>\n","      <td>86.095100</td>\n","      <td>79.392787</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1852</th>\n","      <td>2.0</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.884764</td>\n","      <td>0.884960</td>\n","      <td>45.805060</td>\n","      <td>50.200096</td>\n","      <td>...</td>\n","      <td>0.884810</td>\n","      <td>0.884149</td>\n","      <td>53.212728</td>\n","      <td>61.288255</td>\n","      <td>12.385877</td>\n","      <td>0.000079</td>\n","      <td>0.000123</td>\n","      <td>86.095100</td>\n","      <td>79.392787</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1853</th>\n","      <td>2.0</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.884767</td>\n","      <td>0.884962</td>\n","      <td>53.553320</td>\n","      <td>50.232654</td>\n","      <td>...</td>\n","      <td>0.884810</td>\n","      <td>0.884149</td>\n","      <td>53.212728</td>\n","      <td>61.288255</td>\n","      <td>12.385877</td>\n","      <td>0.000079</td>\n","      <td>0.000123</td>\n","      <td>86.095100</td>\n","      <td>79.392787</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1854</th>\n","      <td>2.0</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.884768</td>\n","      <td>0.884961</td>\n","      <td>48.568041</td>\n","      <td>50.181158</td>\n","      <td>...</td>\n","      <td>0.884813</td>\n","      <td>0.884167</td>\n","      <td>53.529823</td>\n","      <td>61.370683</td>\n","      <td>12.246989</td>\n","      <td>0.000082</td>\n","      <td>0.000115</td>\n","      <td>78.822881</td>\n","      <td>84.035360</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1855</th>\n","      <td>2.0</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.884771</td>\n","      <td>0.884963</td>\n","      <td>55.011138</td>\n","      <td>50.447920</td>\n","      <td>...</td>\n","      <td>0.884813</td>\n","      <td>0.884167</td>\n","      <td>53.529823</td>\n","      <td>61.370683</td>\n","      <td>12.246989</td>\n","      <td>0.000082</td>\n","      <td>0.000115</td>\n","      <td>78.822881</td>\n","      <td>84.035360</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 26 columns</p>\n","</div>"],"text/plain":["      Impact_x  Actual_Class_x  Previous_Class_x  Impact_y  Actual_Class_y  \\\n","1851       2.0            0.25               0.0       2.0             1.0   \n","1852       2.0            0.25               0.0       2.0             1.0   \n","1853       2.0            0.25               0.0       2.0             1.0   \n","1854       2.0            0.25               0.0       2.0             1.0   \n","1855       2.0            0.25               0.0       2.0             1.0   \n","\n","      Previous_Class_y  ema200_x  ema100_x      rsi_x  rsi_sma_x  ...  \\\n","1851               1.0  0.884763  0.884963  49.452913  50.352880  ...   \n","1852               1.0  0.884764  0.884960  45.805060  50.200096  ...   \n","1853               1.0  0.884767  0.884962  53.553320  50.232654  ...   \n","1854               1.0  0.884768  0.884961  48.568041  50.181158  ...   \n","1855               1.0  0.884771  0.884963  55.011138  50.447920  ...   \n","\n","      ema200_y  ema100_y      rsi_y  rsi_sma_y      adx_y    macd_y  \\\n","1851  0.884810  0.884149  53.212728  61.288255  12.385877  0.000079   \n","1852  0.884810  0.884149  53.212728  61.288255  12.385877  0.000079   \n","1853  0.884810  0.884149  53.212728  61.288255  12.385877  0.000079   \n","1854  0.884813  0.884167  53.529823  61.370683  12.246989  0.000082   \n","1855  0.884813  0.884167  53.529823  61.370683  12.246989  0.000082   \n","\n","      macdsignal_y  slowk_rsi_y  slowd_rsi_y  squeeze_on_y  \n","1851      0.000123    86.095100    79.392787          True  \n","1852      0.000123    86.095100    79.392787          True  \n","1853      0.000123    86.095100    79.392787          True  \n","1854      0.000115    78.822881    84.035360          True  \n","1855      0.000115    78.822881    84.035360          True  \n","\n","[5 rows x 26 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["foo.head()"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Hqy2dig_7e-F"},"outputs":[],"source":["def get_sequential_data():\n","    no_actions = []\n","    buys = []\n","    sells = []\n","\n","    for z in range(len(dfs)):\n","        df, df_long = dfs[z], df_longs[z]\n","\n","        buy_indices, sell_indices, nones_indices = buy_indices_list[z], sell_indices_list[z], nones_indices_list[z]\n","\n","        for i in buy_indices:\n","            if len(i) == 1:\n","                i = i[0]\n","                seq = df.iloc[:i + 1, :]\n","                seq_long = df_long.loc[df_long.Date <= seq.loc[seq.index[-1], 'Date']].iloc[:-1, :]\n","                seq = pd.merge(seq, seq_long, how='left', on='Date').iloc[:, 1:]\n","                seq = seq.fillna(method='ffill')\n","                seq.dropna(inplace=True)\n","                seq = seq.iloc[-look_back_size:, :]\n","\n","                if seq.shape == correct_shape[:-1] and not seq.isnull().values.any():\n","                    seq = grab_image_data(seq)\n","                    buys.append([seq, np.array([0, 1, 0])])\n","\n","        for i in sell_indices:\n","            if len(i) == 1:\n","                i = i[0]\n","                seq = df.iloc[:i + 1, :]\n","                seq_long = df_long.loc[df_long.Date <= seq.loc[seq.index[-1], 'Date']].iloc[:-1, :]\n","                seq = pd.merge(seq, seq_long, how='left', on='Date').iloc[:, 1:]\n","                seq = seq.fillna(method='ffill')\n","                seq.dropna(inplace=True)\n","                seq = seq.iloc[-look_back_size:, :]\n","\n","                if seq.shape == correct_shape[:-1] and not seq.isnull().values.any():\n","                    seq = grab_image_data(seq)\n","                    sells.append([seq, np.array([0, 0, 1])])\n","\n","        for i in nones_indices:\n","            if len(i) == 1:\n","                i = i[0]\n","                seq = df.iloc[:i + 1, :]\n","                seq_long = df_long.loc[df_long.Date <= seq.loc[seq.index[-1], 'Date']].iloc[:-1, :]\n","                seq = pd.merge(seq, seq_long, how='left', on='Date').iloc[:, 1:]\n","                seq = seq.fillna(method='ffill')\n","                seq.dropna(inplace=True)\n","                seq = seq.iloc[-look_back_size:, :]\n","\n","                if seq.shape == correct_shape[:-1] and not seq.isnull().values.any():\n","                    seq = grab_image_data(seq)\n","                    no_actions.append([seq, np.array([1, 0, 0])])\n","\n","    np.random.shuffle(no_actions)\n","    np.random.shuffle(buys)\n","    np.random.shuffle(sells)\n","\n","    lower = min(len(no_actions), len(buys), len(sells))\n","\n","    no_actions = no_actions[:int(lower * 1.0)]\n","\n","    sequential_data = no_actions + buys + sells\n","    np.random.shuffle(sequential_data)\n","\n","    return sequential_data"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"gk8jS65z7i5q"},"outputs":[],"source":["sequential_data = get_sequential_data()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["555"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["len(sequential_data)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1631924931206,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":360},"id":"cdYAzLkF5PO5","outputId":"9e5842f8-8004-4914-a05c-2a56353f39c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset shapes:\n","388\n","167\n"]}],"source":["training_proportion = 0.70\n","train_test_cutoff_index = int(len(sequential_data) * training_proportion)\n","\n","train_set = sequential_data[0:train_test_cutoff_index]\n","test_set = sequential_data[train_test_cutoff_index:]\n","\n","print('Dataset shapes:')\n","print(len(train_set))\n","print(len(test_set))"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"wLRUg-ekVUtL"},"outputs":[],"source":["x_train = []\n","y_train = []\n","\n","for seq, target in train_set:\n","  x_train.append(seq)\n","  y_train.append(target)\n","\n","x_test = []\n","y_test = []\n","\n","for seq, target in test_set:\n","  x_test.append(seq)\n","  y_test.append(target)\n","\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)\n","x_test = np.array(x_test)\n","y_test = np.array(y_test)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1631924983918,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":360},"id":"D3_lj-U3NGM2","outputId":"ce1b1761-9bb2-4afc-c7c5-eca2ac8cde79"},"outputs":[{"data":{"text/plain":["(388, 150, 26, 26)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["(388, 3)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["y_train.shape"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"gWXFnbrFEQ9A"},"outputs":[],"source":["n_actions = 3\n","input_data_shape = x_train.shape[1:]\n","\n","model = Sequential()\n","\n","model.add(Conv2D(filters = 16, kernel_size = (3,3), padding ='Same', activation ='relu', input_shape = input_data_shape))\n","model.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n","model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n","\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","# model.add(Dense(128, activation = \"relu\"))\n","# model.add(Dropout(0.5))\n","# model.add(Dense(128, activation = \"relu\"))\n","# model.add(Dropout(0.5))\n","model.add(Dense(16, activation = \"relu\"))\n","# model.add(Dropout(0.25))\n","# model.add(Dense(32, activation = \"relu\"))\n","model.add(Dense(n_actions, activation = \"softmax\"))"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"YzWCOxnCECEl"},"outputs":[],"source":["# Hyperparameters\n","n_epochs = 1000\n","batch_size = 32\n","n_steps = len(x_train) // batch_size \n","mean_loss = tf.keras.metrics.Mean() \n","optimizer = tf.keras.optimizers.Adam()\n","loss_fn = tf.keras.losses.categorical_crossentropy\n","metrics = [tf.keras.metrics.CategoricalAccuracy()]\n","# loss_fn = tf.keras.losses.MeanAbsoluteError\n","# metrics = [tf.keras.metrics.MeanAbsoluteError()]"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["early_stop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=n_epochs)\n","model_checkpoint = ModelCheckpoint(f'/Users/mymac/forex_macd_cnn_{currencies[0]}', monitor='val_accuracy', save_best_only=True, verbose=1)\n","\n","optimizer = Adam()\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60729,"status":"ok","timestamp":1631925055308,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":360},"id":"NRG4mIMcq5_f","outputId":"eb40bd91-3efc-495f-a4a0-8545eab20758"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n","13/13 [==============================] - ETA: 0s - loss: 3.2050 - accuracy: 0.3041\n","Epoch 00001: val_accuracy improved from -inf to 0.35329, saving model to /Users/mymac/forex_macd_cnn_Eur_Gbp\n","INFO:tensorflow:Assets written to: /Users/mymac/forex_macd_cnn_Eur_Gbp/assets\n","13/13 [==============================] - 1s 91ms/step - loss: 3.2050 - accuracy: 0.3041 - val_loss: 1.0984 - val_accuracy: 0.3533\n","Epoch 2/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0987 - accuracy: 0.3068\n","Epoch 00002: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 45ms/step - loss: 1.0986 - accuracy: 0.3067 - val_loss: 1.0983 - val_accuracy: 0.3413\n","Epoch 3/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0984 - accuracy: 0.3693\n","Epoch 00003: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0985 - accuracy: 0.3660 - val_loss: 1.0982 - val_accuracy: 0.3413\n","Epoch 4/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0984 - accuracy: 0.3665\n","Epoch 00004: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0983 - accuracy: 0.3660 - val_loss: 1.0983 - val_accuracy: 0.3413\n","Epoch 5/1000\n","13/13 [==============================] - ETA: 0s - loss: 1.0982 - accuracy: 0.3660\n","Epoch 00005: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 47ms/step - loss: 1.0982 - accuracy: 0.3660 - val_loss: 1.0984 - val_accuracy: 0.3413\n","Epoch 6/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0981 - accuracy: 0.3636\n","Epoch 00006: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 45ms/step - loss: 1.0980 - accuracy: 0.3660 - val_loss: 1.0984 - val_accuracy: 0.3413\n","Epoch 7/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0976 - accuracy: 0.3722\n","Epoch 00007: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0978 - accuracy: 0.3660 - val_loss: 1.0984 - val_accuracy: 0.3413\n","Epoch 8/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0977 - accuracy: 0.3636\n","Epoch 00008: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0976 - accuracy: 0.3660 - val_loss: 1.0985 - val_accuracy: 0.3413\n","Epoch 9/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0970 - accuracy: 0.3778\n","Epoch 00009: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0976 - accuracy: 0.3660 - val_loss: 1.0985 - val_accuracy: 0.3413\n","Epoch 10/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0973 - accuracy: 0.3665\n","Epoch 00010: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0973 - accuracy: 0.3660 - val_loss: 1.0986 - val_accuracy: 0.3413\n","Epoch 11/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0976 - accuracy: 0.3580\n","Epoch 00011: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0972 - accuracy: 0.3660 - val_loss: 1.0987 - val_accuracy: 0.3413\n","Epoch 12/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0976 - accuracy: 0.3580\n","Epoch 00012: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0970 - accuracy: 0.3660 - val_loss: 1.0988 - val_accuracy: 0.3413\n","Epoch 13/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0966 - accuracy: 0.3722\n","Epoch 00013: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0969 - accuracy: 0.3660 - val_loss: 1.0989 - val_accuracy: 0.3413\n","Epoch 14/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0972 - accuracy: 0.3608\n","Epoch 00014: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0967 - accuracy: 0.3660 - val_loss: 1.0989 - val_accuracy: 0.3413\n","Epoch 15/1000\n","13/13 [==============================] - ETA: 0s - loss: 1.0967 - accuracy: 0.3660\n","Epoch 00015: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 44ms/step - loss: 1.0967 - accuracy: 0.3660 - val_loss: 1.0991 - val_accuracy: 0.3413\n","Epoch 16/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0967 - accuracy: 0.3636\n","Epoch 00016: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 45ms/step - loss: 1.0966 - accuracy: 0.3660 - val_loss: 1.0992 - val_accuracy: 0.3413\n","Epoch 17/1000\n","11/13 [========================>.....] - ETA: 0s - loss: 1.0978 - accuracy: 0.3523\n","Epoch 00017: val_accuracy did not improve from 0.35329\n","13/13 [==============================] - 1s 45ms/step - loss: 1.0966 - accuracy: 0.3660 - val_loss: 1.0992 - val_accuracy: 0.3413\n","Epoch 18/1000\n"," 7/13 [===============>..............] - ETA: 0s - loss: 1.0964 - accuracy: 0.3705"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-7af7dcac3212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["history = model.fit(\n","    x_train, y_train,\n","    batch_size=batch_size,\n","    epochs=n_epochs,\n","    validation_data=(x_test, y_test),\n","    callbacks=[early_stop, model_checkpoint]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNNXv50z2GrExQJFFMvQ0O4","collapsed_sections":[],"name":"forex_cnn.ipynb","provenance":[]},"interpreter":{"hash":"2bc6dffc417b633bbbc31cedd954f3e10eebcdab1341647d4de83cb692948a0c"},"kernelspec":{"display_name":"Python 3.9.9 ('forex')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}
