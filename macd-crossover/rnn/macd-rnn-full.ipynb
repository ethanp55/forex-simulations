{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"-3XsA6wafwLf"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","import seaborn as sns\n","import math\n","from pyts.image import RecurrencePlot, GramianAngularField\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GRU\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.models import load_model, Sequential\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from collections import deque\n","import warnings\n","from pickle import dump, load\n","\n","file_path = '/Users/mymac/Google Drive/My Drive/Forex_Robot/'"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# currencies = ['Usd_Chf', 'Gbp_Usd', 'Usd_Cad', 'Aud_Usd', 'Eur_Usd', 'Usd_Jpy', 'Nzd_Usd']\n","currencies = ['Gbp_Usd']\n","years = '2016-2022'\n","\n","size = 3 / 3\n","dfs, df_longs = [], []\n","\n","for currency_pair in currencies:\n","    df = pd.read_csv(file_path + f'Oanda_{currency_pair}_M5_{years}.csv')\n","    df.Date = pd.to_datetime(df.Date)\n","    cutoff_idx = int((1 - size) * len(df))\n","    df = df.iloc[cutoff_idx:, :]\n","    df.dropna(inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","    dfs.append(df)\n","\n","    df_long = pd.read_csv(file_path + f'Oanda_{currency_pair}_M30_{years}.csv')\n","    df_long.Date = pd.to_datetime(df_long.Date)\n","    df_long.dropna(inplace=True)\n","    df_long.reset_index(drop=True, inplace=True)\n","    df_longs.append(df_long)"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1639361445690,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":420},"id":"tedQvbLQ0gBO","outputId":"5e87470b-a435-467d-f6f3-7cd15683527f"},"outputs":[],"source":["for df in dfs:\n","    df['sin_hour'] = np.sin(2 * np.pi * df['Date'].dt.hour / 24)\n","    # df['cos_hour'] = np.cos(2 * np.pi * df['Date'].dt.hour / 24)\n","    df['sin_day'] = np.sin(2 * np.pi * df['Date'].dt.day / 7)\n","    # df['cos_day'] = np.cos(2 * np.pi * df['Date'].dt.day / 7)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["def psar(barsdata, iaf=0.02, maxaf=0.2):\n","    length = len(barsdata)\n","    high = list(barsdata['Mid_High'])\n","    low = list(barsdata['Mid_Low'])\n","    close = list(barsdata['Mid_Close'])\n","    psar = close[0:len(close)]\n","    bull = True\n","    af = iaf\n","    hp = high[0]\n","    lp = low[0]\n","    for i in range(2, length):\n","        if bull:\n","            psar[i] = psar[i - 1] + af * (hp - psar[i - 1])\n","        else:\n","            psar[i] = psar[i - 1] + af * (lp - psar[i - 1])\n","        reverse = False\n","        if bull:\n","            if low[i] < psar[i]:\n","                bull = False\n","                reverse = True\n","                psar[i] = hp\n","                lp = low[i]\n","                af = iaf\n","        else:\n","            if high[i] > psar[i]:\n","                bull = True\n","                reverse = True\n","                psar[i] = lp\n","                hp = high[i]\n","                af = iaf\n","        if not reverse:\n","            if bull:\n","                if high[i] > hp:\n","                    hp = high[i]\n","                    af = min(af + iaf, maxaf)\n","                if low[i - 1] < psar[i]:\n","                    psar[i] = low[i - 1]\n","                if low[i - 2] < psar[i]:\n","                    psar[i] = low[i - 2]\n","            else:\n","                if low[i] < lp:\n","                    lp = low[i]\n","                    af = min(af + iaf, maxaf)\n","                if high[i - 1] > psar[i]:\n","                    psar[i] = high[i - 1]\n","                if high[i - 2] > psar[i]:\n","                    psar[i] = high[i - 2]\n","    return psar\n","\n","\n","def atr(high, low, close, lookback=14):\n","    high_low = high - low\n","    high_close = np.abs(high - close.shift())\n","    low_close = np.abs(low - close.shift())\n","    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n","    true_range = np.max(ranges, axis=1)\n","\n","    return true_range.rolling(lookback).sum() / lookback\n","\n","\n","def rsi(closes, periods=14):\n","    close_delta = closes.diff()\n","\n","    up = close_delta.clip(lower=0)\n","    down = -1 * close_delta.clip(upper=0)\n","    ma_up = up.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n","    ma_down = down.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n","        \n","    rsi = ma_up / ma_down\n","    rsi = 100 - (100/(1 + rsi))\n","\n","    return rsi\n","\n","  \n","def adx(high, low, close, lookback=14):\n","    plus_dm = high.diff()\n","    minus_dm = low.diff()\n","    plus_dm[plus_dm < 0] = 0\n","    minus_dm[minus_dm > 0] = 0\n","    \n","    tr1 = pd.DataFrame(high - low)\n","    tr2 = pd.DataFrame(abs(high - close.shift(1)))\n","    tr3 = pd.DataFrame(abs(low - close.shift(1)))\n","    frames = [tr1, tr2, tr3]\n","    tr = pd.concat(frames, axis = 1, join = 'inner').max(axis = 1)\n","    atr = tr.rolling(lookback).mean()\n","    \n","    plus_di = 100 * (plus_dm.ewm(alpha = 1/lookback).mean() / atr)\n","    minus_di = abs(100 * (minus_dm.ewm(alpha = 1/lookback).mean() / atr))\n","    dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n","    adx = ((dx.shift(1) * (lookback - 1)) + dx) / lookback\n","    adx_smooth = adx.ewm(alpha = 1/lookback).mean()\n","\n","    return adx_smooth\n","\n","\n","def stoch(high, low, close, lookback=14):\n","    high_lookback = high.rolling(lookback).max()\n","    low_lookback = low.rolling(lookback).min()\n","    slow_k = (close - low_lookback) * 100 / (high_lookback - low_lookback)\n","    slow_d = slow_k.rolling(3).mean()\n","\n","    return slow_k, slow_d\n","\n","def stoch_rsi(data, k_window=3, d_window=3, window=14):\n","    min_val = data.rolling(window=window, center=False).min()\n","    max_val = data.rolling(window=window, center=False).max()\n","\n","    stoch = ((data - min_val) / (max_val - min_val)) * 100\n","\n","    slow_k = stoch.rolling(window=k_window, center=False).mean()\n","\n","    slow_d = slow_k.rolling(window=d_window, center=False).mean()\n","\n","    return slow_k, slow_d\n","\n","def n_macd(macd, macdsignal, lookback=50):\n","    n_macd = 2 * (((macd - macd.rolling(lookback).min()) / (macd.rolling(lookback).max() - macd.rolling(lookback).min()))) - 1\n","    n_macdsignal = 2 * (((macdsignal - macdsignal.rolling(lookback).min()) / (macdsignal.rolling(lookback).max() - macdsignal.rolling(lookback).min()))) - 1\n","\n","    return n_macd, n_macdsignal\n","\n","def chop(df, lookback=14):\n","    atr1 = atr(df, lookback=1)\n","    high, low = df['Mid_High'], df['Mid_Low']\n","\n","    chop = np.log10(atr1.rolling(lookback).sum() / (high.rolling(lookback).max() - low.rolling(lookback).min())) / np.log10(lookback)\n","\n","    return chop\n","\n","def vo(volume, short_lookback=5, long_lookback=10):\n","    short_ema =  pd.Series.ewm(volume, span=short_lookback).mean()\n","    long_ema = pd.Series.ewm(volume, span=long_lookback).mean()\n","\n","    volume_oscillator = (short_ema - long_ema) / long_ema\n","\n","    return volume_oscillator\n","\n","def bar_lengths(bar_lens, window=36):\n","    return bar_lens.rolling(window=window).mean(), bar_lens.rolling(window=window).std()\n","\n","def sar_lengths(opens, sars, window=36):\n","    diffs = abs(opens - sars.shift(1))\n","\n","    return diffs.rolling(window=window).mean(), diffs.rolling(window=window).std()\n","\n","def supertrend(barsdata, atr_len=3, mult=3):\n","    curr_atr = atr(barsdata['Mid_High'], barsdata['Mid_Low'], barsdata['Mid_Close'], lookback=atr_len)\n","    highs, lows = barsdata['Mid_High'], barsdata['Mid_Low']\n","    hl2 = (highs + lows) / 2\n","    final_upperband = upper_band = hl2 + mult * curr_atr\n","    final_lowerband = lower_band = hl2 - mult * curr_atr\n","\n","    # initialize Supertrend column to True\n","    supertrend = [True] * len(df)\n","\n","    close = barsdata['Mid_Close']\n","    \n","    for i in range(1, len(df.index)):\n","        curr, prev = i, i - 1\n","        \n","        # if current close price crosses above upperband\n","        if close[curr] > final_upperband[prev]:\n","            supertrend[curr] = True\n","\n","        # if current close price crosses below lowerband\n","        elif close[curr] < final_lowerband[prev]:\n","            supertrend[curr] = False\n","\n","        # else, the trend continues\n","        else:\n","            supertrend[curr] = supertrend[prev]\n","            \n","            # adjustment to the final bands\n","            if supertrend[curr] == True and final_lowerband[curr] < final_lowerband[prev]:\n","                final_lowerband[curr] = final_lowerband[prev]\n","\n","            if supertrend[curr] == False and final_upperband[curr] > final_upperband[prev]:\n","                final_upperband[curr] = final_upperband[prev]\n","\n","    return supertrend, final_upperband, final_lowerband\n","\n","def heikin_ashi(opens, highs, lows, closes):\n","    ha_close = list((opens + highs + lows + closes) / 4)\n","    ha_opens = []\n","\n","    opens_list, closes_list = list(opens), list(closes)\n","\n","    for i in range(len(ha_close)):\n","        if i == 0:\n","            ha_opens.append((opens_list[i] + closes_list[i]) / 2)\n","\n","        else:\n","            ha_opens.append((ha_opens[i - 1] + ha_close[i - 1]) / 2)\n","\n","    ha_highs = list(pd.DataFrame({'ha_open': ha_opens, 'ha_close': ha_close, 'high': list(highs)}).max(axis=1))\n","    ha_lows = list(pd.DataFrame({'ha_open': ha_opens, 'ha_close': ha_close, 'low': list(lows)}).min(axis=1))\n","\n","    return ha_opens, ha_highs, ha_lows, ha_close\n","\n","def trend_indicator(opens, highs, lows, closes, ema_period=50, smoothing_period=10):\n","    ha_open, ha_high, ha_low, ha_close = heikin_ashi(opens, highs, lows, closes)\n","\n","    ha_o_ema = pd.Series.ewm(pd.DataFrame({'ha_open': ha_open}), span=ema_period).mean()\n","    ha_h_ema = pd.Series.ewm(pd.DataFrame({'ha_high': ha_high}), span=ema_period).mean()\n","    ha_l_ema = pd.Series.ewm(pd.DataFrame({'ha_low': ha_low}), span=ema_period).mean()\n","    ha_c_ema = pd.Series.ewm(pd.DataFrame({'ha_close': ha_close}), span=ema_period).mean()\n","\n","    return pd.Series.ewm(ha_o_ema, span=smoothing_period).mean(), pd.Series.ewm(ha_h_ema, span=smoothing_period).mean(), pd.Series.ewm(ha_l_ema, span=smoothing_period).mean(), pd.Series.ewm(ha_c_ema, span=smoothing_period).mean()\n","\n","def qqe_mod(barsdata, rsi_period=6, smoothing=5, qqe_factor=5, qqe2_factor=1.61, threshold=3, mult=0.35, sma_length=50):\n","    wilders_period = rsi_period * 2 - 1\n","\n","    curr_rsi = rsi(barsdata, periods=rsi_period)\n","    rsi_ema = pd.Series.ewm(curr_rsi, span=smoothing).mean()\n","    atr_rsi = abs(rsi_ema.shift(1) - rsi_ema)\n","    atr_rsi_ema = pd.Series.ewm(atr_rsi, span=wilders_period).mean()\n","    dar = pd.Series.ewm(atr_rsi_ema, span=wilders_period).mean() * qqe_factor\n","\n","    newshortband = rsi_ema + dar\n","    newlongband = rsi_ema - dar\n","\n","    rsi_ema_list = list(rsi_ema)\n","\n","    longband = [0]\n","    for i in range(1, len(rsi_ema_list)):\n","        if rsi_ema_list[i - 1] > longband[i - 1] and rsi_ema_list[i] > longband[i - 1]:\n","            longband.append(max(longband[i - 1],newlongband[i]))\n","\n","        else:\n","            longband.append(newlongband[i])\n","\n","    shortband = [0]\n","    for i in range(1,len(rsi_ema_list)):\n","        if rsi_ema_list[i - 1] < shortband[i - 1] and rsi_ema_list[i] < shortband[i - 1]:\n","            shortband.append(min(shortband[i - 1],newshortband[i]))\n","            \n","        else:\n","            shortband.append(newshortband[i])\n","\n","    longband = pd.Series(longband)\n","    shortband = pd.Series(shortband)\n","\n","    trend = np.where(rsi_ema > longband.shift(1), 1, -1)    \n","    fastatrrsitl = pd.Series(np.where(trend == 1, longband, shortband))\n","\n","    basis = (fastatrrsitl - 50).rolling(window=sma_length).mean()\n","    dev = (fastatrrsitl - 50).rolling(window=sma_length).std() * mult\n","    upper = basis + dev\n","    lower = basis - dev\n","\n","    greenbar1 = rsi_ema - 50 > threshold\n","    greenbar2 = rsi_ema - 50 > upper\n","    redbar1 = rsi_ema - 50 < threshold\n","    redbar2 = rsi_ema - 50 < lower\n","\n","    # uptrend = np.where((greenbar1 & greenbar2), True, False)\n","    # downtrend = np.where((redbar1 & redbar2), True, False)\n","\n","    uptrend = np.where((greenbar2), True, False)\n","    downtrend = np.where((redbar2), True, False)\n","\n","    return uptrend, downtrend\n","\n","def williams_r(highs, lows, closes, length=21, ema_length=15):\n","    highest_highs = highs.rolling(window=length).max()\n","    lowest_lows = lows.rolling(window=length).min()\n","\n","    willy = 100 * (closes - highest_highs) / (highest_highs - lowest_lows)\n","    willy_ema = pd.Series.ewm(willy, span=ema_length).mean()\n","\n","    return willy, willy_ema\n","\n","def squeeze(barsdata, length=20, length_kc=20, mult=1.5):\n","    # Bollinger bands\n","    m_avg = barsdata['Mid_Close'].rolling(window=length).mean()\n","    m_std = barsdata['Mid_Close'].rolling(window=length).std(ddof=0)\n","    upper_bb = m_avg + mult * m_std\n","    lower_bb = m_avg - mult * m_std\n","\n","    # Keltner channel\n","    tr0 = abs(barsdata['Mid_High'] - barsdata['Mid_Low'])\n","    tr1 = abs(barsdata['Mid_High'] - barsdata['Mid_Close'].shift())\n","    tr2 = abs(barsdata['Mid_Low'] - barsdata['Mid_Close'].shift())\n","    tr = pd.concat([tr0, tr1, tr2], axis=1).max(axis=1)\n","    range_ma = tr.rolling(window=length_kc).mean()\n","    upper_kc = m_avg + range_ma * mult\n","    lower_kc = m_avg - range_ma * mult\n","\n","    # Squeeze\n","    squeeze_on = (lower_bb > lower_kc) & (upper_bb < upper_kc)\n","\n","    return squeeze_on"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1639361446900,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":420},"id":"5Ttafp9WxjAe","outputId":"92fd8ae2-3721-4852-eb4d-6fa6c6226a50"},"outputs":[],"source":["bid_ask_mid_prices_list = []\n","\n","for df in dfs:\n","    # Add technical indicators (for additional features)\n","    df['ema200'] = pd.Series.ewm(df['Mid_Close'], span=200).mean()\n","    df['ema100'] = pd.Series.ewm(df['Mid_Close'], span=100).mean()\n","    # df['ema50'] = pd.Series.ewm(df['Mid_Close'], span=50).mean()\n","\n","    df['atr'] = atr(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","    df['atr_sma'] = df['atr'].rolling(window=20).mean()\n","    df['rsi'] = rsi(df['Mid_Close'])\n","    df['rsi_sma'] = df['rsi'].rolling(50).mean()\n","    df['adx'] = adx(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","    df['macd'] = pd.Series.ewm(df['Mid_Close'], span=12).mean() - pd.Series.ewm(df['Mid_Close'], span=26).mean()\n","    df['macdsignal'] = pd.Series.ewm(df['macd'], span=9).mean()\n","    df['slowk_rsi'], df['slowd_rsi'] = stoch_rsi(df['rsi'])\n","\n","    df['vo'] = vo(df['Volume'])\n","\n","    df['willy'], df['willy_ema'] = williams_r(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","\n","    df['squeeze_on'] = squeeze(df)\n","\n","    df.dropna(inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","    # Extract the bid and ask prices and fractals and remove them from the df\n","    bid_ask_mid_prices = df[['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close']]\n","    df.drop(['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume'], axis=1, inplace=True)\n","    bid_ask_mid_prices_list.append(bid_ask_mid_prices)\n","\n","    df.dropna(inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","for df_long in df_longs:\n","    df_long['ema200'] = pd.Series.ewm(df_long['Mid_Close'], span=200).mean()\n","    df_long['ema100'] = pd.Series.ewm(df_long['Mid_Close'], span=100).mean()\n","    # df_long['ema50'] = pd.Series.ewm(df_long['Mid_Close'], span=50).mean()\n","\n","    df_long['atr'] = atr(df_long['Mid_High'], df_long['Mid_Low'], df_long['Mid_Close'])\n","    df_long['atr_sma'] = df_long['atr'].rolling(window=20).mean()\n","    df_long['rsi'] = rsi(df_long['Mid_Close'])\n","    df_long['rsi_sma'] = df_long['rsi'].rolling(50).mean()\n","    df_long['adx'] = adx(df_long['Mid_High'], df_long['Mid_Low'], df_long['Mid_Close'])\n","    df_long['macd'] = pd.Series.ewm(df_long['Mid_Close'], span=12).mean() - pd.Series.ewm(df_long['Mid_Close'], span=26).mean()\n","    df_long['macdsignal'] = pd.Series.ewm(df_long['macd'], span=9).mean()\n","    df_long['slowk_rsi'], df_long['slowd_rsi'] = stoch_rsi(df_long['rsi'])\n","\n","    df_long['vo'] = vo(df_long['Volume'])\n","\n","    df_long['willy'], df_long['willy_ema'] = williams_r(df_long['Mid_High'], df_long['Mid_Low'], df_long['Mid_Close'])\n","\n","    df_long['squeeze_on'] = squeeze(df_long)\n","\n","    df_long.dropna(inplace=True)\n","    df_long.reset_index(drop=True, inplace=True)\n","\n","    df_long.drop(['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume'], axis=1, inplace=True)\n","\n","    df_long.dropna(inplace=True)\n","    df_long.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"Qp5VKTj7ujLO"},"outputs":[],"source":["look_back_size = 50"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RUNNING SIMULATION FOR Gbp_Usd...\n","2016\n","Buys: 0\n","Sells: 0\n","Nones: 0\n","\n","2017\n","Buys: 2981\n","Sells: 3200\n","Nones: 10271\n","\n","2018\n","Buys: 5310\n","Sells: 5272\n","Nones: 18428\n","\n","2019\n","Buys: 7778\n","Sells: 8086\n","Nones: 27251\n","\n","2020\n","Buys: 10011\n","Sells: 10655\n","Nones: 35047\n","\n","2021\n","Buys: 13907\n","Sells: 14032\n","Nones: 46454\n","\n","Buys: 16337\n","Sells: 16696\n","Nones: 55650\n","\n"]}],"source":["buys_list = []\n","sells_list = []\n","nones_list = []\n","\n","value_per_pip = 1.0\n","amounts_per_day = [-0.00008, -0.0001, -0.00012]\n","spread_cutoff = 0.10\n","risk_reward_ratio = 1.5\n","\n","def get_n_units(trade_type, stop_loss, ask_open, bid_open, mid_open, currency_pair):\n","    _, second = currency_pair.split('_')\n","  \n","    pips_to_risk = ask_open - stop_loss if trade_type == 'buy' else stop_loss - bid_open\n","    pips_to_risk_calc = pips_to_risk * 10000 if second != 'Jpy' else pips_to_risk * 100\n","\n","    if second == 'Usd':\n","        per_pip = 0.0001\n","\n","    else:\n","        per_pip = 0.0001 / mid_open if second != 'Jpy' else 0.01 / mid_open\n","\n","    n_units = int(50 / (pips_to_risk_calc * per_pip))\n","\n","    return n_units\n","\n","def calculate_day_fees(start_date, end_date, n_units):\n","    curr_fee = np.random.choice(amounts_per_day, p=[0.25, 0.50, 0.25]) * n_units\n","    num_days = np.busday_count(start_date.date(), end_date.date())\n","\n","    return num_days * curr_fee\n","\n","for idx in range(len(currencies)):\n","    currency_pair, df, df_long, bid_ask_mid_prices = currencies[idx], dfs[idx], df_longs[idx], bid_ask_mid_prices_list[idx]\n","    rounding = 3 if 'Jpy' in currency_pair else 5\n","    buys, sells, nones = [], [], []\n","    trade, prev_year = None, None\n","\n","    print(f'RUNNING SIMULATION FOR {currency_pair}...')\n","\n","    for i in range(look_back_size, len(df)):\n","        curr_date = df.loc[df.index[i], 'Date']\n","        if prev_year is None or curr_date.year > prev_year:\n","            prev_year = curr_date.year\n","            print(prev_year)\n","            print(f'Buys: {len(buys)}')\n","            print(f'Sells: {len(sells)}')\n","            print(f'Nones: {len(nones)}\\n')\n","        curr_long = df_long.loc[df_long['Date'] < curr_date]\n","        if len(curr_long) < look_back_size + 1:\n","            continue\n","        ema200_2, ema100_2, atr2, rsi2, rsi_sma2, vo2, macd2, macdsignal2 = df.loc[df.index[i - 2], ['ema200', 'ema100', 'atr', 'rsi', 'rsi_sma', 'vo', 'macd', 'macdsignal']]\n","        ema200_1, ema100_1, atr1, rsi1, rsi_sma1, vo1, adx1, atr_sma1, macd1, macdsignal1 = df.loc[df.index[i - 1], ['ema200', 'ema100', 'atr', 'rsi', 'rsi_sma', 'vo', 'adx', 'atr_sma', 'macd', 'macdsignal']]\n","        mid_open2, mid_close2, mid_low2, mid_high2 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 2], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","        mid_open1, mid_close1, mid_low1, mid_high1 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 1], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","        curr_ao, curr_bo, curr_mid_open, curr_ask_low, curr_bid_high = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i], ['Ask_Open', 'Bid_Open', 'Mid_Open', 'Ask_Low', 'Bid_High']]\n","        spread = abs(curr_ao - curr_bo)\n","\n","        emas_buy_signal = ema200_1 < ema100_1\n","        emas_sell_signal = ema200_1 > ema100_1\n","\n","        if trade is None:\n","            if emas_buy_signal:\n","                lowest_low = min(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_Low']))\n","                \n","                open_price = float(curr_ao)\n","                pullback = float(lowest_low) - spread\n","\n","                stop_loss = round(pullback, rounding)\n","\n","                if stop_loss < open_price:\n","                    curr_pips_to_risk = open_price - stop_loss\n","\n","                    if spread <= curr_pips_to_risk * spread_cutoff:\n","                        stop_gain = round(open_price + (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","                        n_units = get_n_units('buy', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","                        trade = {'open_price': open_price, 'trade_type': 'buy', 'stop_loss': stop_loss,\n","                                                        'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","                                                        'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","            elif emas_sell_signal:\n","                highest_high = max(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_High']))\n","\n","                open_price = float(curr_bo)\n","                pullback = float(highest_high) + spread\n","\n","                stop_loss = round(pullback, rounding)\n","\n","                if stop_loss > open_price:\n","                    curr_pips_to_risk = stop_loss - open_price\n","\n","                    if spread <= curr_pips_to_risk * spread_cutoff:\n","                        stop_gain = round(open_price - (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","                        n_units = get_n_units('sell', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","                        trade = {'open_price': open_price, 'trade_type': 'sell', 'stop_loss': stop_loss,\n","                                'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","                                'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","        if trade is not None:\n","            for j in range(i, len(df)):\n","                curr_date = df.loc[df.index[j], 'Date']\n","                curr_bid_open, curr_bid_high, curr_bid_low, curr_bid_close, curr_ask_open, curr_ask_high, curr_ask_low, curr_ask_close = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[j], ['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close']]\n","\n","                if trade['trade_type'] == 'buy' and curr_bid_low <= trade['stop_loss']:\n","                    nones.append(trade['start_date']) \n","\n","                    trade = None\n","                    break\n","\n","\n","                if trade['trade_type'] == 'buy' and curr_bid_high >= trade['stop_gain']:\n","                    trade_amount = (trade['stop_gain'] - trade['open_price']) * trade['n_units'] * value_per_pip\n","                    day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","                    if trade_amount + day_fees > 0:\n","                        buys.append(trade['start_date'])\n","\n","                    trade = None\n","                    break\n","\n","                if trade['trade_type'] == 'sell' and curr_ask_high >= trade['stop_loss']:\n","                    nones.append(trade['start_date'])\n","\n","                    trade = None\n","                    break\n","\n","                if trade['trade_type'] == 'sell' and curr_ask_low <= trade['stop_gain']:\n","                    trade_amount = (trade['open_price'] - trade['stop_gain']) * trade['n_units'] * value_per_pip\n","                    day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","                    if trade_amount + day_fees > 0:\n","                        sells.append(trade['start_date'])\n","\n","                    trade = None\n","                    break\n","    \n","    buys_list.append(buys)\n","    sells_list.append(sells)\n","    nones_list.append(nones)\n","\n","    print(f'Buys: {len(buys)}')\n","    print(f'Sells: {len(sells)}')\n","    print(f'Nones: {len(nones)}\\n')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2722\n","2722\n","2722\n"]}],"source":["buy_indices_list = []\n","sell_indices_list = []\n","nones_indices_list = []\n","size = 1 / 6\n","\n","for i in range(len(dfs)):\n","    buys, sells, nones, df = buys_list[i], sells_list[i], nones_list[i], dfs[i]\n","    \n","    buy_indices = [df.index[df['Date'] == curr_date] - 1 for curr_date in buys]\n","    sell_indices = [df.index[df['Date'] == curr_date] - 1 for curr_date in sells]\n","    nones_indices = [df.index[df['Date'] == curr_date] - 1 for curr_date in nones]\n","\n","    np.random.shuffle(buy_indices)\n","    np.random.shuffle(sell_indices)\n","    np.random.shuffle(nones_indices)\n","\n","    lower = min(len(buy_indices), len(sell_indices), len(nones_indices))\n","    lower = int(lower * size)\n","\n","    buy_indices = buy_indices[:lower]\n","    sell_indices = sell_indices[:lower]\n","    nones_indices = nones_indices[:lower]\n","\n","    buy_indices_list.append(buy_indices)\n","    sell_indices_list.append(sell_indices)\n","    nones_indices_list.append(nones_indices)\n","\n","    print(len(buy_indices))\n","    print(len(sell_indices))\n","    print(len(nones_indices))"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["for df in dfs:\n","    df.drop('Date', axis=1, inplace=True)\n","    df['squeeze_on'] = df['squeeze_on'].astype(float)"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["scalers, pcas = {}, {}\n","explained_variance = 0.99\n","\n","for i in range(len(dfs)):\n","    currency_pair, df = currencies[i], dfs[i]\n","\n","    scaler = StandardScaler()\n","\n","    dfs[i] = scaler.fit_transform(df)\n","\n","    scalers[currency_pair] = scaler"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/plain":["(50, 17)"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["correct_shape = (look_back_size, dfs[0].shape[1])\n","correct_shape"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"Hqy2dig_7e-F"},"outputs":[],"source":["def get_sequential_data():\n","    no_actions = []\n","    buys = []\n","    sells = []\n","\n","    for z in range(len(dfs)):\n","        print(currencies[z])\n","        df = dfs[z]\n","\n","        buy_indices, sell_indices, nones_indices = buy_indices_list[z], sell_indices_list[z], nones_indices_list[z]\n","\n","        for i in buy_indices:\n","            if len(i) == 1:\n","                i = i[0]\n","                seq = df[i - look_back_size + 1:i + 1, :]\n","                assert seq.shape == correct_shape\n","                buys.append([seq, np.array([0, 1, 0])])\n","\n","        for i in sell_indices:\n","            if len(i) == 1:\n","                i = i[0]\n","                seq = df[i - look_back_size + 1:i + 1, :]\n","                assert seq.shape == correct_shape\n","                sells.append([seq, np.array([0, 0, 1])])\n","\n","        for i in nones_indices:\n","            if len(i) == 1:\n","                i = i[0]\n","                seq = df[i - look_back_size + 1:i + 1, :]\n","                assert seq.shape == correct_shape\n","                no_actions.append([seq, np.array([1, 0, 0])])\n","\n","    np.random.shuffle(no_actions)\n","    np.random.shuffle(buys)\n","    np.random.shuffle(sells)\n","\n","    sequential_data = no_actions + buys + sells\n","    np.random.shuffle(sequential_data)\n","\n","    return sequential_data"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"gk8jS65z7i5q"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gbp_Usd\n"]}],"source":["sequential_data = get_sequential_data()"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"data":{"text/plain":["8166"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["len(sequential_data)"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1631924931206,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":360},"id":"cdYAzLkF5PO5","outputId":"9e5842f8-8004-4914-a05c-2a56353f39c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset shapes:\n","5716\n","2450\n"]}],"source":["training_proportion = 0.70\n","train_test_cutoff_index = int(len(sequential_data) * training_proportion)\n","\n","train_set = sequential_data[0:train_test_cutoff_index]\n","test_set = sequential_data[train_test_cutoff_index:]\n","\n","print('Dataset shapes:')\n","print(len(train_set))\n","print(len(test_set))"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"wLRUg-ekVUtL"},"outputs":[],"source":["x_train = []\n","y_train = []\n","\n","for seq, target in train_set:\n","  x_train.append(seq)\n","  y_train.append(target)\n","\n","x_test = []\n","y_test = []\n","\n","for seq, target in test_set:\n","  x_test.append(seq)\n","  y_test.append(target)\n","\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)\n","x_test = np.array(x_test)\n","y_test = np.array(y_test)\n","\n","x_train, x_test = x_train.astype(float), x_test.astype(float)"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1631924983918,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":360},"id":"D3_lj-U3NGM2","outputId":"ce1b1761-9bb2-4afc-c7c5-eca2ac8cde79"},"outputs":[{"data":{"text/plain":["(5716, 50, 17)"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"data":{"text/plain":["(5716, 3)"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["y_train.shape"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"gWXFnbrFEQ9A"},"outputs":[],"source":["# # Number of possible actions to take - determines the output dimension of the\n","# #  neural network\n","# n_actions = 3\n","# input_data_shape = x_train.shape[1:]\n","\n","# model = Sequential()\n","\n","# model.add(Conv2D(filters = 32, kernel_size = (3,3), padding ='Same', activation ='relu', input_shape = input_data_shape))\n","# model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n","\n","# model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","# model.add(Dropout(0.25))\n","\n","# model.add(Flatten())\n","# model.add(Dense(128, activation = \"relu\"))\n","# model.add(Dropout(0.5))\n","# model.add(Dense(n_actions, activation = \"softmax\"))\n","\n","n_actions = 3\n","input_data_shape = x_train.shape[1:]\n","\n","model = Sequential()\n","\n","model.add(GRU(256, return_sequences=True, input_shape=input_data_shape))\n","# model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n","\n","model.add(GRU(256, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n","\n","model.add(GRU(256, return_sequences=True))\n","# model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n","\n","model.add(GRU(256, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n","\n","model.add(GRU(256))\n","# model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n","\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.25))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(n_actions, activation='softmax'))"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"YzWCOxnCECEl"},"outputs":[],"source":["# Hyperparameters\n","n_epochs = 300\n","batch_size = 32\n","n_steps = len(x_train) // batch_size \n","mean_loss = tf.keras.metrics.Mean() \n","optimizer = tf.keras.optimizers.Adam()\n","loss_fn = tf.keras.losses.categorical_crossentropy\n","metrics = [tf.keras.metrics.CategoricalAccuracy()]\n","# loss_fn = tf.keras.losses.MeanAbsoluteError\n","# metrics = [tf.keras.metrics.MeanAbsoluteError()]"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["early_stop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=n_epochs)\n","model_checkpoint = ModelCheckpoint('/Users/mymac/test_rnn', monitor='val_accuracy', save_best_only=True, verbose=1)\n","\n","optimizer = Adam()\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60729,"status":"ok","timestamp":1631925055308,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":360},"id":"NRG4mIMcq5_f","outputId":"eb40bd91-3efc-495f-a4a0-8545eab20758"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/300\n","179/179 [==============================] - ETA: 0s - loss: 0.9987 - accuracy: 0.4983\n","Epoch 00001: val_accuracy improved from -inf to 0.59878, saving model to /Users/mymac/test_rnn\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses, gru_cell_22_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e34fa90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e6dbc40> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16dbcad60> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e4b0a00> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e3e5820> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"name":"stdout","output_type":"stream","text":["179/179 [==============================] - 30s 146ms/step - loss: 0.9987 - accuracy: 0.4983 - val_loss: 0.8589 - val_accuracy: 0.5988\n","Epoch 2/300\n","179/179 [==============================] - ETA: 0s - loss: 0.8395 - accuracy: 0.5765\n","Epoch 00002: val_accuracy improved from 0.59878 to 0.63306, saving model to /Users/mymac/test_rnn\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses, gru_cell_22_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e34fa90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e6dbc40> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16dbcad60> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e4b0a00> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e3e5820> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"name":"stdout","output_type":"stream","text":["179/179 [==============================] - 24s 136ms/step - loss: 0.8395 - accuracy: 0.5765 - val_loss: 0.7608 - val_accuracy: 0.6331\n","Epoch 3/300\n","179/179 [==============================] - ETA: 0s - loss: 0.8022 - accuracy: 0.5941\n","Epoch 00003: val_accuracy did not improve from 0.63306\n","179/179 [==============================] - 19s 105ms/step - loss: 0.8022 - accuracy: 0.5941 - val_loss: 0.7616 - val_accuracy: 0.6306\n","Epoch 4/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7881 - accuracy: 0.5994\n","Epoch 00004: val_accuracy did not improve from 0.63306\n","179/179 [==============================] - 19s 106ms/step - loss: 0.7881 - accuracy: 0.5994 - val_loss: 0.7635 - val_accuracy: 0.6208\n","Epoch 5/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7661 - accuracy: 0.6144\n","Epoch 00005: val_accuracy did not improve from 0.63306\n","179/179 [==============================] - 19s 105ms/step - loss: 0.7661 - accuracy: 0.6144 - val_loss: 0.7567 - val_accuracy: 0.6216\n","Epoch 6/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7570 - accuracy: 0.6167\n","Epoch 00006: val_accuracy improved from 0.63306 to 0.64735, saving model to /Users/mymac/test_rnn\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses, gru_cell_22_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e34fa90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e6dbc40> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16dbcad60> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e4b0a00> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e3e5820> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"name":"stdout","output_type":"stream","text":["179/179 [==============================] - 24s 137ms/step - loss: 0.7570 - accuracy: 0.6167 - val_loss: 0.7164 - val_accuracy: 0.6473\n","Epoch 7/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7497 - accuracy: 0.6232\n","Epoch 00007: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7497 - accuracy: 0.6232 - val_loss: 0.7318 - val_accuracy: 0.6376\n","Epoch 8/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7439 - accuracy: 0.6251\n","Epoch 00008: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 19s 106ms/step - loss: 0.7439 - accuracy: 0.6251 - val_loss: 0.7209 - val_accuracy: 0.6429\n","Epoch 9/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7382 - accuracy: 0.6251\n","Epoch 00009: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 19s 109ms/step - loss: 0.7382 - accuracy: 0.6251 - val_loss: 0.7450 - val_accuracy: 0.6359\n","Epoch 10/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7617 - accuracy: 0.6163\n","Epoch 00010: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7617 - accuracy: 0.6163 - val_loss: 0.7429 - val_accuracy: 0.6424\n","Epoch 11/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7436 - accuracy: 0.6247\n","Epoch 00011: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7436 - accuracy: 0.6247 - val_loss: 0.7384 - val_accuracy: 0.6465\n","Epoch 12/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7834 - accuracy: 0.6109\n","Epoch 00012: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7834 - accuracy: 0.6109 - val_loss: 0.7327 - val_accuracy: 0.6384\n","Epoch 13/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7625 - accuracy: 0.6202\n","Epoch 00013: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 19s 107ms/step - loss: 0.7625 - accuracy: 0.6202 - val_loss: 0.7531 - val_accuracy: 0.6376\n","Epoch 14/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7488 - accuracy: 0.6246\n","Epoch 00014: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7488 - accuracy: 0.6246 - val_loss: 0.7169 - val_accuracy: 0.6469\n","Epoch 15/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7473 - accuracy: 0.6244\n","Epoch 00015: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7473 - accuracy: 0.6244 - val_loss: 0.8007 - val_accuracy: 0.6131\n","Epoch 16/300\n","179/179 [==============================] - ETA: 0s - loss: 0.8005 - accuracy: 0.6029\n","Epoch 00016: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 19s 107ms/step - loss: 0.8005 - accuracy: 0.6029 - val_loss: 0.7729 - val_accuracy: 0.6335\n","Epoch 17/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7814 - accuracy: 0.6127\n","Epoch 00017: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7814 - accuracy: 0.6127 - val_loss: 0.7601 - val_accuracy: 0.6286\n","Epoch 18/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7827 - accuracy: 0.6085\n","Epoch 00018: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7827 - accuracy: 0.6085 - val_loss: 0.8397 - val_accuracy: 0.5910\n","Epoch 19/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7711 - accuracy: 0.6141\n","Epoch 00019: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7711 - accuracy: 0.6141 - val_loss: 0.7625 - val_accuracy: 0.6363\n","Epoch 20/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7634 - accuracy: 0.6177\n","Epoch 00020: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7634 - accuracy: 0.6177 - val_loss: 0.7984 - val_accuracy: 0.6127\n","Epoch 21/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7701 - accuracy: 0.6128\n","Epoch 00021: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7701 - accuracy: 0.6128 - val_loss: 0.7443 - val_accuracy: 0.6367\n","Epoch 22/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7547 - accuracy: 0.6200\n","Epoch 00022: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7547 - accuracy: 0.6200 - val_loss: 0.7685 - val_accuracy: 0.6245\n","Epoch 23/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7437 - accuracy: 0.6242\n","Epoch 00023: val_accuracy did not improve from 0.64735\n","179/179 [==============================] - 20s 111ms/step - loss: 0.7437 - accuracy: 0.6242 - val_loss: 0.7232 - val_accuracy: 0.6433\n","Epoch 24/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7469 - accuracy: 0.6207\n","Epoch 00024: val_accuracy improved from 0.64735 to 0.65102, saving model to /Users/mymac/test_rnn\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses, gru_cell_22_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e34fa90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e6dbc40> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16dbcad60> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e4b0a00> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e3e5820> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"name":"stdout","output_type":"stream","text":["179/179 [==============================] - 25s 141ms/step - loss: 0.7469 - accuracy: 0.6207 - val_loss: 0.7235 - val_accuracy: 0.6510\n","Epoch 25/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7503 - accuracy: 0.6239\n","Epoch 00025: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7503 - accuracy: 0.6239 - val_loss: 0.7347 - val_accuracy: 0.6380\n","Epoch 26/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7758 - accuracy: 0.6128\n","Epoch 00026: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7758 - accuracy: 0.6128 - val_loss: 0.7565 - val_accuracy: 0.6327\n","Epoch 27/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7676 - accuracy: 0.6127\n","Epoch 00027: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7676 - accuracy: 0.6127 - val_loss: 0.7442 - val_accuracy: 0.6400\n","Epoch 28/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7638 - accuracy: 0.6165\n","Epoch 00028: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 19s 109ms/step - loss: 0.7638 - accuracy: 0.6165 - val_loss: 0.7330 - val_accuracy: 0.6396\n","Epoch 29/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7585 - accuracy: 0.6181\n","Epoch 00029: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7585 - accuracy: 0.6181 - val_loss: 0.7488 - val_accuracy: 0.6294\n","Epoch 30/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7681 - accuracy: 0.6176\n","Epoch 00030: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7681 - accuracy: 0.6176 - val_loss: 0.7743 - val_accuracy: 0.6257\n","Epoch 31/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7532 - accuracy: 0.6177\n","Epoch 00031: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 19s 109ms/step - loss: 0.7532 - accuracy: 0.6177 - val_loss: 0.7291 - val_accuracy: 0.6437\n","Epoch 32/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7462 - accuracy: 0.6260\n","Epoch 00032: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7462 - accuracy: 0.6260 - val_loss: 0.7139 - val_accuracy: 0.6494\n","Epoch 33/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7433 - accuracy: 0.6282\n","Epoch 00033: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7433 - accuracy: 0.6282 - val_loss: 0.7322 - val_accuracy: 0.6380\n","Epoch 34/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7460 - accuracy: 0.6244\n","Epoch 00034: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7460 - accuracy: 0.6244 - val_loss: 0.7183 - val_accuracy: 0.6498\n","Epoch 35/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7410 - accuracy: 0.6258\n","Epoch 00035: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 20s 111ms/step - loss: 0.7410 - accuracy: 0.6258 - val_loss: 0.7293 - val_accuracy: 0.6347\n","Epoch 36/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7424 - accuracy: 0.6272\n","Epoch 00036: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7424 - accuracy: 0.6272 - val_loss: 0.7215 - val_accuracy: 0.6469\n","Epoch 37/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.6286\n","Epoch 00037: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7323 - accuracy: 0.6286 - val_loss: 0.7081 - val_accuracy: 0.6461\n","Epoch 38/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7342 - accuracy: 0.6288\n","Epoch 00038: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7342 - accuracy: 0.6288 - val_loss: 0.7214 - val_accuracy: 0.6441\n","Epoch 39/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7326 - accuracy: 0.6298\n","Epoch 00039: val_accuracy did not improve from 0.65102\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7326 - accuracy: 0.6298 - val_loss: 0.7403 - val_accuracy: 0.6367\n","Epoch 40/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7465 - accuracy: 0.6244\n","Epoch 00040: val_accuracy improved from 0.65102 to 0.65184, saving model to /Users/mymac/test_rnn\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses, gru_cell_22_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e34fa90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e6dbc40> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16dbcad60> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e4b0a00> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e3e5820> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"name":"stdout","output_type":"stream","text":["179/179 [==============================] - 25s 141ms/step - loss: 0.7465 - accuracy: 0.6244 - val_loss: 0.7177 - val_accuracy: 0.6518\n","Epoch 41/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7262 - accuracy: 0.6309\n","Epoch 00041: val_accuracy did not improve from 0.65184\n","179/179 [==============================] - 19s 107ms/step - loss: 0.7262 - accuracy: 0.6309 - val_loss: 0.7192 - val_accuracy: 0.6420\n","Epoch 42/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7317 - accuracy: 0.6261\n","Epoch 00042: val_accuracy did not improve from 0.65184\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7317 - accuracy: 0.6261 - val_loss: 0.7203 - val_accuracy: 0.6469\n","Epoch 43/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7294 - accuracy: 0.6296\n","Epoch 00043: val_accuracy did not improve from 0.65184\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7294 - accuracy: 0.6296 - val_loss: 0.7405 - val_accuracy: 0.6404\n","Epoch 44/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7336 - accuracy: 0.6289\n","Epoch 00044: val_accuracy did not improve from 0.65184\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7336 - accuracy: 0.6289 - val_loss: 0.7211 - val_accuracy: 0.6490\n","Epoch 45/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7415 - accuracy: 0.6277\n","Epoch 00045: val_accuracy improved from 0.65184 to 0.65551, saving model to /Users/mymac/test_rnn\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_20_layer_call_fn, gru_cell_20_layer_call_and_return_conditional_losses, gru_cell_21_layer_call_fn, gru_cell_21_layer_call_and_return_conditional_losses, gru_cell_22_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/mymac/test_rnn/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e34fa90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e6dbc40> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16dbcad60> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e4b0a00> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x16e3e5820> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"name":"stdout","output_type":"stream","text":["179/179 [==============================] - 25s 140ms/step - loss: 0.7415 - accuracy: 0.6277 - val_loss: 0.7137 - val_accuracy: 0.6555\n","Epoch 46/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7310 - accuracy: 0.6286\n","Epoch 00046: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7310 - accuracy: 0.6286 - val_loss: 0.7100 - val_accuracy: 0.6506\n","Epoch 47/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7350 - accuracy: 0.6268\n","Epoch 00047: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 111ms/step - loss: 0.7350 - accuracy: 0.6268 - val_loss: 0.7219 - val_accuracy: 0.6461\n","Epoch 48/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7286 - accuracy: 0.6284\n","Epoch 00048: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7286 - accuracy: 0.6284 - val_loss: 0.7088 - val_accuracy: 0.6518\n","Epoch 49/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7281 - accuracy: 0.6298\n","Epoch 00049: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7281 - accuracy: 0.6298 - val_loss: 0.7080 - val_accuracy: 0.6518\n","Epoch 50/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7313 - accuracy: 0.6310\n","Epoch 00050: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7313 - accuracy: 0.6310 - val_loss: 0.7135 - val_accuracy: 0.6514\n","Epoch 51/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7267 - accuracy: 0.6328\n","Epoch 00051: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 109ms/step - loss: 0.7267 - accuracy: 0.6328 - val_loss: 0.7065 - val_accuracy: 0.6539\n","Epoch 52/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7263 - accuracy: 0.6289\n","Epoch 00052: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 109ms/step - loss: 0.7263 - accuracy: 0.6289 - val_loss: 0.7117 - val_accuracy: 0.6469\n","Epoch 53/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7261 - accuracy: 0.6317\n","Epoch 00053: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7261 - accuracy: 0.6317 - val_loss: 0.7300 - val_accuracy: 0.6465\n","Epoch 54/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.6328\n","Epoch 00054: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7246 - accuracy: 0.6328 - val_loss: 0.7155 - val_accuracy: 0.6469\n","Epoch 55/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7297 - accuracy: 0.6293\n","Epoch 00055: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7297 - accuracy: 0.6293 - val_loss: 0.7193 - val_accuracy: 0.6465\n","Epoch 56/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7329 - accuracy: 0.6275\n","Epoch 00056: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7329 - accuracy: 0.6275 - val_loss: 0.7236 - val_accuracy: 0.6482\n","Epoch 57/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7264 - accuracy: 0.6321\n","Epoch 00057: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7264 - accuracy: 0.6321 - val_loss: 0.7140 - val_accuracy: 0.6486\n","Epoch 58/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7321 - accuracy: 0.6279\n","Epoch 00058: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 109ms/step - loss: 0.7321 - accuracy: 0.6279 - val_loss: 0.7224 - val_accuracy: 0.6473\n","Epoch 59/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7322 - accuracy: 0.6282\n","Epoch 00059: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7322 - accuracy: 0.6282 - val_loss: 0.7342 - val_accuracy: 0.6424\n","Epoch 60/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7378 - accuracy: 0.6246\n","Epoch 00060: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7378 - accuracy: 0.6246 - val_loss: 0.7398 - val_accuracy: 0.6416\n","Epoch 61/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7373 - accuracy: 0.6246\n","Epoch 00061: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 113ms/step - loss: 0.7373 - accuracy: 0.6246 - val_loss: 0.7140 - val_accuracy: 0.6461\n","Epoch 62/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7342 - accuracy: 0.6275\n","Epoch 00062: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7342 - accuracy: 0.6275 - val_loss: 0.7295 - val_accuracy: 0.6449\n","Epoch 63/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7381 - accuracy: 0.6274\n","Epoch 00063: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 111ms/step - loss: 0.7381 - accuracy: 0.6274 - val_loss: 0.7203 - val_accuracy: 0.6510\n","Epoch 64/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7295 - accuracy: 0.6286\n","Epoch 00064: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7295 - accuracy: 0.6286 - val_loss: 0.7122 - val_accuracy: 0.6510\n","Epoch 65/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7318 - accuracy: 0.6270\n","Epoch 00065: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7318 - accuracy: 0.6270 - val_loss: 0.7200 - val_accuracy: 0.6445\n","Epoch 66/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7452 - accuracy: 0.6232\n","Epoch 00066: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7452 - accuracy: 0.6232 - val_loss: 0.7434 - val_accuracy: 0.6343\n","Epoch 67/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7378 - accuracy: 0.6268\n","Epoch 00067: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 111ms/step - loss: 0.7378 - accuracy: 0.6268 - val_loss: 0.7218 - val_accuracy: 0.6445\n","Epoch 68/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7364 - accuracy: 0.6282\n","Epoch 00068: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7364 - accuracy: 0.6282 - val_loss: 0.7397 - val_accuracy: 0.6469\n","Epoch 69/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7693 - accuracy: 0.6163\n","Epoch 00069: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7693 - accuracy: 0.6163 - val_loss: 0.7783 - val_accuracy: 0.6229\n","Epoch 70/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7680 - accuracy: 0.6149\n","Epoch 00070: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7680 - accuracy: 0.6149 - val_loss: 0.7516 - val_accuracy: 0.6335\n","Epoch 71/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7755 - accuracy: 0.6118\n","Epoch 00071: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7755 - accuracy: 0.6118 - val_loss: 0.7684 - val_accuracy: 0.6224\n","Epoch 72/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7647 - accuracy: 0.6155\n","Epoch 00072: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7647 - accuracy: 0.6155 - val_loss: 0.7596 - val_accuracy: 0.6351\n","Epoch 73/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7976 - accuracy: 0.5995\n","Epoch 00073: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 109ms/step - loss: 0.7976 - accuracy: 0.5995 - val_loss: 0.8198 - val_accuracy: 0.6037\n","Epoch 74/300\n","179/179 [==============================] - ETA: 0s - loss: 0.8119 - accuracy: 0.5978\n","Epoch 00074: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 108ms/step - loss: 0.8119 - accuracy: 0.5978 - val_loss: 0.8062 - val_accuracy: 0.6098\n","Epoch 75/300\n","179/179 [==============================] - ETA: 0s - loss: 0.8439 - accuracy: 0.5791\n","Epoch 00075: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 107ms/step - loss: 0.8439 - accuracy: 0.5791 - val_loss: 0.8188 - val_accuracy: 0.6057\n","Epoch 76/300\n","179/179 [==============================] - ETA: 0s - loss: 0.8167 - accuracy: 0.5957\n","Epoch 00076: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 109ms/step - loss: 0.8167 - accuracy: 0.5957 - val_loss: 0.7796 - val_accuracy: 0.6188\n","Epoch 77/300\n","179/179 [==============================] - ETA: 0s - loss: 0.8019 - accuracy: 0.6013\n","Epoch 00077: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 111ms/step - loss: 0.8019 - accuracy: 0.6013 - val_loss: 0.7747 - val_accuracy: 0.6261\n","Epoch 78/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7823 - accuracy: 0.6076\n","Epoch 00078: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7823 - accuracy: 0.6076 - val_loss: 0.7628 - val_accuracy: 0.6314\n","Epoch 79/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7775 - accuracy: 0.6102\n","Epoch 00079: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7775 - accuracy: 0.6102 - val_loss: 0.7633 - val_accuracy: 0.6310\n","Epoch 80/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7781 - accuracy: 0.6130\n","Epoch 00080: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 107ms/step - loss: 0.7781 - accuracy: 0.6130 - val_loss: 0.7605 - val_accuracy: 0.6322\n","Epoch 81/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7678 - accuracy: 0.6132\n","Epoch 00081: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 109ms/step - loss: 0.7678 - accuracy: 0.6132 - val_loss: 0.7615 - val_accuracy: 0.6331\n","Epoch 82/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7702 - accuracy: 0.6100\n","Epoch 00082: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7702 - accuracy: 0.6100 - val_loss: 0.7774 - val_accuracy: 0.6343\n","Epoch 83/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7836 - accuracy: 0.6079\n","Epoch 00083: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 109ms/step - loss: 0.7836 - accuracy: 0.6079 - val_loss: 0.7706 - val_accuracy: 0.6294\n","Epoch 84/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7685 - accuracy: 0.6130\n","Epoch 00084: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7685 - accuracy: 0.6130 - val_loss: 0.7637 - val_accuracy: 0.6282\n","Epoch 85/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7676 - accuracy: 0.6153\n","Epoch 00085: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7676 - accuracy: 0.6153 - val_loss: 0.7558 - val_accuracy: 0.6302\n","Epoch 86/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7622 - accuracy: 0.6135\n","Epoch 00086: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 110ms/step - loss: 0.7622 - accuracy: 0.6135 - val_loss: 0.7492 - val_accuracy: 0.6392\n","Epoch 87/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7567 - accuracy: 0.6177\n","Epoch 00087: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7567 - accuracy: 0.6177 - val_loss: 0.7528 - val_accuracy: 0.6355\n","Epoch 88/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7527 - accuracy: 0.6237\n","Epoch 00088: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 20s 109ms/step - loss: 0.7527 - accuracy: 0.6237 - val_loss: 0.7445 - val_accuracy: 0.6335\n","Epoch 89/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7531 - accuracy: 0.6190\n","Epoch 00089: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7531 - accuracy: 0.6190 - val_loss: 0.7474 - val_accuracy: 0.6371\n","Epoch 90/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7617 - accuracy: 0.6156\n","Epoch 00090: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 107ms/step - loss: 0.7617 - accuracy: 0.6156 - val_loss: 0.7416 - val_accuracy: 0.6408\n","Epoch 91/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7613 - accuracy: 0.6163\n","Epoch 00091: val_accuracy did not improve from 0.65551\n","179/179 [==============================] - 19s 108ms/step - loss: 0.7613 - accuracy: 0.6163 - val_loss: 0.7602 - val_accuracy: 0.6331\n","Epoch 92/300\n","115/179 [==================>...........] - ETA: 5s - loss: 0.7726 - accuracy: 0.6120"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-85-7af7dcac3212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["history = model.fit(\n","    x_train, y_train,\n","    batch_size=batch_size,\n","    epochs=n_epochs,\n","    validation_data=(x_test, y_test),\n","    callbacks=[early_stop, model_checkpoint]\n",")"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["model = load_model('/Users/mymac/test_rnn')"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["df = pd.read_csv(file_path + 'Oanda_Gbp_Usd_M5_2021-2022.csv')\n","df.Date = pd.to_datetime(df.Date)\n","df.dropna(inplace=True)\n","df.reset_index(drop=True, inplace=True)\n","\n","df['sin_hour'] = np.sin(2 * np.pi * df['Date'].dt.hour / 24)\n","df['sin_day'] = np.sin(2 * np.pi * df['Date'].dt.day / 7)\n","\n","# Add technical indicators (for additional features)\n","df['ema200'] = pd.Series.ewm(df['Mid_Close'], span=200).mean()\n","df['ema100'] = pd.Series.ewm(df['Mid_Close'], span=100).mean()\n","# df['ema50'] = pd.Series.ewm(df['Mid_Close'], span=50).mean()\n","\n","df['atr'] = atr(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","df['atr_sma'] = df['atr'].rolling(window=20).mean()\n","df['rsi'] = rsi(df['Mid_Close'])\n","df['rsi_sma'] = df['rsi'].rolling(50).mean()\n","df['adx'] = adx(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","df['macd'] = pd.Series.ewm(df['Mid_Close'], span=12).mean() - pd.Series.ewm(df['Mid_Close'], span=26).mean()\n","df['macdsignal'] = pd.Series.ewm(df['macd'], span=9).mean()\n","df['slowk_rsi'], df['slowd_rsi'] = stoch_rsi(df['rsi'])\n","\n","df['vo'] = vo(df['Volume'])\n","\n","df['willy'], df['willy_ema'] = williams_r(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","\n","df['squeeze_on'] = squeeze(df)\n","\n","df.dropna(inplace=True)\n","df.reset_index(drop=True, inplace=True)\n","\n","# Extract the bid and ask prices and fractals and remove them from the df\n","bid_ask_mid_prices = df[['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close']]\n","df.drop(['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume'], axis=1, inplace=True)\n","\n","df.dropna(inplace=True)\n","df.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["from copy import deepcopy\n","\n","currency_pair = 'Gbp_Usd'\n","\n","df_copy = deepcopy(df)\n","\n","df_copy.drop('Date', axis=1, inplace=True)\n","\n","df_copy = scalers[currency_pair].transform(df_copy)\n","# df_copy = pcas[currency_pair].transform(df_copy)"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"data":{"text/plain":["(74602, 17)"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["df_copy.shape"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["assert len(df) == len(df_copy)"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["value_per_pip = 1.0\n","amounts_per_day = [-0.00008, -0.0001, -0.00012]\n","spread_cutoff = 0.10\n","risk_reward_ratio = 1.5\n","proba_threshold = 0.65\n","reward = 0\n","n_wins, n_losses, n_buys, n_sells = 0, 0, 0, 0\n","probas = []\n","\n","def get_n_units(trade_type, stop_loss, ask_open, bid_open, mid_open, currency_pair):\n","    _, second = currency_pair.split('_')\n","  \n","    pips_to_risk = ask_open - stop_loss if trade_type == 'buy' else stop_loss - bid_open\n","    pips_to_risk_calc = pips_to_risk * 10000 if second != 'Jpy' else pips_to_risk * 100\n","\n","    if second == 'Usd':\n","        per_pip = 0.0001\n","\n","    else:\n","        per_pip = 0.0001 / mid_open if second != 'Jpy' else 0.01 / mid_open\n","\n","    n_units = int(50 / (pips_to_risk_calc * per_pip))\n","\n","    return n_units\n","\n","def calculate_day_fees(start_date, end_date, n_units):\n","    curr_fee = np.random.choice(amounts_per_day, p=[0.25, 0.50, 0.25]) * n_units\n","    num_days = np.busday_count(start_date.date(), end_date.date())\n","\n","    return num_days * curr_fee\n","\n","rounding = 3 if 'Jpy' in currency_pair else 5\n","buys, sells, nones = [], [], []\n","trade = None\n","\n","for i in range(look_back_size, len(df)):\n","    curr_date = df.loc[df.index[i], 'Date']\n","\n","    ema200_2, ema100_2, atr2, rsi2, rsi_sma2, vo2, macd2, macdsignal2 = df.loc[df.index[i - 2], ['ema200', 'ema100', 'atr', 'rsi', 'rsi_sma', 'vo', 'macd', 'macdsignal']]\n","    ema200_1, ema100_1, atr1, rsi1, rsi_sma1, vo1, adx1, atr_sma1, macd1, macdsignal1, squeeze_on = df.loc[df.index[i - 1], ['ema200', 'ema100', 'atr', 'rsi', 'rsi_sma', 'vo', 'adx', 'atr_sma', 'macd', 'macdsignal', 'squeeze_on']]\n","    mid_open2, mid_close2, mid_low2, mid_high2 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 2], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","    mid_open1, mid_close1, mid_low1, mid_high1 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 1], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","    curr_ao, curr_bo, curr_mid_open, curr_ask_low, curr_bid_high = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i], ['Ask_Open', 'Bid_Open', 'Mid_Open', 'Ask_Low', 'Bid_High']]\n","    spread = abs(curr_ao - curr_bo)\n","\n","    emas_buy_signal = ema200_1 < ema100_1\n","    emas_sell_signal = ema200_1 > ema100_1\n","\n","    # sideways = adx1 < 20 or atr1 < atr_sma1\n","    sideways = False\n","\n","    rsi_buy_signal = rsi1 > rsi_sma1\n","    rsi_sell_signal = rsi1 < rsi_sma1\n","\n","    macd_vals = [0, macd2, macdsignal2, macd1, macdsignal1]\n","\n","    macd_buy_signal = macd2 < macdsignal2 and macd1 > macdsignal1 and max(macd_vals) == 0\n","    macd_sell_signal = macd2 > macdsignal2 and macd1 < macdsignal1 and min(macd_vals) == 0\n","\n","    if trade is None:\n","        if macd_buy_signal and emas_buy_signal and rsi_buy_signal and not squeeze_on:\n","            lowest_low = min(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_Low']))\n","            \n","            open_price = float(curr_ao)\n","            pullback = float(lowest_low) - spread\n","\n","            stop_loss = round(pullback, rounding)\n","\n","            if stop_loss < open_price:\n","                curr_pips_to_risk = open_price - stop_loss\n","\n","                if spread <= curr_pips_to_risk * spread_cutoff:\n","                    curr_seq = df_copy[i - look_back_size:i, :]\n","                    pred = model.predict(curr_seq.reshape(1, curr_seq.shape[0], curr_seq.shape[1]))\n","                    argmax = np.argmax(pred)\n","                    proba = pred[0][argmax]\n","                    nn_buy_signal = argmax == 1 and proba >= proba_threshold\n","\n","                    if argmax == 1:\n","                        probas.append(proba)\n","\n","                    if nn_buy_signal:\n","                        stop_gain = round(open_price + (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","                        n_units = get_n_units('buy', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","                        trade = {'open_price': open_price, 'trade_type': 'buy', 'stop_loss': stop_loss,\n","                                                        'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","                                                        'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","                        n_buys += 1\n","\n","        elif macd_sell_signal and emas_sell_signal and rsi_sell_signal and not squeeze_on:\n","            highest_high = max(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_High']))\n","\n","            open_price = float(curr_bo)\n","            pullback = float(highest_high) + spread\n","\n","            stop_loss = round(pullback, rounding)\n","\n","            if stop_loss > open_price:\n","                curr_pips_to_risk = stop_loss - open_price\n","\n","                if spread <= curr_pips_to_risk * spread_cutoff:\n","                    curr_seq = df_copy[i - look_back_size:i, :]\n","                    pred = model.predict(curr_seq.reshape(1, curr_seq.shape[0], curr_seq.shape[1]))\n","                    argmax = np.argmax(pred)\n","                    proba = pred[0][argmax]\n","                    nn_sell_signal = argmax == 2 and proba >= proba_threshold\n","\n","                    if argmax == 2:\n","                        probas.append(proba)\n","\n","                    if nn_sell_signal:\n","                        stop_gain = round(open_price - (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","                        n_units = get_n_units('sell', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","                        trade = {'open_price': open_price, 'trade_type': 'sell', 'stop_loss': stop_loss,\n","                                'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","                                'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","                        n_sells += 1\n","\n","    if trade is not None:\n","        curr_date = df.loc[df.index[i], 'Date']\n","        curr_bid_open, curr_bid_high, curr_bid_low, curr_bid_close, curr_ask_open, curr_ask_high, curr_ask_low, curr_ask_close = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i], ['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close']]\n","\n","        if trade['trade_type'] == 'buy' and curr_bid_low <= trade['stop_loss']:\n","            day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","            reward += -50.0\n","            reward += day_fees\n","\n","            n_losses += 1\n","\n","            trade = None\n","            continue\n","\n","\n","        if trade['trade_type'] == 'buy' and curr_bid_high >= trade['stop_gain']:\n","            trade_amount = (trade['stop_gain'] - trade['open_price']) * trade['n_units'] * value_per_pip\n","            day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","            reward += trade_amount + day_fees\n","\n","            if trade_amount + day_fees > 0:\n","                n_wins += 1\n","\n","            trade = None\n","            continue\n","\n","        if trade['trade_type'] == 'sell' and curr_ask_high >= trade['stop_loss']:\n","            day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","            reward += -50.0\n","            reward += day_fees\n","\n","            n_losses += 1\n","\n","            trade = None\n","            continue\n","\n","        if trade['trade_type'] == 'sell' and curr_ask_low <= trade['stop_gain']:\n","            trade_amount = (trade['open_price'] - trade['stop_gain']) * trade['n_units'] * value_per_pip\n","            day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","            reward += trade_amount + day_fees\n","\n","            if trade_amount + day_fees > 0:\n","                n_wins += 1\n","\n","            trade = None\n","            continue"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Reward = -4.044059999998339\n","Wins = 2\n","Losses = 3\n","Buys = 0\n","Sells = 5\n","0.7300598\n","0.3543726\n","0.61034626\n"]}],"source":["print(f'Reward = {reward}')\n","print(f'Wins = {n_wins}')\n","print(f'Losses = {n_losses}')\n","print(f'Buys = {n_buys}')\n","print(f'Sells = {n_sells}')\n","print(max(probas))\n","print(min(probas))\n","print(np.array(probas).mean())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNNXv50z2GrExQJFFMvQ0O4","collapsed_sections":[],"name":"forex_cnn.ipynb","provenance":[]},"interpreter":{"hash":"2bc6dffc417b633bbbc31cedd954f3e10eebcdab1341647d4de83cb692948a0c"},"kernelspec":{"display_name":"Python 3.9.9 ('forex')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}
