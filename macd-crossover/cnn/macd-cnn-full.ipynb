{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"-3XsA6wafwLf"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","import seaborn as sns\n","import math\n","from pyts.image import RecurrencePlot, GramianAngularField\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.models import load_model, Sequential\n","import json\n","import time\n","from collections import deque\n","import warnings\n","from pickle import dump, load\n","\n","file_path = '/Users/mymac/Google Drive/My Drive/Forex_Robot/'"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# currencies = ['Usd_Chf', 'Gbp_Usd', 'Usd_Cad', 'Aud_Usd', 'Eur_Usd', 'Usd_Jpy', 'Nzd_Usd']\n","currencies = ['Gbp_Usd']\n","years = '2016-2022'\n","\n","size = 3 / 3\n","dfs, df_longs = [], []\n","\n","for currency_pair in currencies:\n","    df = pd.read_csv(file_path + f'Oanda_{currency_pair}_M5_{years}.csv')\n","    df.Date = pd.to_datetime(df.Date)\n","    cutoff_idx = int((1 - size) * len(df))\n","    df = df.iloc[cutoff_idx:, :]\n","    df.dropna(inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","    dfs.append(df)\n","\n","    df_long = pd.read_csv(file_path + f'Oanda_{currency_pair}_M30_{years}.csv')\n","    df_long.Date = pd.to_datetime(df_long.Date)\n","    df_long.dropna(inplace=True)\n","    df_long.reset_index(drop=True, inplace=True)\n","    df_longs.append(df_long)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1639361445690,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":420},"id":"tedQvbLQ0gBO","outputId":"5e87470b-a435-467d-f6f3-7cd15683527f"},"outputs":[],"source":["for df in dfs:\n","    df['sin_hour'] = np.sin(2 * np.pi * df['Date'].dt.hour / 24)\n","    # df['cos_hour'] = np.cos(2 * np.pi * df['Date'].dt.hour / 24)\n","    df['sin_day'] = np.sin(2 * np.pi * df['Date'].dt.day / 7)\n","    # df['cos_day'] = np.cos(2 * np.pi * df['Date'].dt.day / 7)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def psar(barsdata, iaf=0.02, maxaf=0.2):\n","    length = len(barsdata)\n","    high = list(barsdata['Mid_High'])\n","    low = list(barsdata['Mid_Low'])\n","    close = list(barsdata['Mid_Close'])\n","    psar = close[0:len(close)]\n","    bull = True\n","    af = iaf\n","    hp = high[0]\n","    lp = low[0]\n","    for i in range(2, length):\n","        if bull:\n","            psar[i] = psar[i - 1] + af * (hp - psar[i - 1])\n","        else:\n","            psar[i] = psar[i - 1] + af * (lp - psar[i - 1])\n","        reverse = False\n","        if bull:\n","            if low[i] < psar[i]:\n","                bull = False\n","                reverse = True\n","                psar[i] = hp\n","                lp = low[i]\n","                af = iaf\n","        else:\n","            if high[i] > psar[i]:\n","                bull = True\n","                reverse = True\n","                psar[i] = lp\n","                hp = high[i]\n","                af = iaf\n","        if not reverse:\n","            if bull:\n","                if high[i] > hp:\n","                    hp = high[i]\n","                    af = min(af + iaf, maxaf)\n","                if low[i - 1] < psar[i]:\n","                    psar[i] = low[i - 1]\n","                if low[i - 2] < psar[i]:\n","                    psar[i] = low[i - 2]\n","            else:\n","                if low[i] < lp:\n","                    lp = low[i]\n","                    af = min(af + iaf, maxaf)\n","                if high[i - 1] > psar[i]:\n","                    psar[i] = high[i - 1]\n","                if high[i - 2] > psar[i]:\n","                    psar[i] = high[i - 2]\n","    return psar\n","\n","\n","def atr(high, low, close, lookback=14):\n","    high_low = high - low\n","    high_close = np.abs(high - close.shift())\n","    low_close = np.abs(low - close.shift())\n","    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n","    true_range = np.max(ranges, axis=1)\n","\n","    return true_range.rolling(lookback).sum() / lookback\n","\n","\n","def rsi(closes, periods=14):\n","    close_delta = closes.diff()\n","\n","    up = close_delta.clip(lower=0)\n","    down = -1 * close_delta.clip(upper=0)\n","    ma_up = up.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n","    ma_down = down.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n","        \n","    rsi = ma_up / ma_down\n","    rsi = 100 - (100/(1 + rsi))\n","\n","    return rsi\n","\n","  \n","def adx(high, low, close, lookback=14):\n","    plus_dm = high.diff()\n","    minus_dm = low.diff()\n","    plus_dm[plus_dm < 0] = 0\n","    minus_dm[minus_dm > 0] = 0\n","    \n","    tr1 = pd.DataFrame(high - low)\n","    tr2 = pd.DataFrame(abs(high - close.shift(1)))\n","    tr3 = pd.DataFrame(abs(low - close.shift(1)))\n","    frames = [tr1, tr2, tr3]\n","    tr = pd.concat(frames, axis = 1, join = 'inner').max(axis = 1)\n","    atr = tr.rolling(lookback).mean()\n","    \n","    plus_di = 100 * (plus_dm.ewm(alpha = 1/lookback).mean() / atr)\n","    minus_di = abs(100 * (minus_dm.ewm(alpha = 1/lookback).mean() / atr))\n","    dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n","    adx = ((dx.shift(1) * (lookback - 1)) + dx) / lookback\n","    adx_smooth = adx.ewm(alpha = 1/lookback).mean()\n","\n","    return adx_smooth\n","\n","\n","def stoch(high, low, close, lookback=14):\n","    high_lookback = high.rolling(lookback).max()\n","    low_lookback = low.rolling(lookback).min()\n","    slow_k = (close - low_lookback) * 100 / (high_lookback - low_lookback)\n","    slow_d = slow_k.rolling(3).mean()\n","\n","    return slow_k, slow_d\n","\n","def stoch_rsi(data, k_window=3, d_window=3, window=14):\n","    min_val = data.rolling(window=window, center=False).min()\n","    max_val = data.rolling(window=window, center=False).max()\n","\n","    stoch = ((data - min_val) / (max_val - min_val)) * 100\n","\n","    slow_k = stoch.rolling(window=k_window, center=False).mean()\n","\n","    slow_d = slow_k.rolling(window=d_window, center=False).mean()\n","\n","    return slow_k, slow_d\n","\n","def n_macd(macd, macdsignal, lookback=50):\n","    n_macd = 2 * (((macd - macd.rolling(lookback).min()) / (macd.rolling(lookback).max() - macd.rolling(lookback).min()))) - 1\n","    n_macdsignal = 2 * (((macdsignal - macdsignal.rolling(lookback).min()) / (macdsignal.rolling(lookback).max() - macdsignal.rolling(lookback).min()))) - 1\n","\n","    return n_macd, n_macdsignal\n","\n","def chop(df, lookback=14):\n","    atr1 = atr(df, lookback=1)\n","    high, low = df['Mid_High'], df['Mid_Low']\n","\n","    chop = np.log10(atr1.rolling(lookback).sum() / (high.rolling(lookback).max() - low.rolling(lookback).min())) / np.log10(lookback)\n","\n","    return chop\n","\n","def vo(volume, short_lookback=5, long_lookback=10):\n","    short_ema =  pd.Series.ewm(volume, span=short_lookback).mean()\n","    long_ema = pd.Series.ewm(volume, span=long_lookback).mean()\n","\n","    volume_oscillator = (short_ema - long_ema) / long_ema\n","\n","    return volume_oscillator\n","\n","def bar_lengths(bar_lens, window=36):\n","    return bar_lens.rolling(window=window).mean(), bar_lens.rolling(window=window).std()\n","\n","def sar_lengths(opens, sars, window=36):\n","    diffs = abs(opens - sars.shift(1))\n","\n","    return diffs.rolling(window=window).mean(), diffs.rolling(window=window).std()\n","\n","def supertrend(barsdata, atr_len=3, mult=3):\n","    curr_atr = atr(barsdata['Mid_High'], barsdata['Mid_Low'], barsdata['Mid_Close'], lookback=atr_len)\n","    highs, lows = barsdata['Mid_High'], barsdata['Mid_Low']\n","    hl2 = (highs + lows) / 2\n","    final_upperband = upper_band = hl2 + mult * curr_atr\n","    final_lowerband = lower_band = hl2 - mult * curr_atr\n","\n","    # initialize Supertrend column to True\n","    supertrend = [True] * len(df)\n","\n","    close = barsdata['Mid_Close']\n","    \n","    for i in range(1, len(df.index)):\n","        curr, prev = i, i - 1\n","        \n","        # if current close price crosses above upperband\n","        if close[curr] > final_upperband[prev]:\n","            supertrend[curr] = True\n","\n","        # if current close price crosses below lowerband\n","        elif close[curr] < final_lowerband[prev]:\n","            supertrend[curr] = False\n","\n","        # else, the trend continues\n","        else:\n","            supertrend[curr] = supertrend[prev]\n","            \n","            # adjustment to the final bands\n","            if supertrend[curr] == True and final_lowerband[curr] < final_lowerband[prev]:\n","                final_lowerband[curr] = final_lowerband[prev]\n","\n","            if supertrend[curr] == False and final_upperband[curr] > final_upperband[prev]:\n","                final_upperband[curr] = final_upperband[prev]\n","\n","    return supertrend, final_upperband, final_lowerband\n","\n","# def supertrend(barsdata, atr_len=3, mult=3):\n","#     curr_atr = atr(barsdata['ha_high'], barsdata['ha_low'], barsdata['ha_close'], lookback=atr_len)\n","#     highs, lows = barsdata['ha_high'], barsdata['ha_low']\n","#     hl2 = (highs + lows) / 2\n","#     final_upperband = upper_band = hl2 + mult * curr_atr\n","#     final_lowerband = lower_band = hl2 - mult * curr_atr\n","\n","#     # initialize Supertrend column to True\n","#     supertrend = [True] * len(df)\n","\n","#     close = barsdata['ha_close']\n","    \n","#     for i in range(1, len(df.index)):\n","#         curr, prev = i, i - 1\n","        \n","#         # if current close price crosses above upperband\n","#         if close[curr] > final_upperband[prev]:\n","#             supertrend[curr] = True\n","\n","#         # if current close price crosses below lowerband\n","#         elif close[curr] < final_lowerband[prev]:\n","#             supertrend[curr] = False\n","\n","#         # else, the trend continues\n","#         else:\n","#             supertrend[curr] = supertrend[prev]\n","            \n","#             # adjustment to the final bands\n","#             if supertrend[curr] == True and final_lowerband[curr] < final_lowerband[prev]:\n","#                 final_lowerband[curr] = final_lowerband[prev]\n","\n","#             if supertrend[curr] == False and final_upperband[curr] > final_upperband[prev]:\n","#                 final_upperband[curr] = final_upperband[prev]\n","\n","#     return supertrend, final_upperband, final_lowerband\n","\n","def heikin_ashi(opens, highs, lows, closes):\n","    ha_close = list((opens + highs + lows + closes) / 4)\n","    ha_opens = []\n","\n","    opens_list, closes_list = list(opens), list(closes)\n","\n","    for i in range(len(ha_close)):\n","        if i == 0:\n","            ha_opens.append((opens_list[i] + closes_list[i]) / 2)\n","\n","        else:\n","            ha_opens.append((ha_opens[i - 1] + ha_close[i - 1]) / 2)\n","\n","    ha_highs = list(pd.DataFrame({'ha_open': ha_opens, 'ha_close': ha_close, 'high': list(highs)}).max(axis=1))\n","    ha_lows = list(pd.DataFrame({'ha_open': ha_opens, 'ha_close': ha_close, 'low': list(lows)}).min(axis=1))\n","\n","    return ha_opens, ha_highs, ha_lows, ha_close\n","\n","def trend_indicator(opens, highs, lows, closes, ema_period=50, smoothing_period=10):\n","    ha_open, ha_high, ha_low, ha_close = heikin_ashi(opens, highs, lows, closes)\n","\n","    ha_o_ema = pd.Series.ewm(pd.DataFrame({'ha_open': ha_open}), span=ema_period).mean()\n","    ha_h_ema = pd.Series.ewm(pd.DataFrame({'ha_high': ha_high}), span=ema_period).mean()\n","    ha_l_ema = pd.Series.ewm(pd.DataFrame({'ha_low': ha_low}), span=ema_period).mean()\n","    ha_c_ema = pd.Series.ewm(pd.DataFrame({'ha_close': ha_close}), span=ema_period).mean()\n","\n","    return pd.Series.ewm(ha_o_ema, span=smoothing_period).mean(), pd.Series.ewm(ha_h_ema, span=smoothing_period).mean(), pd.Series.ewm(ha_l_ema, span=smoothing_period).mean(), pd.Series.ewm(ha_c_ema, span=smoothing_period).mean()\n","\n","def qqe_mod(barsdata, rsi_period=6, smoothing=5, qqe_factor=5, qqe2_factor=1.61, threshold=3, mult=0.35, sma_length=50):\n","    wilders_period = rsi_period * 2 - 1\n","\n","    curr_rsi = rsi(barsdata, periods=rsi_period)\n","    rsi_ema = pd.Series.ewm(curr_rsi, span=smoothing).mean()\n","    atr_rsi = abs(rsi_ema.shift(1) - rsi_ema)\n","    atr_rsi_ema = pd.Series.ewm(atr_rsi, span=wilders_period).mean()\n","    dar = pd.Series.ewm(atr_rsi_ema, span=wilders_period).mean() * qqe_factor\n","\n","    newshortband = rsi_ema + dar\n","    newlongband = rsi_ema - dar\n","\n","    rsi_ema_list = list(rsi_ema)\n","\n","    longband = [0]\n","    for i in range(1, len(rsi_ema_list)):\n","        if rsi_ema_list[i - 1] > longband[i - 1] and rsi_ema_list[i] > longband[i - 1]:\n","            longband.append(max(longband[i - 1],newlongband[i]))\n","\n","        else:\n","            longband.append(newlongband[i])\n","\n","    shortband = [0]\n","    for i in range(1,len(rsi_ema_list)):\n","        if rsi_ema_list[i - 1] < shortband[i - 1] and rsi_ema_list[i] < shortband[i - 1]:\n","            shortband.append(min(shortband[i - 1],newshortband[i]))\n","            \n","        else:\n","            shortband.append(newshortband[i])\n","\n","    longband = pd.Series(longband)\n","    shortband = pd.Series(shortband)\n","\n","    trend = np.where(rsi_ema > longband.shift(1), 1, -1)    \n","    fastatrrsitl = pd.Series(np.where(trend == 1, longband, shortband))\n","\n","    basis = (fastatrrsitl - 50).rolling(window=sma_length).mean()\n","    dev = (fastatrrsitl - 50).rolling(window=sma_length).std() * mult\n","    upper = basis + dev\n","    lower = basis - dev\n","\n","    greenbar1 = rsi_ema - 50 > threshold\n","    greenbar2 = rsi_ema - 50 > upper\n","    redbar1 = rsi_ema - 50 < threshold\n","    redbar2 = rsi_ema - 50 < lower\n","\n","    # uptrend = np.where((greenbar1 & greenbar2), True, False)\n","    # downtrend = np.where((redbar1 & redbar2), True, False)\n","\n","    uptrend = np.where((greenbar2), True, False)\n","    downtrend = np.where((redbar2), True, False)\n","\n","    return uptrend, downtrend\n","\n","def williams_r(highs, lows, closes, length=21, ema_length=15):\n","    highest_highs = highs.rolling(window=length).max()\n","    lowest_lows = lows.rolling(window=length).min()\n","\n","    willy = 100 * (closes - highest_highs) / (highest_highs - lowest_lows)\n","    willy_ema = pd.Series.ewm(willy, span=ema_length).mean()\n","\n","    return willy, willy_ema"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1639361446900,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":420},"id":"5Ttafp9WxjAe","outputId":"92fd8ae2-3721-4852-eb4d-6fa6c6226a50"},"outputs":[],"source":["bid_ask_mid_prices_list = []\n","\n","for df in dfs:\n","    # Add technical indicators (for additional features)\n","    df['ema200'] = pd.Series.ewm(df['Mid_Close'], span=200).mean()\n","    df['ema100'] = pd.Series.ewm(df['Mid_Close'], span=100).mean()\n","    # df['ema50'] = pd.Series.ewm(df['Mid_Close'], span=50).mean()\n","\n","    df['atr'] = atr(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","    df['atr_sma'] = df['atr'].rolling(window=20).mean()\n","    df['rsi'] = rsi(df['Mid_Close'])\n","    df['rsi_sma'] = df['rsi'].rolling(50).mean()\n","    df['adx'] = adx(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","    df['macd'] = pd.Series.ewm(df['Mid_Close'], span=12).mean() - pd.Series.ewm(df['Mid_Close'], span=26).mean()\n","    df['macdsignal'] = pd.Series.ewm(df['macd'], span=9).mean()\n","    df['slowk_rsi'], df['slowd_rsi'] = stoch_rsi(df['rsi'])\n","\n","    df['vo'] = vo(df['Volume'])\n","\n","    df['willy'], df['willy_ema'] = williams_r(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","\n","    # df['ti_o'], df['ti_h'], df['ti_l'], df['ti_c'] = trend_indicator(df['Mid_Open'], df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","\n","    df.dropna(inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","    # Extract the bid and ask prices and fractals and remove them from the df\n","    bid_ask_mid_prices = df[['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close']]\n","    df.drop(['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume'], axis=1, inplace=True)\n","    bid_ask_mid_prices_list.append(bid_ask_mid_prices)\n","\n","    df.dropna(inplace=True)\n","    df.reset_index(drop=True, inplace=True)\n","\n","for df_long in df_longs:\n","    df_long['ema200'] = pd.Series.ewm(df_long['Mid_Close'], span=200).mean()\n","    df_long['ema100'] = pd.Series.ewm(df_long['Mid_Close'], span=100).mean()\n","    # df_long['ema50'] = pd.Series.ewm(df_long['Mid_Close'], span=50).mean()\n","\n","    df_long['atr'] = atr(df_long['Mid_High'], df_long['Mid_Low'], df_long['Mid_Close'])\n","    df_long['atr_sma'] = df_long['atr'].rolling(window=20).mean()\n","    df_long['rsi'] = rsi(df_long['Mid_Close'])\n","    df_long['rsi_sma'] = df_long['rsi'].rolling(50).mean()\n","    df_long['adx'] = adx(df_long['Mid_High'], df_long['Mid_Low'], df_long['Mid_Close'])\n","    df_long['macd'] = pd.Series.ewm(df_long['Mid_Close'], span=12).mean() - pd.Series.ewm(df_long['Mid_Close'], span=26).mean()\n","    df_long['macdsignal'] = pd.Series.ewm(df_long['macd'], span=9).mean()\n","    df_long['slowk_rsi'], df_long['slowd_rsi'] = stoch_rsi(df_long['rsi'])\n","\n","    df_long['vo'] = vo(df_long['Volume'])\n","\n","    df_long['willy'], df_long['willy_ema'] = williams_r(df_long['Mid_High'], df_long['Mid_Low'], df_long['Mid_Close'])\n","\n","    df_long.dropna(inplace=True)\n","    df_long.reset_index(drop=True, inplace=True)\n","\n","    df_long.drop(['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume'], axis=1, inplace=True)\n","\n","    df_long.dropna(inplace=True)\n","    df_long.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Qp5VKTj7ujLO"},"outputs":[],"source":["look_back_size = 50"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"LNUGMb0RR18a"},"outputs":[],"source":["def grab_image_data(subset):\n","  # rp_transformer = RecurrencePlot()\n","  # rp_subset = rp_transformer.transform(subset)\n","\n","  # return rp_subset\n","\n","  gasf_transformer = GramianAngularField(method='summation')\n","  gasf_subset = gasf_transformer.transform(subset)\n","\n","  return gasf_subset\n","\n","  # gadf_transformer = GramianAngularField(method='difference')\n","  # gadf_subset = gadf_transformer.transform(subset)\n","\n","  # return gadf_subset\n","\n","  # image_data = np.append(rp_subset, gasf_subset, axis=-1)\n","  # image_data = np.append(image_data, gadf_subset ,axis=-1)\n","  \n","  # return image_data"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RUNNING SIMULATION FOR Gbp_Usd...\n","2016\n","Buys: 0\n","Sells: 0\n","Nones: 0\n","\n","2017\n","Buys: 2981\n","Sells: 3200\n","Nones: 10271\n","\n","2018\n","Buys: 5310\n","Sells: 5272\n","Nones: 18428\n","\n","2019\n","Buys: 7778\n","Sells: 8086\n","Nones: 27251\n","\n","2020\n","Buys: 10011\n","Sells: 10655\n","Nones: 35047\n","\n","2021\n","Buys: 13907\n","Sells: 14032\n","Nones: 46454\n","\n","Buys: 16337\n","Sells: 16696\n","Nones: 55650\n","\n"]}],"source":["buys_list = []\n","sells_list = []\n","nones_list = []\n","\n","value_per_pip = 1.0\n","amounts_per_day = [-0.00008, -0.0001, -0.00012]\n","spread_cutoff = 0.10\n","risk_reward_ratio = 1.5\n","\n","def get_n_units(trade_type, stop_loss, ask_open, bid_open, mid_open, currency_pair):\n","    _, second = currency_pair.split('_')\n","  \n","    pips_to_risk = ask_open - stop_loss if trade_type == 'buy' else stop_loss - bid_open\n","    pips_to_risk_calc = pips_to_risk * 10000 if second != 'Jpy' else pips_to_risk * 100\n","\n","    if second == 'Usd':\n","        per_pip = 0.0001\n","\n","    else:\n","        per_pip = 0.0001 / mid_open if second != 'Jpy' else 0.01 / mid_open\n","\n","    n_units = int(50 / (pips_to_risk_calc * per_pip))\n","\n","    return n_units\n","\n","def calculate_day_fees(start_date, end_date, n_units):\n","    curr_fee = np.random.choice(amounts_per_day, p=[0.25, 0.50, 0.25]) * n_units\n","    num_days = np.busday_count(start_date.date(), end_date.date())\n","\n","    return num_days * curr_fee\n","\n","for idx in range(len(currencies)):\n","    currency_pair, df, df_long, bid_ask_mid_prices = currencies[idx], dfs[idx], df_longs[idx], bid_ask_mid_prices_list[idx]\n","    rounding = 3 if 'Jpy' in currency_pair else 5\n","    buys, sells, nones = [], [], []\n","    trade, prev_year = None, None\n","\n","    print(f'RUNNING SIMULATION FOR {currency_pair}...')\n","\n","    for i in range(look_back_size, len(df)):\n","        curr_date = df.loc[df.index[i], 'Date']\n","        if prev_year is None or curr_date.year > prev_year:\n","            prev_year = curr_date.year\n","            print(prev_year)\n","            print(f'Buys: {len(buys)}')\n","            print(f'Sells: {len(sells)}')\n","            print(f'Nones: {len(nones)}\\n')\n","        curr_long = df_long.loc[df_long['Date'] < curr_date]\n","        if len(curr_long) < look_back_size + 1:\n","            continue\n","        ema200_2, ema100_2, atr2, rsi2, rsi_sma2, vo2, macd2, macdsignal2 = df.loc[df.index[i - 2], ['ema200', 'ema100', 'atr', 'rsi', 'rsi_sma', 'vo', 'macd', 'macdsignal']]\n","        ema200_1, ema100_1, atr1, rsi1, rsi_sma1, vo1, adx1, atr_sma1, macd1, macdsignal1 = df.loc[df.index[i - 1], ['ema200', 'ema100', 'atr', 'rsi', 'rsi_sma', 'vo', 'adx', 'atr_sma', 'macd', 'macdsignal']]\n","        mid_open2, mid_close2, mid_low2, mid_high2 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 2], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","        mid_open1, mid_close1, mid_low1, mid_high1 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 1], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","        curr_ao, curr_bo, curr_mid_open, curr_ask_low, curr_bid_high = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i], ['Ask_Open', 'Bid_Open', 'Mid_Open', 'Ask_Low', 'Bid_High']]\n","        spread = abs(curr_ao - curr_bo)\n","\n","        emas_buy_signal = ema200_1 < ema100_1\n","        emas_sell_signal = ema200_1 > ema100_1\n","\n","        if trade is None:\n","            if emas_buy_signal:\n","                lowest_low = min(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_Low']))\n","                \n","                open_price = float(curr_ao)\n","                pullback = float(lowest_low) - spread\n","\n","                stop_loss = round(pullback, rounding)\n","\n","                if stop_loss < open_price:\n","                    curr_pips_to_risk = open_price - stop_loss\n","\n","                    if spread <= curr_pips_to_risk * spread_cutoff:\n","                        stop_gain = round(open_price + (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","                        n_units = get_n_units('buy', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","                        trade = {'open_price': open_price, 'trade_type': 'buy', 'stop_loss': stop_loss,\n","                                                        'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","                                                        'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","            elif emas_sell_signal:\n","                highest_high = max(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_High']))\n","\n","                open_price = float(curr_bo)\n","                pullback = float(highest_high) + spread\n","\n","                stop_loss = round(pullback, rounding)\n","\n","                if stop_loss > open_price:\n","                    curr_pips_to_risk = stop_loss - open_price\n","\n","                    if spread <= curr_pips_to_risk * spread_cutoff:\n","                        stop_gain = round(open_price - (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","                        n_units = get_n_units('sell', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","                        trade = {'open_price': open_price, 'trade_type': 'sell', 'stop_loss': stop_loss,\n","                                'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","                                'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","        if trade is not None:\n","            for j in range(i, len(df)):\n","                curr_date = df.loc[df.index[j], 'Date']\n","                curr_bid_open, curr_bid_high, curr_bid_low, curr_bid_close, curr_ask_open, curr_ask_high, curr_ask_low, curr_ask_close = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[j], ['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close']]\n","\n","                if trade['trade_type'] == 'buy' and curr_bid_low <= trade['stop_loss']:\n","                    nones.append(trade['start_date']) \n","\n","                    trade = None\n","                    break\n","\n","\n","                if trade['trade_type'] == 'buy' and curr_bid_high >= trade['stop_gain']:\n","                    trade_amount = (trade['stop_gain'] - trade['open_price']) * trade['n_units'] * value_per_pip\n","                    day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","                    if trade_amount + day_fees > 0:\n","                        buys.append(trade['start_date'])\n","\n","                    trade = None\n","                    break\n","\n","                if trade['trade_type'] == 'sell' and curr_ask_high >= trade['stop_loss']:\n","                    nones.append(trade['start_date'])\n","\n","                    trade = None\n","                    break\n","\n","                if trade['trade_type'] == 'sell' and curr_ask_low <= trade['stop_gain']:\n","                    trade_amount = (trade['open_price'] - trade['stop_gain']) * trade['n_units'] * value_per_pip\n","                    day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","                    if trade_amount + day_fees > 0:\n","                        sells.append(trade['start_date'])\n","\n","                    trade = None\n","                    break\n","    \n","    buys_list.append(buys)\n","    sells_list.append(sells)\n","    nones_list.append(nones)\n","\n","    print(f'Buys: {len(buys)}')\n","    print(f'Sells: {len(sells)}')\n","    print(f'Nones: {len(nones)}\\n')"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2722\n","2722\n","2722\n"]}],"source":["buy_indices_list = []\n","sell_indices_list = []\n","nones_indices_list = []\n","size = 1 / 6\n","\n","for i in range(len(dfs)):\n","    buys, sells, nones, df = buys_list[i], sells_list[i], nones_list[i], dfs[i]\n","    \n","    buy_indices = [df.index[df['Date'] == curr_date] - 1 for curr_date in buys]\n","    sell_indices = [df.index[df['Date'] == curr_date] - 1 for curr_date in sells]\n","    nones_indices = [df.index[df['Date'] == curr_date] - 1 for curr_date in nones]\n","\n","    np.random.shuffle(buy_indices)\n","    np.random.shuffle(sell_indices)\n","    np.random.shuffle(nones_indices)\n","\n","    lower = min(len(buy_indices), len(sell_indices), len(nones_indices))\n","    lower = int(lower * size)\n","\n","    buy_indices = buy_indices[:lower]\n","    sell_indices = sell_indices[:lower]\n","    nones_indices = nones_indices[:lower]\n","\n","    buy_indices_list.append(buy_indices)\n","    sell_indices_list.append(sell_indices)\n","    nones_indices_list.append(nones_indices)\n","\n","    print(len(buy_indices))\n","    print(len(sell_indices))\n","    print(len(nones_indices))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["(50, 30, 30)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["i = 5000\n","foo = dfs[0].iloc[i - look_back_size + 1:i + 1, 1:]\n","curr_date = dfs[0].iloc[i, 0]\n","curr_long = df_longs[0].loc[df_longs[0]['Date'] < curr_date]\n","foo2 = curr_long.iloc[-look_back_size - 1:-1, 1:]\n","foo3 = pd.concat([foo.reset_index(drop=True), foo2.reset_index(drop=True)], axis=1, ignore_index=True)\n","correct_shape = grab_image_data(foo3).shape\n","correct_shape"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Hqy2dig_7e-F"},"outputs":[],"source":["def get_sequential_data():\n","    no_actions = []\n","    buys = []\n","    sells = []\n","\n","    for z in range(len(dfs)):\n","        print(currencies[z])\n","        df, df_long = dfs[z], df_longs[z]\n","\n","        buy_indices, sell_indices, nones_indices = buy_indices_list[z], sell_indices_list[z], nones_indices_list[z]\n","\n","        for i in buy_indices:\n","            if len(i) == 1:\n","                i = i[0]\n","                seq1 = df.iloc[i - look_back_size + 1:i + 1, 1:]\n","                curr_date = df.iloc[i, 0]\n","                curr_long = df_long.loc[df_long['Date'] < curr_date]\n","                seq2 = curr_long.iloc[-look_back_size - 1:-1, 1:]\n","                seq = pd.concat([seq1.reset_index(drop=True), seq2.reset_index(drop=True)], axis=1, ignore_index=True)\n","\n","                if seq.shape == correct_shape[:-1] and not seq.isnull().values.any():\n","                    seq = grab_image_data(seq)\n","                    buys.append([seq, np.array([0, 1, 0])])\n","\n","        for i in sell_indices:\n","            if len(i) == 1:\n","                i = i[0]\n","                seq1 = df.iloc[i - look_back_size + 1:i + 1, 1:]\n","                curr_date = df.iloc[i, 0]\n","                curr_long = df_long.loc[df_long['Date'] < curr_date]\n","                seq2 = curr_long.iloc[-look_back_size - 1:-1, 1:]\n","                seq = pd.concat([seq1.reset_index(drop=True), seq2.reset_index(drop=True)], axis=1, ignore_index=True)\n","\n","                if seq.shape == correct_shape[:-1] and not seq.isnull().values.any():\n","                    seq = grab_image_data(seq)\n","                    sells.append([seq, np.array([0, 0, 1])])\n","\n","        for i in nones_indices:\n","            if len(i) == 1:\n","                i = i[0]\n","                seq1 = df.iloc[i - look_back_size + 1:i + 1, 1:]\n","                curr_date = df.iloc[i, 0]\n","                curr_long = df_long.loc[df_long['Date'] < curr_date]\n","                seq2 = curr_long.iloc[-look_back_size - 1:-1, 1:]\n","                seq = pd.concat([seq1.reset_index(drop=True), seq2.reset_index(drop=True)], axis=1, ignore_index=True)\n","\n","                if seq.shape == correct_shape[:-1] and not seq.isnull().values.any():\n","                    seq = grab_image_data(seq)\n","                    no_actions.append([seq, np.array([1, 0, 0])])\n","\n","    np.random.shuffle(no_actions)\n","    np.random.shuffle(buys)\n","    np.random.shuffle(sells)\n","\n","    sequential_data = no_actions + buys + sells\n","    np.random.shuffle(sequential_data)\n","\n","    return sequential_data"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"gk8jS65z7i5q"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gbp_Usd\n"]}],"source":["sequential_data = get_sequential_data()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["8166"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["len(sequential_data)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1631924931206,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":360},"id":"cdYAzLkF5PO5","outputId":"9e5842f8-8004-4914-a05c-2a56353f39c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset shapes:\n","5716\n","2450\n"]}],"source":["training_proportion = 0.70\n","train_test_cutoff_index = int(len(sequential_data) * training_proportion)\n","\n","train_set = sequential_data[0:train_test_cutoff_index]\n","test_set = sequential_data[train_test_cutoff_index:]\n","\n","print('Dataset shapes:')\n","print(len(train_set))\n","print(len(test_set))"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"wLRUg-ekVUtL"},"outputs":[],"source":["x_train = []\n","y_train = []\n","\n","for seq, target in train_set:\n","  x_train.append(seq)\n","  y_train.append(target)\n","\n","x_test = []\n","y_test = []\n","\n","for seq, target in test_set:\n","  x_test.append(seq)\n","  y_test.append(target)\n","\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)\n","x_test = np.array(x_test)\n","y_test = np.array(y_test)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1631924983918,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":360},"id":"D3_lj-U3NGM2","outputId":"ce1b1761-9bb2-4afc-c7c5-eca2ac8cde79"},"outputs":[{"data":{"text/plain":["(5716, 50, 30, 30)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["(5716, 3)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["y_train.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"gWXFnbrFEQ9A"},"outputs":[],"source":["# # Number of possible actions to take - determines the output dimension of the\n","# #  neural network\n","# n_actions = 3\n","# input_data_shape = x_train.shape[1:]\n","\n","# model = Sequential()\n","\n","# model.add(Conv2D(filters = 32, kernel_size = (3,3), padding ='Same', activation ='relu', input_shape = input_data_shape))\n","# model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n","\n","# model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","# model.add(Dropout(0.25))\n","\n","# model.add(Flatten())\n","# model.add(Dense(128, activation = \"relu\"))\n","# model.add(Dropout(0.5))\n","# model.add(Dense(n_actions, activation = \"softmax\"))\n","\n","n_actions = 3\n","input_data_shape = x_train.shape[1:]\n","\n","model = Sequential()\n","\n","model.add(Conv2D(filters = 16, kernel_size = (3,3), padding ='Same', activation ='relu', input_shape = input_data_shape))\n","model.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n","model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n","\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation = \"relu\"))\n","model.add(Dense(128, activation = \"relu\"))\n","model.add(Dropout(0.5))\n","# model.add(Dense(128, activation = \"relu\"))\n","# model.add(Dropout(0.5))\n","model.add(Dense(64, activation = \"relu\"))\n","model.add(Dropout(0.25))\n","model.add(Dense(32, activation = \"relu\"))\n","model.add(Dense(n_actions, activation = \"softmax\"))"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"YzWCOxnCECEl"},"outputs":[],"source":["# Hyperparameters\n","n_epochs = 300\n","batch_size = 32\n","n_steps = len(x_train) // batch_size \n","mean_loss = tf.keras.metrics.Mean() \n","optimizer = tf.keras.optimizers.Adam()\n","loss_fn = tf.keras.losses.categorical_crossentropy\n","metrics = [tf.keras.metrics.CategoricalAccuracy()]\n","# loss_fn = tf.keras.losses.MeanAbsoluteError\n","# metrics = [tf.keras.metrics.MeanAbsoluteError()]"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["early_stop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=n_epochs)\n","model_checkpoint = ModelCheckpoint('/Users/mymac/test_cnn', monitor='val_accuracy', save_best_only=True, verbose=1)\n","\n","optimizer = Adam()\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60729,"status":"ok","timestamp":1631925055308,"user":{"displayName":"Ethan Pedersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09911969564442359454"},"user_tz":360},"id":"NRG4mIMcq5_f","outputId":"eb40bd91-3efc-495f-a4a0-8545eab20758"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/300\n","179/179 [==============================] - ETA: 0s - loss: 0.9567 - accuracy: 0.4962\n","Epoch 00001: val_accuracy improved from -inf to 0.62898, saving model to /Users/mymac/test_cnn\n","INFO:tensorflow:Assets written to: /Users/mymac/test_cnn/assets\n","179/179 [==============================] - 7s 36ms/step - loss: 0.9567 - accuracy: 0.4962 - val_loss: 0.7495 - val_accuracy: 0.6290\n","Epoch 2/300\n","177/179 [============================>.] - ETA: 0s - loss: 0.7557 - accuracy: 0.6163\n","Epoch 00002: val_accuracy improved from 0.62898 to 0.65755, saving model to /Users/mymac/test_cnn\n","INFO:tensorflow:Assets written to: /Users/mymac/test_cnn/assets\n","179/179 [==============================] - 6s 31ms/step - loss: 0.7551 - accuracy: 0.6167 - val_loss: 0.6865 - val_accuracy: 0.6576\n","Epoch 3/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.7103 - accuracy: 0.6417\n","Epoch 00003: val_accuracy did not improve from 0.65755\n","179/179 [==============================] - 5s 28ms/step - loss: 0.7103 - accuracy: 0.6415 - val_loss: 0.7061 - val_accuracy: 0.6543\n","Epoch 4/300\n","179/179 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.6380\n","Epoch 00004: val_accuracy did not improve from 0.65755\n","179/179 [==============================] - 5s 28ms/step - loss: 0.7060 - accuracy: 0.6380 - val_loss: 0.6813 - val_accuracy: 0.6567\n","Epoch 5/300\n","177/179 [============================>.] - ETA: 0s - loss: 0.6891 - accuracy: 0.6395\n","Epoch 00005: val_accuracy did not improve from 0.65755\n","179/179 [==============================] - 5s 29ms/step - loss: 0.6893 - accuracy: 0.6394 - val_loss: 0.6925 - val_accuracy: 0.6547\n","Epoch 6/300\n","179/179 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.6454\n","Epoch 00006: val_accuracy did not improve from 0.65755\n","179/179 [==============================] - 5s 30ms/step - loss: 0.6776 - accuracy: 0.6454 - val_loss: 0.6989 - val_accuracy: 0.6547\n","Epoch 7/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.6807 - accuracy: 0.6471\n","Epoch 00007: val_accuracy did not improve from 0.65755\n","179/179 [==============================] - 5s 29ms/step - loss: 0.6803 - accuracy: 0.6477 - val_loss: 0.7087 - val_accuracy: 0.6176\n","Epoch 8/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.6503 - accuracy: 0.6548\n","Epoch 00008: val_accuracy improved from 0.65755 to 0.66041, saving model to /Users/mymac/test_cnn\n","INFO:tensorflow:Assets written to: /Users/mymac/test_cnn/assets\n","179/179 [==============================] - 6s 33ms/step - loss: 0.6504 - accuracy: 0.6545 - val_loss: 0.6890 - val_accuracy: 0.6604\n","Epoch 9/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.6273 - accuracy: 0.6705\n","Epoch 00009: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.6276 - accuracy: 0.6700 - val_loss: 0.7205 - val_accuracy: 0.6408\n","Epoch 10/300\n","179/179 [==============================] - ETA: 0s - loss: 0.5921 - accuracy: 0.7035\n","Epoch 00010: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 27ms/step - loss: 0.5921 - accuracy: 0.7035 - val_loss: 0.7566 - val_accuracy: 0.6318\n","Epoch 11/300\n","179/179 [==============================] - ETA: 0s - loss: 0.5489 - accuracy: 0.7369\n","Epoch 00011: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.5489 - accuracy: 0.7369 - val_loss: 0.7273 - val_accuracy: 0.6322\n","Epoch 12/300\n","179/179 [==============================] - ETA: 0s - loss: 0.4751 - accuracy: 0.7797\n","Epoch 00012: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.4751 - accuracy: 0.7797 - val_loss: 0.8081 - val_accuracy: 0.5845\n","Epoch 13/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.3935 - accuracy: 0.8294\n","Epoch 00013: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.3939 - accuracy: 0.8293 - val_loss: 0.8534 - val_accuracy: 0.6282\n","Epoch 14/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.2972 - accuracy: 0.8796\n","Epoch 00014: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.2968 - accuracy: 0.8798 - val_loss: 0.9782 - val_accuracy: 0.6249\n","Epoch 15/300\n","177/179 [============================>.] - ETA: 0s - loss: 0.2240 - accuracy: 0.9128\n","Epoch 00015: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 29ms/step - loss: 0.2239 - accuracy: 0.9132 - val_loss: 1.0999 - val_accuracy: 0.6008\n","Epoch 16/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9292\n","Epoch 00016: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.1886 - accuracy: 0.9291 - val_loss: 1.1608 - val_accuracy: 0.5976\n","Epoch 17/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.1252 - accuracy: 0.9515\n","Epoch 00017: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.1251 - accuracy: 0.9517 - val_loss: 1.6229 - val_accuracy: 0.6135\n","Epoch 18/300\n","177/179 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.9613\n","Epoch 00018: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.1140 - accuracy: 0.9613 - val_loss: 1.3935 - val_accuracy: 0.6057\n","Epoch 19/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9738\n","Epoch 00019: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.0786 - accuracy: 0.9738 - val_loss: 1.6215 - val_accuracy: 0.6180\n","Epoch 20/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9733\n","Epoch 00020: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 29ms/step - loss: 0.0754 - accuracy: 0.9734 - val_loss: 1.5702 - val_accuracy: 0.6122\n","Epoch 21/300\n","179/179 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9797\n","Epoch 00021: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.0619 - accuracy: 0.9797 - val_loss: 1.8225 - val_accuracy: 0.6184\n","Epoch 22/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9826\n","Epoch 00022: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 30ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 1.7469 - val_accuracy: 0.6061\n","Epoch 23/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 0.9803\n","Epoch 00023: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 29ms/step - loss: 0.0603 - accuracy: 0.9804 - val_loss: 1.7036 - val_accuracy: 0.6163\n","Epoch 24/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9903\n","Epoch 00024: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.0271 - accuracy: 0.9904 - val_loss: 2.0466 - val_accuracy: 0.6171\n","Epoch 25/300\n","177/179 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9869\n","Epoch 00025: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.0391 - accuracy: 0.9871 - val_loss: 2.2330 - val_accuracy: 0.6180\n","Epoch 26/300\n","177/179 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9871\n","Epoch 00026: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 1.9870 - val_accuracy: 0.6086\n","Epoch 27/300\n","179/179 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9913\n","Epoch 00027: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 29ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 2.0420 - val_accuracy: 0.6082\n","Epoch 28/300\n","179/179 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9897\n","Epoch 00028: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 30ms/step - loss: 0.0274 - accuracy: 0.9897 - val_loss: 2.3833 - val_accuracy: 0.6118\n","Epoch 29/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9898\n","Epoch 00029: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.0311 - accuracy: 0.9899 - val_loss: 2.0715 - val_accuracy: 0.6094\n","Epoch 30/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9889\n","Epoch 00030: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 30ms/step - loss: 0.0311 - accuracy: 0.9890 - val_loss: 2.0817 - val_accuracy: 0.6135\n","Epoch 31/300\n","177/179 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9910\n","Epoch 00031: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 27ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 2.1265 - val_accuracy: 0.6049\n","Epoch 32/300\n","178/179 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9898\n","Epoch 00032: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 29ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 1.9379 - val_accuracy: 0.5959\n","Epoch 33/300\n","179/179 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9923\n","Epoch 00033: val_accuracy did not improve from 0.66041\n","179/179 [==============================] - 5s 28ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 1.9550 - val_accuracy: 0.6065\n","Epoch 34/300\n"," 53/179 [=======>......................] - ETA: 2s - loss: 0.0110 - accuracy: 0.9976"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-7af7dcac3212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniforge3/envs/forex/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["history = model.fit(\n","    x_train, y_train,\n","    batch_size=batch_size,\n","    epochs=n_epochs,\n","    validation_data=(x_test, y_test),\n","    callbacks=[early_stop, model_checkpoint]\n",")"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["model = load_model('/Users/mymac/test_cnn')"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["df = pd.read_csv(file_path + 'Oanda_Gbp_Usd_M5_2021-2022.csv')\n","df.Date = pd.to_datetime(df.Date)\n","df.dropna(inplace=True)\n","df.reset_index(drop=True, inplace=True)\n","\n","df['sin_hour'] = np.sin(2 * np.pi * df['Date'].dt.hour / 24)\n","df['sin_day'] = np.sin(2 * np.pi * df['Date'].dt.day / 7)\n","\n","# Add technical indicators (for additional features)\n","df['ema200'] = pd.Series.ewm(df['Mid_Close'], span=200).mean()\n","df['ema100'] = pd.Series.ewm(df['Mid_Close'], span=100).mean()\n","# df['ema50'] = pd.Series.ewm(df['Mid_Close'], span=50).mean()\n","\n","df['atr'] = atr(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","df['atr_sma'] = df['atr'].rolling(window=20).mean()\n","df['rsi'] = rsi(df['Mid_Close'])\n","df['rsi_sma'] = df['rsi'].rolling(50).mean()\n","df['adx'] = adx(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","df['macd'] = pd.Series.ewm(df['Mid_Close'], span=12).mean() - pd.Series.ewm(df['Mid_Close'], span=26).mean()\n","df['macdsignal'] = pd.Series.ewm(df['macd'], span=9).mean()\n","df['slowk_rsi'], df['slowd_rsi'] = stoch_rsi(df['rsi'])\n","\n","df['vo'] = vo(df['Volume'])\n","\n","df['willy'], df['willy_ema'] = williams_r(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","\n","# df['ti_o'], df['ti_h'], df['ti_l'], df['ti_c'] = trend_indicator(df['Mid_Open'], df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n","\n","df.dropna(inplace=True)\n","df.reset_index(drop=True, inplace=True)\n","\n","# Extract the bid and ask prices and fractals and remove them from the df\n","bid_ask_mid_prices = df[['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close']]\n","df.drop(['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume'], axis=1, inplace=True)\n","\n","df.dropna(inplace=True)\n","df.reset_index(drop=True, inplace=True)\n","\n","df_long = pd.read_csv(file_path + 'Oanda_Nzd_Usd_M30_2016-2022.csv')\n","df_long.Date = pd.to_datetime(df_long.Date)\n","df_long.dropna(inplace=True)\n","df_long.reset_index(drop=True, inplace=True)\n","\n","df_long['ema200'] = pd.Series.ewm(df_long['Mid_Close'], span=200).mean()\n","df_long['ema100'] = pd.Series.ewm(df_long['Mid_Close'], span=100).mean()\n","# df_long['ema50'] = pd.Series.ewm(df_long['Mid_Close'], span=50).mean()\n","\n","df_long['atr'] = atr(df_long['Mid_High'], df_long['Mid_Low'], df_long['Mid_Close'])\n","df_long['atr_sma'] = df_long['atr'].rolling(window=20).mean()\n","df_long['rsi'] = rsi(df_long['Mid_Close'])\n","df_long['rsi_sma'] = df_long['rsi'].rolling(50).mean()\n","df_long['adx'] = adx(df_long['Mid_High'], df_long['Mid_Low'], df_long['Mid_Close'])\n","df_long['macd'] = pd.Series.ewm(df_long['Mid_Close'], span=12).mean() - pd.Series.ewm(df_long['Mid_Close'], span=26).mean()\n","df_long['macdsignal'] = pd.Series.ewm(df_long['macd'], span=9).mean()\n","df_long['slowk_rsi'], df_long['slowd_rsi'] = stoch_rsi(df_long['rsi'])\n","\n","df_long['vo'] = vo(df_long['Volume'])\n","\n","df_long['willy'], df_long['willy_ema'] = williams_r(df_long['Mid_High'], df_long['Mid_Low'], df_long['Mid_Close'])\n","\n","df_long.dropna(inplace=True)\n","df_long.reset_index(drop=True, inplace=True)\n","\n","df_long.drop(['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume'], axis=1, inplace=True)\n","\n","df_long.dropna(inplace=True)\n","df_long.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["value_per_pip = 1.0\n","amounts_per_day = [-0.00008, -0.0001, -0.00012]\n","spread_cutoff = 0.10\n","risk_reward_ratio = 1.5\n","proba_threshold = 0.9\n","reward = 0\n","n_wins, n_losses, n_buys, n_sells = 0, 0, 0, 0\n","\n","def get_n_units(trade_type, stop_loss, ask_open, bid_open, mid_open, currency_pair):\n","    _, second = currency_pair.split('_')\n","  \n","    pips_to_risk = ask_open - stop_loss if trade_type == 'buy' else stop_loss - bid_open\n","    pips_to_risk_calc = pips_to_risk * 10000 if second != 'Jpy' else pips_to_risk * 100\n","\n","    if second == 'Usd':\n","        per_pip = 0.0001\n","\n","    else:\n","        per_pip = 0.0001 / mid_open if second != 'Jpy' else 0.01 / mid_open\n","\n","    n_units = int(50 / (pips_to_risk_calc * per_pip))\n","\n","    return n_units\n","\n","def calculate_day_fees(start_date, end_date, n_units):\n","    curr_fee = np.random.choice(amounts_per_day, p=[0.25, 0.50, 0.25]) * n_units\n","    num_days = np.busday_count(start_date.date(), end_date.date())\n","\n","    return num_days * curr_fee\n","\n","currency_pair = 'Gbp_Usd'\n","rounding = 3 if 'Jpy' in currency_pair else 5\n","buys, sells, nones = [], [], []\n","trade = None\n","\n","for i in range(look_back_size, len(df)):\n","    curr_date = df.loc[df.index[i], 'Date']\n","    curr_long = df_long.loc[df_long['Date'] < curr_date]\n","    if len(curr_long) < look_back_size + 1:\n","        continue\n","\n","    ema200_2, ema100_2, atr2, rsi2, rsi_sma2, vo2, macd2, macdsignal2 = df.loc[df.index[i - 2], ['ema200', 'ema100', 'atr', 'rsi', 'rsi_sma', 'vo', 'macd', 'macdsignal']]\n","    ema200_1, ema100_1, atr1, rsi1, rsi_sma1, vo1, adx1, atr_sma1, macd1, macdsignal1 = df.loc[df.index[i - 1], ['ema200', 'ema100', 'atr', 'rsi', 'rsi_sma', 'vo', 'adx', 'atr_sma', 'macd', 'macdsignal']]\n","    mid_open2, mid_close2, mid_low2, mid_high2 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 2], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","    mid_open1, mid_close1, mid_low1, mid_high1 = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 1], ['Mid_Open', 'Mid_Close', 'Mid_Low', 'Mid_High']]\n","    curr_ao, curr_bo, curr_mid_open, curr_ask_low, curr_bid_high = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i], ['Ask_Open', 'Bid_Open', 'Mid_Open', 'Ask_Low', 'Bid_High']]\n","    spread = abs(curr_ao - curr_bo)\n","\n","    emas_buy_signal = ema200_1 < ema100_1\n","    emas_sell_signal = ema200_1 > ema100_1\n","\n","    # sideways = adx1 < 20 or atr1 < atr_sma1\n","    sideways = False\n","\n","    rsi_buy_signal = rsi1 > rsi_sma1\n","    rsi_sell_signal = rsi1 < rsi_sma1\n","\n","    macd_vals = [0, macd2, macdsignal2, macd1, macdsignal1]\n","\n","    macd_buy_signal = macd2 < macdsignal2 and macd1 > macdsignal1 and max(macd_vals) == 0\n","    macd_sell_signal = macd2 > macdsignal2 and macd1 < macdsignal1 and min(macd_vals) == 0\n","\n","    if trade is None:\n","        if macd_buy_signal and emas_buy_signal and rsi_buy_signal and not sideways:\n","            lowest_low = min(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_Low']))\n","            \n","            open_price = float(curr_ao)\n","            pullback = float(lowest_low) - spread\n","\n","            stop_loss = round(pullback, rounding)\n","\n","            if stop_loss < open_price:\n","                curr_pips_to_risk = open_price - stop_loss\n","\n","                if spread <= curr_pips_to_risk * spread_cutoff:\n","                    curr_seq = df.iloc[i - look_back_size:i, 1:]\n","                    seq2 = curr_long.iloc[-look_back_size:, 1:]\n","                    curr_seq = pd.concat([curr_seq.reset_index(drop=True), seq2.reset_index(drop=True)], axis=1, ignore_index=True)\n","                    curr_seq = grab_image_data(curr_seq)\n","                    pred = model.predict(curr_seq.reshape(1, curr_seq.shape[0], curr_seq.shape[1], curr_seq.shape[2]))\n","                    argmax = np.argmax(pred)\n","                    proba = pred[0][argmax]\n","                    nn_buy_signal = argmax == 1 and proba >= proba_threshold\n","\n","                    if nn_buy_signal:\n","                        stop_gain = round(open_price + (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","                        n_units = get_n_units('buy', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","                        trade = {'open_price': open_price, 'trade_type': 'buy', 'stop_loss': stop_loss,\n","                                                        'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","                                                        'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","                        n_buys += 1\n","\n","        elif macd_sell_signal and emas_sell_signal and rsi_sell_signal and not sideways:\n","            highest_high = max(list(bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i - 12:i], 'Mid_High']))\n","\n","            open_price = float(curr_bo)\n","            pullback = float(highest_high) + spread\n","\n","            stop_loss = round(pullback, rounding)\n","\n","            if stop_loss > open_price:\n","                curr_pips_to_risk = stop_loss - open_price\n","\n","                if spread <= curr_pips_to_risk * spread_cutoff:\n","                    curr_seq = df.iloc[i - look_back_size:i, 1:]\n","                    seq2 = curr_long.iloc[-look_back_size:, 1:]\n","                    curr_seq = pd.concat([curr_seq.reset_index(drop=True), seq2.reset_index(drop=True)], axis=1, ignore_index=True)\n","                    curr_seq = grab_image_data(curr_seq)\n","                    pred = model.predict(curr_seq.reshape(1, curr_seq.shape[0], curr_seq.shape[1], curr_seq.shape[2]))\n","                    argmax = np.argmax(pred)\n","                    proba = pred[0][argmax]\n","                    nn_sell_signal = argmax == 2 and proba >= proba_threshold\n","\n","                    if nn_sell_signal:\n","                        stop_gain = round(open_price - (curr_pips_to_risk * risk_reward_ratio), rounding)\n","\n","                        n_units = get_n_units('sell', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n","\n","                        trade = {'open_price': open_price, 'trade_type': 'sell', 'stop_loss': stop_loss,\n","                                'stop_gain': stop_gain, 'pips_risked': round(curr_pips_to_risk, 5),\n","                                'n_units': n_units, 'original_units': n_units, 'start_date': curr_date, 'end_date': None}\n","\n","                        n_sells += 1\n","\n","    if trade is not None:\n","        curr_date = df.loc[df.index[i], 'Date']\n","        curr_bid_open, curr_bid_high, curr_bid_low, curr_bid_close, curr_ask_open, curr_ask_high, curr_ask_low, curr_ask_close = bid_ask_mid_prices.loc[bid_ask_mid_prices.index[i], ['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close']]\n","\n","        if trade['trade_type'] == 'buy' and curr_bid_low <= trade['stop_loss']:\n","            day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","            reward += -50.0\n","            reward += day_fees\n","\n","            n_losses += 1\n","\n","            trade = None\n","            continue\n","\n","\n","        if trade['trade_type'] == 'buy' and curr_bid_high >= trade['stop_gain']:\n","            trade_amount = (trade['stop_gain'] - trade['open_price']) * trade['n_units'] * value_per_pip\n","            day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","            reward += trade_amount + day_fees\n","\n","            if trade_amount + day_fees > 0:\n","                n_wins += 1\n","\n","            trade = None\n","            continue\n","\n","        if trade['trade_type'] == 'sell' and curr_ask_high >= trade['stop_loss']:\n","            day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","            reward += -50.0\n","            reward += day_fees\n","\n","            n_losses += 1\n","\n","            trade = None\n","            continue\n","\n","        if trade['trade_type'] == 'sell' and curr_ask_low <= trade['stop_gain']:\n","            trade_amount = (trade['open_price'] - trade['stop_gain']) * trade['n_units'] * value_per_pip\n","            day_fees = calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n","\n","            reward += trade_amount + day_fees\n","\n","            if trade_amount + day_fees > 0:\n","                n_wins += 1\n","\n","            trade = None\n","            continue"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Reward = 0\n","Wins = 0\n","Losses = 0\n","Buys = 0\n","Sells = 0\n"]}],"source":["print(f'Reward = {reward}')\n","print(f'Wins = {n_wins}')\n","print(f'Losses = {n_losses}')\n","print(f'Buys = {n_buys}')\n","print(f'Sells = {n_sells}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNNXv50z2GrExQJFFMvQ0O4","collapsed_sections":[],"name":"forex_cnn.ipynb","provenance":[]},"interpreter":{"hash":"2bc6dffc417b633bbbc31cedd954f3e10eebcdab1341647d4de83cb692948a0c"},"kernelspec":{"display_name":"Python 3.9.9 ('forex')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}
