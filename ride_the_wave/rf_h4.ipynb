{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../bar_movement/data/'\n",
    "currency_pair = 'Eur_Usd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path + f'Oanda_{currency_pair}_H4_2015-2023.csv')\n",
    "df.Date = pd.to_datetime(df.Date, utc=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adx(high, low, close, lookback=14):\n",
    "    plus_dm = high.diff()\n",
    "    minus_dm = low.diff()\n",
    "    plus_dm[plus_dm < 0] = 0\n",
    "    minus_dm[minus_dm > 0] = 0\n",
    "    \n",
    "    tr1 = pd.DataFrame(high - low)\n",
    "    tr2 = pd.DataFrame(abs(high - close.shift(1)))\n",
    "    tr3 = pd.DataFrame(abs(low - close.shift(1)))\n",
    "    frames = [tr1, tr2, tr3]\n",
    "    tr = pd.concat(frames, axis = 1, join = 'inner').max(axis = 1)\n",
    "    atr = tr.rolling(lookback).mean()\n",
    "    \n",
    "    plus_di = 100 * (plus_dm.ewm(alpha = 1/lookback).mean() / atr)\n",
    "    minus_di = abs(100 * (minus_dm.ewm(alpha = 1/lookback).mean() / atr))\n",
    "    dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n",
    "    adx = ((dx.shift(1) * (lookback - 1)) + dx) / lookback\n",
    "    adx_smooth = adx.ewm(alpha = 1/lookback).mean()\n",
    "\n",
    "    return adx_smooth\n",
    "\n",
    "def stoch(high, low, close, lookback=14):\n",
    "    high_lookback = high.rolling(lookback).max()\n",
    "    low_lookback = low.rolling(lookback).min()\n",
    "    slow_k = (close - low_lookback) * 100 / (high_lookback - low_lookback)\n",
    "    slow_d = slow_k.rolling(3).mean()\n",
    "\n",
    "    return slow_k, slow_d\n",
    "\n",
    "def chop(df, lookback=14):\n",
    "    atr1 = atr(df['Mid_High'], df['Mid_Low'], df['Mid_Close'], lookback=1)\n",
    "    high, low = df['Mid_High'], df['Mid_Low']\n",
    "\n",
    "    chop = np.log10(atr1.rolling(lookback).sum() / (high.rolling(lookback).max() - low.rolling(lookback).min())) / np.log10(lookback)\n",
    "\n",
    "    return chop\n",
    "\n",
    "def vo(volume, short_lookback=5, long_lookback=10):\n",
    "    short_ema =  pd.Series.ewm(volume, span=short_lookback).mean()\n",
    "    long_ema = pd.Series.ewm(volume, span=long_lookback).mean()\n",
    "\n",
    "    volume_oscillator = (short_ema - long_ema) / long_ema\n",
    "\n",
    "    return volume_oscillator\n",
    "\n",
    "def williams_r(highs, lows, closes, length=21, ema_length=15):\n",
    "    highest_highs = highs.rolling(window=length).max()\n",
    "    lowest_lows = lows.rolling(window=length).min()\n",
    "\n",
    "    willy = 100 * (closes - highest_highs) / (highest_highs - lowest_lows)\n",
    "    willy_ema = pd.Series.ewm(willy, span=ema_length).mean()\n",
    "\n",
    "    return willy, willy_ema\n",
    "\n",
    "def squeeze(barsdata, length=20, length_kc=20, mult=1.5):\n",
    "    # Bollinger bands\n",
    "    m_avg = barsdata['Mid_Close'].rolling(window=length).mean()\n",
    "    m_std = barsdata['Mid_Close'].rolling(window=length).std(ddof=0)\n",
    "    upper_bb = m_avg + mult * m_std\n",
    "    lower_bb = m_avg - mult * m_std\n",
    "\n",
    "    # Keltner channel\n",
    "    tr0 = abs(barsdata['Mid_High'] - barsdata['Mid_Low'])\n",
    "    tr1 = abs(barsdata['Mid_High'] - barsdata['Mid_Close'].shift())\n",
    "    tr2 = abs(barsdata['Mid_Low'] - barsdata['Mid_Close'].shift())\n",
    "    tr = pd.concat([tr0, tr1, tr2], axis=1).max(axis=1)\n",
    "    range_ma = tr.rolling(window=length_kc).mean()\n",
    "    upper_kc = m_avg + range_ma * mult\n",
    "    lower_kc = m_avg - range_ma * mult\n",
    "\n",
    "    # Squeeze\n",
    "    squeeze_on = (lower_bb > lower_kc) & (upper_bb < upper_kc)\n",
    "\n",
    "    return squeeze_on\n",
    "\n",
    "def atr(high, low, close, lookback=14):\n",
    "    high_low = high - low\n",
    "    high_close = np.abs(high - close.shift())\n",
    "    low_close = np.abs(low - close.shift())\n",
    "    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "    true_range = np.max(ranges, axis=1)\n",
    "\n",
    "    return true_range.rolling(lookback).mean()\n",
    "\n",
    "def atr_bands(high, low, close, lookback=14, atr_multiplier=3):\n",
    "    scaled_atr_vals = atr(high, low, close, lookback) * atr_multiplier\n",
    "    lower_band = close - scaled_atr_vals\n",
    "    upper_band = close + scaled_atr_vals\n",
    "\n",
    "    return lower_band, upper_band\n",
    "\n",
    "def rsi(closes, periods=14):\n",
    "    close_delta = closes.diff()\n",
    "\n",
    "    up = close_delta.clip(lower=0)\n",
    "    down = -1 * close_delta.clip(upper=0)\n",
    "    ma_up = up.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "    ma_down = down.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "        \n",
    "    rsi = ma_up / ma_down\n",
    "    rsi = 100 - (100 / (1 + rsi))\n",
    "\n",
    "    return rsi\n",
    "\n",
    "def qqe_mod(closes, rsi_period=6, smoothing=5, qqe_factor=3, threshold=3, mult=0.35, sma_length=50):\n",
    "    Rsi = rsi(closes, rsi_period)\n",
    "    RsiMa = Rsi.ewm(span=smoothing).mean()\n",
    "    AtrRsi = np.abs(RsiMa.shift(1) - RsiMa)\n",
    "    Wilders_Period = rsi_period * 2 - 1\n",
    "    MaAtrRsi = AtrRsi.ewm(span=Wilders_Period).mean()\n",
    "    dar = MaAtrRsi.ewm(span=Wilders_Period).mean() * qqe_factor\n",
    "\n",
    "    longband = pd.Series(0.0, index=Rsi.index)\n",
    "    shortband = pd.Series(0.0, index=Rsi.index)\n",
    "    trend = pd.Series(0, index=Rsi.index)\n",
    "\n",
    "    DeltaFastAtrRsi = dar\n",
    "    RSIndex = RsiMa\n",
    "    newshortband = RSIndex + DeltaFastAtrRsi\n",
    "    newlongband = RSIndex - DeltaFastAtrRsi\n",
    "    longband = pd.Series(np.where((RSIndex.shift(1) > longband.shift(1)) & (RSIndex > longband.shift(1)),\n",
    "                        np.maximum(longband.shift(1), newlongband), newlongband))\n",
    "    shortband = pd.Series(np.where((RSIndex.shift(1) < shortband.shift(1)) & (RSIndex < shortband.shift(1)),\n",
    "                        np.minimum(shortband.shift(1), newshortband), newshortband))\n",
    "    cross_1 = (longband.shift(1) < RSIndex) & (longband > RSIndex)\n",
    "    cross_2 = (RSIndex > shortband.shift(1)) & (RSIndex.shift(1) < shortband)\n",
    "    trend = np.where(cross_2, 1, np.where(cross_1, -1, trend.shift(1).fillna(1)))\n",
    "    FastAtrRsiTL = pd.Series(np.where(trend == 1, longband, shortband))\n",
    "\n",
    "    basis = (FastAtrRsiTL - 50).rolling(sma_length).mean()\n",
    "    dev = mult * (FastAtrRsiTL - 50).rolling(sma_length).std()\n",
    "    upper = basis + dev\n",
    "    lower = basis - dev\n",
    "\n",
    "    Greenbar1 = RsiMa - 50 > threshold\n",
    "    Greenbar2 = RsiMa - 50 > upper\n",
    "\n",
    "    Redbar1 = RsiMa - 50 < 0 - threshold\n",
    "    Redbar2 = RsiMa - 50 < lower\n",
    "\n",
    "    Greenbar = Greenbar1 & Greenbar2\n",
    "    Redbar = Redbar1 & Redbar2\n",
    "\n",
    "    return Greenbar, Redbar, RsiMa - 50\n",
    "\n",
    "def heikin_ashi(open_values, high_values, low_values, close_values):\n",
    "    ha_close = (open_values + high_values + low_values + close_values) / 4\n",
    "\n",
    "    ha_open = pd.Series(0.0, index=open_values.index)\n",
    "    ha_open.iloc[0] = open_values.iloc[0]\n",
    "\n",
    "    for i in range(1, len(open_values)):\n",
    "        ha_open.iloc[i] = (ha_open.iloc[i - 1] + ha_close.iloc[i - 1]) / 2\n",
    "\n",
    "    ha_high = pd.concat([ha_open, ha_close, high_values], axis=1).max(axis=1)\n",
    "    ha_low = pd.concat([ha_open, ha_close, low_values], axis=1).min(axis=1)\n",
    "\n",
    "    return ha_open, ha_high, ha_low, ha_close\n",
    "\n",
    "def trend_indicator(opens, highs, lows, closes, ema_period=50, smoothing_period=10):\n",
    "    ha_open, _, _, ha_close = heikin_ashi(opens, highs, lows, closes)\n",
    "\n",
    "    ha_o_ema = pd.Series.ewm(ha_open, span=ema_period).mean()\n",
    "    ha_c_ema = pd.Series.ewm(ha_close, span=ema_period).mean()\n",
    "\n",
    "    ha_o_ema_smooth = pd.Series.ewm(ha_o_ema, span=smoothing_period).mean()\n",
    "    ha_c_ema_smooth = pd.Series.ewm(ha_c_ema, span=smoothing_period).mean()\n",
    "\n",
    "    return ha_c_ema_smooth > ha_o_ema_smooth\n",
    "\n",
    "def supertrend(barsdata, atr_len=10, mult=3):\n",
    "    curr_atr = atr(barsdata['Mid_High'], barsdata['Mid_Low'], barsdata['Mid_Close'], lookback=atr_len)\n",
    "    highs, lows = barsdata['Mid_High'], barsdata['Mid_Low']\n",
    "    hl2 = (highs + lows) / 2\n",
    "    final_upperband = hl2 + mult * curr_atr\n",
    "    final_lowerband = hl2 - mult * curr_atr\n",
    "\n",
    "    # initialize Supertrend column to True\n",
    "    supertrend = [True] * len(df)\n",
    "\n",
    "    close = barsdata['Mid_Close']\n",
    "    \n",
    "    for i in range(1, len(df.index)):\n",
    "        curr, prev = i, i - 1\n",
    "        \n",
    "        # if current close price crosses above upperband\n",
    "        if close[curr] > final_upperband[prev]:\n",
    "            supertrend[curr] = True\n",
    "\n",
    "        # if current close price crosses below lowerband\n",
    "        elif close[curr] < final_lowerband[prev]:\n",
    "            supertrend[curr] = False\n",
    "\n",
    "        # else, the trend continues\n",
    "        else:\n",
    "            supertrend[curr] = supertrend[prev]\n",
    "            \n",
    "            # adjustment to the final bands\n",
    "            if supertrend[curr] == True and final_lowerband[curr] < final_lowerband[prev]:\n",
    "                final_lowerband[curr] = final_lowerband[prev]\n",
    "\n",
    "            if supertrend[curr] == False and final_upperband[curr] > final_upperband[prev]:\n",
    "                final_upperband[curr] = final_upperband[prev]\n",
    "\n",
    "    return supertrend, final_upperband, final_lowerband\n",
    "\n",
    "def fractal(lows, highs, window=20):\n",
    "    assert len(lows) == len(highs)\n",
    "\n",
    "    fractal_period = 2 * window + 1\n",
    "\n",
    "    is_support = lows.rolling(fractal_period, center=True).apply(lambda x: x[window] == min(x), raw=True)\n",
    "    is_resistance = highs.rolling(fractal_period, center=True).apply(lambda x: x[window] == max(x), raw=True)\n",
    "    \n",
    "    is_support_indices = pd.Series(is_support.index[is_support == 1.0])\n",
    "    is_resistance_indices = pd.Series(is_resistance.index[is_resistance == 1.0])\n",
    "\n",
    "    support_fractal_vals = lows[is_support_indices].reindex(lows.index).ffill()\n",
    "    resistance_fractal_vals = highs[is_resistance_indices].reindex(highs.index).ffill()\n",
    "\n",
    "    return support_fractal_vals, resistance_fractal_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pips_multiplier = 100 if 'Jpy' in currency_pair else 10000\n",
    "\n",
    "df['rsi'] = rsi(df['Mid_Close'])\n",
    "df['rsi_ema'] = pd.Series.ewm(df['rsi'], span=50).mean()\n",
    "df['adx'] = adx(df['Mid_High'], df['Mid_Low'], df['Mid_Close'])\n",
    "df['chop'] = chop(df)\n",
    "df['vo'] = vo(df['Volume'])\n",
    "df['qqe_up'], df['qqe_down'], df['qqe_val'] = qqe_mod(df['Mid_Close'])\n",
    "df['rsi_up'] = df['rsi'] > df['rsi_ema']\n",
    "df['adx_large'] = df['adx'] > 30\n",
    "df['chop_small'] = df['chop'] < 0.5\n",
    "df['vo_positive'] = df['vo'] > 0\n",
    "df['ask_pips_up'], df['ask_pips_down'] = abs(df['Ask_High'] - df['Ask_Open']), abs(df['Ask_Open'] - df['Ask_Low'])\n",
    "df['ask_pips_up_ema'], df['ask_pips_down_ema'] = pd.Series.ewm(df['ask_pips_up'], span=50).mean(), pd.Series.ewm(df['ask_pips_down'], span=50).mean()\n",
    "df['bid_pips_up'], df['bid_pips_down'] = abs(df['Bid_High'] - df['Bid_Open']), abs(df['Bid_Open'] - df['Bid_Low'])\n",
    "df['bid_pips_up_ema'], df['bid_pips_down_ema'] = pd.Series.ewm(df['bid_pips_up'], span=50).mean(), pd.Series.ewm(df['bid_pips_down'], span=50).mean()\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "prices = df[['Date', 'Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume']]\n",
    "df.drop(['Bid_Open', 'Bid_High', 'Bid_Low', 'Bid_Close', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Ask_Close', 'Mid_Open', 'Mid_High', 'Mid_Low', 'Mid_Close', 'Volume'], axis=1, inplace=True)\n",
    "\n",
    "assert len(prices) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = '2022-06-15 05:00:00'\n",
    "\n",
    "df_train = df.loc[df['Date'] <= cutoff_date]\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "prices_train = prices.loc[prices['Date'] <= cutoff_date]\n",
    "prices_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_test = df.loc[df['Date'] > cutoff_date]\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "prices_test = prices.loc[prices['Date'] > cutoff_date]\n",
    "prices_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_train.drop(['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_train = scaler.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = 0.99\n",
    "\n",
    "pca = PCA(n_components=explained_variance)\n",
    "df_train = pca.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(df_train)):\n",
    "    mid_open, mid_high, mid_low, ask_open, ask_high, ask_low, bid_open, bid_high, bid_low = prices_train.loc[prices_train.index[i], ['Mid_Open', 'Mid_High', 'Mid_Low', 'Ask_Open', 'Ask_High', 'Ask_Low', 'Bid_Open', 'Bid_High', 'Bid_Low']]\n",
    "\n",
    "    ask_pips_up, ask_pips_down, bid_pips_up, bid_pips_down = abs(ask_high - ask_open) * pips_multiplier, abs(ask_open - ask_low) * pips_multiplier, abs(bid_high - bid_open) * pips_multiplier, abs(bid_open - bid_low) * pips_multiplier\n",
    "    training_data.append([np.array(df_train[i - 1, :]), np.array([ask_pips_up, ask_pips_down, bid_pips_up, bid_pips_down])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(training_data)\n",
    "\n",
    "train_set_ratio = 0.7\n",
    "cutoff_index = int(len(training_data) * train_set_ratio)\n",
    "train_set, validation_set = training_data[:cutoff_index], training_data[cutoff_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7622, 14) (7622, 4) (3267, 14) (3267, 4)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for seq, target in train_set:\n",
    "  x_train.append(seq)\n",
    "  y_train.append(target)\n",
    "\n",
    "x_validation = []\n",
    "y_validation = []\n",
    "\n",
    "for seq, target in validation_set:\n",
    "  x_validation.append(seq)\n",
    "  y_validation.append(target)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_validation = np.array(x_validation)\n",
    "y_validation = np.array(y_validation)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_validation.shape, y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num runs: 432\n",
      "Remaining runs: 431\n",
      "Remaining runs: 430\n",
      "Remaining runs: 429\n",
      "Remaining runs: 428\n",
      "Remaining runs: 427\n",
      "Remaining runs: 426\n",
      "Remaining runs: 425\n",
      "Remaining runs: 424\n",
      "Remaining runs: 423\n",
      "Remaining runs: 422\n",
      "Remaining runs: 421\n",
      "Remaining runs: 420\n",
      "Remaining runs: 419\n",
      "Remaining runs: 418\n",
      "Remaining runs: 417\n",
      "Remaining runs: 416\n",
      "Remaining runs: 415\n",
      "Remaining runs: 414\n",
      "Remaining runs: 413\n",
      "Remaining runs: 412\n",
      "Remaining runs: 411\n",
      "Remaining runs: 410\n",
      "Remaining runs: 409\n",
      "Remaining runs: 408\n",
      "Remaining runs: 407\n",
      "Remaining runs: 406\n",
      "Remaining runs: 405\n",
      "Remaining runs: 404\n",
      "Remaining runs: 403\n",
      "Remaining runs: 402\n",
      "Remaining runs: 401\n",
      "Remaining runs: 400\n",
      "Remaining runs: 399\n",
      "Remaining runs: 398\n",
      "Remaining runs: 397\n",
      "Remaining runs: 396\n",
      "Remaining runs: 395\n",
      "Remaining runs: 394\n",
      "Remaining runs: 393\n",
      "Remaining runs: 392\n",
      "Remaining runs: 391\n",
      "Remaining runs: 390\n",
      "Remaining runs: 389\n",
      "Remaining runs: 388\n",
      "Remaining runs: 387\n",
      "Remaining runs: 386\n",
      "Remaining runs: 385\n",
      "Remaining runs: 384\n",
      "Remaining runs: 383\n",
      "Remaining runs: 382\n",
      "Remaining runs: 381\n",
      "Remaining runs: 380\n",
      "Remaining runs: 379\n",
      "Remaining runs: 378\n",
      "Remaining runs: 377\n",
      "Remaining runs: 376\n",
      "Remaining runs: 375\n",
      "Remaining runs: 374\n",
      "Remaining runs: 373\n",
      "Remaining runs: 372\n",
      "Remaining runs: 371\n",
      "Remaining runs: 370\n",
      "Remaining runs: 369\n",
      "Remaining runs: 368\n",
      "Remaining runs: 367\n",
      "Remaining runs: 366\n",
      "Remaining runs: 365\n",
      "Remaining runs: 364\n",
      "Remaining runs: 363\n",
      "Remaining runs: 362\n",
      "Remaining runs: 361\n",
      "Remaining runs: 360\n",
      "Remaining runs: 359\n",
      "Remaining runs: 358\n",
      "Remaining runs: 357\n",
      "Remaining runs: 356\n",
      "Remaining runs: 355\n",
      "Remaining runs: 354\n",
      "Remaining runs: 353\n",
      "Remaining runs: 352\n",
      "Remaining runs: 351\n",
      "Remaining runs: 350\n",
      "Remaining runs: 349\n",
      "Remaining runs: 348\n",
      "Remaining runs: 347\n",
      "Remaining runs: 346\n",
      "Remaining runs: 345\n",
      "Remaining runs: 344\n",
      "Remaining runs: 343\n",
      "Remaining runs: 342\n",
      "Remaining runs: 341\n",
      "Remaining runs: 340\n",
      "Remaining runs: 339\n",
      "Remaining runs: 338\n",
      "Remaining runs: 337\n",
      "Remaining runs: 336\n",
      "Remaining runs: 335\n",
      "Remaining runs: 334\n",
      "Remaining runs: 333\n",
      "Remaining runs: 332\n",
      "Remaining runs: 331\n",
      "Remaining runs: 330\n",
      "Remaining runs: 329\n",
      "Remaining runs: 328\n",
      "Remaining runs: 327\n",
      "Remaining runs: 326\n",
      "Remaining runs: 325\n",
      "Remaining runs: 324\n",
      "Remaining runs: 323\n",
      "Remaining runs: 322\n",
      "Remaining runs: 321\n",
      "Remaining runs: 320\n",
      "Remaining runs: 319\n",
      "Remaining runs: 318\n",
      "Remaining runs: 317\n",
      "Remaining runs: 316\n",
      "Remaining runs: 315\n",
      "Remaining runs: 314\n",
      "Remaining runs: 313\n",
      "Remaining runs: 312\n",
      "Remaining runs: 311\n",
      "Remaining runs: 310\n",
      "Remaining runs: 309\n",
      "Remaining runs: 308\n",
      "Remaining runs: 307\n",
      "Remaining runs: 306\n",
      "Remaining runs: 305\n",
      "Remaining runs: 304\n",
      "Remaining runs: 303\n",
      "Remaining runs: 302\n",
      "Remaining runs: 301\n",
      "Remaining runs: 300\n",
      "Remaining runs: 299\n",
      "Remaining runs: 298\n",
      "Remaining runs: 297\n",
      "Remaining runs: 296\n",
      "Remaining runs: 295\n",
      "Remaining runs: 294\n",
      "Remaining runs: 293\n",
      "Remaining runs: 292\n",
      "Remaining runs: 291\n",
      "Remaining runs: 290\n",
      "Remaining runs: 289\n",
      "Remaining runs: 288\n",
      "Remaining runs: 287\n",
      "Remaining runs: 286\n",
      "Remaining runs: 285\n",
      "Remaining runs: 284\n",
      "Remaining runs: 283\n",
      "Remaining runs: 282\n",
      "Remaining runs: 281\n",
      "Remaining runs: 280\n",
      "Remaining runs: 279\n",
      "Remaining runs: 278\n",
      "Remaining runs: 277\n",
      "Remaining runs: 276\n",
      "Remaining runs: 275\n",
      "Remaining runs: 274\n",
      "Remaining runs: 273\n",
      "Remaining runs: 272\n",
      "Remaining runs: 271\n",
      "Remaining runs: 270\n",
      "Remaining runs: 269\n",
      "Remaining runs: 268\n",
      "Remaining runs: 267\n",
      "Remaining runs: 266\n",
      "Remaining runs: 265\n",
      "Remaining runs: 264\n",
      "Remaining runs: 263\n",
      "Remaining runs: 262\n",
      "Remaining runs: 261\n",
      "Remaining runs: 260\n",
      "Remaining runs: 259\n",
      "Remaining runs: 258\n",
      "Remaining runs: 257\n",
      "Remaining runs: 256\n",
      "Remaining runs: 255\n",
      "Remaining runs: 254\n",
      "Remaining runs: 253\n",
      "Remaining runs: 252\n",
      "Remaining runs: 251\n",
      "Remaining runs: 250\n",
      "Remaining runs: 249\n",
      "Remaining runs: 248\n",
      "Remaining runs: 247\n",
      "Remaining runs: 246\n",
      "Remaining runs: 245\n",
      "Remaining runs: 244\n",
      "Remaining runs: 243\n",
      "Remaining runs: 242\n",
      "Remaining runs: 241\n",
      "Remaining runs: 240\n",
      "Remaining runs: 239\n",
      "Remaining runs: 238\n",
      "Remaining runs: 237\n",
      "Remaining runs: 236\n",
      "Remaining runs: 235\n",
      "Remaining runs: 234\n",
      "Remaining runs: 233\n",
      "Remaining runs: 232\n",
      "Remaining runs: 231\n",
      "Remaining runs: 230\n",
      "Remaining runs: 229\n",
      "Remaining runs: 228\n",
      "Remaining runs: 227\n",
      "Remaining runs: 226\n",
      "Remaining runs: 225\n",
      "Remaining runs: 224\n",
      "Remaining runs: 223\n",
      "Remaining runs: 222\n",
      "Remaining runs: 221\n",
      "Remaining runs: 220\n",
      "Remaining runs: 219\n",
      "Remaining runs: 218\n",
      "Remaining runs: 217\n",
      "Remaining runs: 216\n",
      "Remaining runs: 215\n",
      "Remaining runs: 214\n",
      "Remaining runs: 213\n",
      "Remaining runs: 212\n",
      "Remaining runs: 211\n",
      "Remaining runs: 210\n",
      "Remaining runs: 209\n",
      "Remaining runs: 208\n",
      "Remaining runs: 207\n",
      "Remaining runs: 206\n",
      "Remaining runs: 205\n",
      "Remaining runs: 204\n",
      "Remaining runs: 203\n",
      "Remaining runs: 202\n",
      "Remaining runs: 201\n",
      "Remaining runs: 200\n",
      "Remaining runs: 199\n",
      "Remaining runs: 198\n",
      "Remaining runs: 197\n",
      "Remaining runs: 196\n",
      "Remaining runs: 195\n",
      "Remaining runs: 194\n",
      "Remaining runs: 193\n",
      "Remaining runs: 192\n",
      "Remaining runs: 191\n",
      "Remaining runs: 190\n",
      "Remaining runs: 189\n",
      "Remaining runs: 188\n",
      "Remaining runs: 187\n",
      "Remaining runs: 186\n",
      "Remaining runs: 185\n",
      "Remaining runs: 184\n",
      "Remaining runs: 183\n",
      "Remaining runs: 182\n",
      "Remaining runs: 181\n",
      "Remaining runs: 180\n",
      "Remaining runs: 179\n",
      "Remaining runs: 178\n",
      "Remaining runs: 177\n",
      "Remaining runs: 176\n",
      "Remaining runs: 175\n",
      "Remaining runs: 174\n",
      "Remaining runs: 173\n",
      "Remaining runs: 172\n",
      "Remaining runs: 171\n",
      "Remaining runs: 170\n",
      "Remaining runs: 169\n",
      "Remaining runs: 168\n",
      "Remaining runs: 167\n",
      "Remaining runs: 166\n",
      "Remaining runs: 165\n",
      "Remaining runs: 164\n",
      "Remaining runs: 163\n",
      "Remaining runs: 162\n",
      "Remaining runs: 161\n",
      "Remaining runs: 160\n",
      "Remaining runs: 159\n",
      "Remaining runs: 158\n",
      "Remaining runs: 157\n",
      "Remaining runs: 156\n",
      "Remaining runs: 155\n",
      "Remaining runs: 154\n",
      "Remaining runs: 153\n",
      "Remaining runs: 152\n",
      "Remaining runs: 151\n",
      "Remaining runs: 150\n",
      "Remaining runs: 149\n",
      "Remaining runs: 148\n",
      "Remaining runs: 147\n",
      "Remaining runs: 146\n",
      "Remaining runs: 145\n",
      "Remaining runs: 144\n",
      "Remaining runs: 143\n",
      "Remaining runs: 142\n",
      "Remaining runs: 141\n",
      "Remaining runs: 140\n",
      "Remaining runs: 139\n",
      "Remaining runs: 138\n",
      "Remaining runs: 137\n",
      "Remaining runs: 136\n",
      "Remaining runs: 135\n",
      "Remaining runs: 134\n",
      "Remaining runs: 133\n",
      "Remaining runs: 132\n",
      "Remaining runs: 131\n",
      "Remaining runs: 130\n",
      "Remaining runs: 129\n",
      "Remaining runs: 128\n",
      "Remaining runs: 127\n",
      "Remaining runs: 126\n",
      "Remaining runs: 125\n",
      "Remaining runs: 124\n",
      "Remaining runs: 123\n",
      "Remaining runs: 122\n",
      "Remaining runs: 121\n",
      "Remaining runs: 120\n",
      "Remaining runs: 119\n",
      "Remaining runs: 118\n",
      "Remaining runs: 117\n",
      "Remaining runs: 116\n",
      "Remaining runs: 115\n",
      "Remaining runs: 114\n",
      "Remaining runs: 113\n",
      "Remaining runs: 112\n",
      "Remaining runs: 111\n",
      "Remaining runs: 110\n",
      "Remaining runs: 109\n",
      "Remaining runs: 108\n",
      "Remaining runs: 107\n",
      "Remaining runs: 106\n",
      "Remaining runs: 105\n",
      "Remaining runs: 104\n",
      "Remaining runs: 103\n",
      "Remaining runs: 102\n",
      "Remaining runs: 101\n",
      "Remaining runs: 100\n",
      "Remaining runs: 99\n",
      "Remaining runs: 98\n",
      "Remaining runs: 97\n",
      "Remaining runs: 96\n",
      "Remaining runs: 95\n",
      "Remaining runs: 94\n",
      "Remaining runs: 93\n",
      "Remaining runs: 92\n",
      "Remaining runs: 91\n",
      "Remaining runs: 90\n",
      "Remaining runs: 89\n",
      "Remaining runs: 88\n",
      "Remaining runs: 87\n",
      "Remaining runs: 86\n",
      "Remaining runs: 85\n",
      "Remaining runs: 84\n",
      "Remaining runs: 83\n",
      "Remaining runs: 82\n",
      "Remaining runs: 81\n",
      "Remaining runs: 80\n",
      "Remaining runs: 79\n",
      "Remaining runs: 78\n",
      "Remaining runs: 77\n",
      "Remaining runs: 76\n",
      "Remaining runs: 75\n",
      "Remaining runs: 74\n",
      "Remaining runs: 73\n",
      "Remaining runs: 72\n",
      "Remaining runs: 71\n",
      "Remaining runs: 70\n",
      "Remaining runs: 69\n",
      "Remaining runs: 68\n",
      "Remaining runs: 67\n",
      "Remaining runs: 66\n",
      "Remaining runs: 65\n",
      "Remaining runs: 64\n",
      "Remaining runs: 63\n",
      "Remaining runs: 62\n",
      "Remaining runs: 61\n",
      "Remaining runs: 60\n",
      "Remaining runs: 59\n",
      "Remaining runs: 58\n",
      "Remaining runs: 57\n",
      "Remaining runs: 56\n",
      "Remaining runs: 55\n",
      "Remaining runs: 54\n",
      "Remaining runs: 53\n",
      "Remaining runs: 52\n",
      "Remaining runs: 51\n",
      "Remaining runs: 50\n",
      "Remaining runs: 49\n",
      "Remaining runs: 48\n",
      "Remaining runs: 47\n",
      "Remaining runs: 46\n",
      "Remaining runs: 45\n",
      "Remaining runs: 44\n",
      "Remaining runs: 43\n",
      "Remaining runs: 42\n",
      "Remaining runs: 41\n",
      "Remaining runs: 40\n",
      "Remaining runs: 39\n",
      "Remaining runs: 38\n",
      "Remaining runs: 37\n",
      "Remaining runs: 36\n",
      "Remaining runs: 35\n",
      "Remaining runs: 34\n",
      "Remaining runs: 33\n",
      "Remaining runs: 32\n",
      "Remaining runs: 31\n",
      "Remaining runs: 30\n",
      "Remaining runs: 29\n",
      "Remaining runs: 28\n",
      "Remaining runs: 27\n",
      "Remaining runs: 26\n",
      "Remaining runs: 25\n",
      "Remaining runs: 24\n",
      "Remaining runs: 23\n",
      "Remaining runs: 22\n",
      "Remaining runs: 21\n",
      "Remaining runs: 20\n",
      "Remaining runs: 19\n",
      "Remaining runs: 18\n",
      "Remaining runs: 17\n",
      "Remaining runs: 16\n",
      "Remaining runs: 15\n",
      "Remaining runs: 14\n",
      "Remaining runs: 13\n",
      "Remaining runs: 12\n",
      "Remaining runs: 11\n",
      "Remaining runs: 10\n",
      "Remaining runs: 9\n",
      "Remaining runs: 8\n",
      "Remaining runs: 7\n",
      "Remaining runs: 6\n",
      "Remaining runs: 5\n",
      "Remaining runs: 4\n",
      "Remaining runs: 3\n",
      "Remaining runs: 2\n",
      "Remaining runs: 1\n",
      "Remaining runs: 0\n"
     ]
    }
   ],
   "source": [
    "all_combos = []\n",
    "\n",
    "for n_estimators in [5, 10, 15, 20, 25, 50]:\n",
    "    for min_samples_leaf in [5, 10, 15, 20, 25, 50]:\n",
    "        for max_depth in [3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "            for min_samples_split in [2, 3, 4, 5, 10, 15]:\n",
    "                all_combos.append((n_estimators, min_samples_leaf, max_depth, min_samples_split))\n",
    "\n",
    "percentage_to_try = 0.25\n",
    "n_runs = int(percentage_to_try * len(all_combos))\n",
    "combos_to_try = random.sample(all_combos, n_runs)\n",
    "print(f'Num runs: {n_runs}')\n",
    "\n",
    "best_validation_mse = np.inf\n",
    "model = None\n",
    "\n",
    "for n_estimators, min_samples_leaf, max_depth, min_samples_split in combos_to_try:\n",
    "    curr_model = RandomForestRegressor(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "    curr_model.fit(x_train, y_train)\n",
    "\n",
    "    y_validation_pred = curr_model.predict(x_validation)\n",
    "    validation_mse = np.square(y_validation_pred - y_validation).mean()\n",
    "\n",
    "    if validation_mse < best_validation_mse:\n",
    "        best_validation_mse, model = validation_mse, curr_model\n",
    "\n",
    "    n_runs -= 1\n",
    "    print(f'Remaining runs: {n_runs}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239.3883641753995"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_validation_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./rf_h4_{currency_pair.lower()}.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(f'./rf_h4_scaler_{currency_pair.lower()}.pickle', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open(f'./rf_h4_pca_{currency_pair.lower()}.pickle', 'wb') as f:\n",
    "    pickle.dump(pca, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(f'./rf_h4_{currency_pair.lower()}.pickle', 'rb'))\n",
    "scaler = pickle.load(open(f'./rf_h4_scaler_{currency_pair.lower()}.pickle', 'rb'))\n",
    "pca = pickle.load(open(f'./rf_h4_pca_{currency_pair.lower()}.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_per_pip = 1.0\n",
    "amounts_per_day = [-0.008, -0.01, -0.012] if 'Jpy' in currency_pair else [-0.00008, -0.0001, -0.00012]\n",
    "rounding = 3 if 'Jpy' in currency_pair else 5\n",
    "df = pd.read_csv(file_path + f'Oanda_{currency_pair}_M5_2022-2023.csv')\n",
    "df.Date = pd.to_datetime(df.Date, utc=True)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# validation_avg_error = 266.24554306862154 ** 0.5\n",
    "validation_avg_error = 239.3883641753995 ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_units(trade_type, stop_loss, ask_open, bid_open, mid_open, currency_pair):\n",
    "    _, second = currency_pair.split('_')\n",
    "  \n",
    "    pips_to_risk = ask_open - stop_loss if trade_type == 'buy' else stop_loss - bid_open\n",
    "    pips_to_risk_calc = pips_to_risk * 10000 if second != 'Jpy' else pips_to_risk * 100\n",
    "\n",
    "    if second == 'Usd':\n",
    "        per_pip = 0.0001\n",
    "\n",
    "    else:\n",
    "        per_pip = 0.0001 / mid_open if second != 'Jpy' else 0.01 / mid_open\n",
    "\n",
    "    n_units = int(50 / (pips_to_risk_calc * per_pip))\n",
    "\n",
    "    return n_units\n",
    "\n",
    "def calculate_day_fees(start_date, end_date, n_units):\n",
    "    curr_fee = np.random.choice(amounts_per_day, p=[0.25, 0.50, 0.25]) * n_units\n",
    "    num_days = np.busday_count(start_date.date(), end_date.date())\n",
    "\n",
    "    return num_days * curr_fee\n",
    "\n",
    "def run_simulation(pips_to_risk, adapt_errors, error_array_len, error_multiplier, invert):\n",
    "    reward, day_fees, n_wins, n_losses, win_streak, loss_streak, curr_win_streak, curr_loss_streak, n_buys, n_sells = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    pips_risked, win_amounts, loss_amounts = [], [], []\n",
    "    prev_long_date, trade = None, None\n",
    "    sl_pips = pips_to_risk / pips_multiplier\n",
    "\n",
    "    ask_pips_up_errors, ask_pips_down_errors, bid_pips_up_errors, bid_pips_down_errors = deque(maxlen=error_array_len), deque(maxlen=error_array_len), deque(maxlen=error_array_len), deque(maxlen=error_array_len)\n",
    "\n",
    "    for _ in range(error_array_len):\n",
    "        ask_pips_up_errors.append(validation_avg_error)\n",
    "        ask_pips_down_errors.append(validation_avg_error)\n",
    "        bid_pips_up_errors.append(validation_avg_error)\n",
    "        bid_pips_down_errors.append(validation_avg_error)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        curr_date, curr_ao, curr_bo, curr_mid_open, curr_ask_low, curr_bid_high, curr_bid_low, curr_ask_high, curr_bid_close, curr_ask_close = df.loc[df.index[i], ['Date', 'Ask_Open', 'Bid_Open', 'Mid_Open', 'Ask_Low', 'Bid_High', 'Bid_Low', 'Ask_High', 'Bid_Close', 'Ask_Close']]\n",
    "        spread = abs(curr_ao - curr_bo)\n",
    "\n",
    "        curr_long_df = df_test.loc[df_test.Date <= curr_date]\n",
    "        gte = df_test.loc[df_test.Date >= curr_date]\n",
    "\n",
    "        if len(gte) == 0:\n",
    "            break\n",
    "\n",
    "        curr_long_df_len = len(curr_long_df)\n",
    "\n",
    "        if curr_long_df_len < 2:\n",
    "            continue\n",
    "\n",
    "        curr_long_date = curr_long_df.loc[curr_long_df.index[-2], 'Date']\n",
    "\n",
    "        if trade is None and curr_long_date != prev_long_date:\n",
    "            prev_long_date = curr_long_date\n",
    "\n",
    "            # seq = scaler.transform(np.array(curr_long_df.iloc[-2, 1:]).reshape(1, -1))\n",
    "            seq = pca.transform(scaler.transform(np.array(curr_long_df.iloc[-2, 1:]).reshape(1, -1)))\n",
    "\n",
    "            ask_pips_up_pred, ask_pips_down_pred, bid_pips_up_pred, bid_pips_down_pred = model.predict(seq.reshape(1, -1))[0]\n",
    "\n",
    "            ask_pips_up_error_avg = np.array(ask_pips_up_errors).mean() if adapt_errors else validation_avg_error\n",
    "            ask_pips_down_error_avg = np.array(ask_pips_down_errors).mean() if adapt_errors else validation_avg_error\n",
    "            bid_pips_up_error_avg = np.array(bid_pips_up_errors).mean() if adapt_errors else validation_avg_error\n",
    "            bid_pips_down_error_avg = np.array(bid_pips_down_errors).mean() if adapt_errors else validation_avg_error\n",
    "\n",
    "            if adapt_errors:\n",
    "                curr_prices_long = prices_test.loc[prices_test.Date <= curr_date]\n",
    "                ask_open, ask_high, ask_low, bid_open, bid_high, bid_low = curr_prices_long.loc[curr_prices_long.index[-1], ['Ask_Open', 'Ask_High', 'Ask_Low', 'Bid_Open', 'Bid_High', 'Bid_Low']]\n",
    "                ask_pips_up_true, ask_pips_down_true, bid_pips_up_true, bid_pips_down_true = abs(ask_high - ask_open) * pips_multiplier, abs(ask_open - ask_low) * pips_multiplier, abs(bid_high - bid_open) * pips_multiplier, abs(bid_open - bid_low) * pips_multiplier\n",
    "\n",
    "                ask_pips_up_errors.append(abs(ask_pips_up_true - ask_pips_up_pred))\n",
    "                ask_pips_down_errors.append(abs(ask_pips_down_true - ask_pips_down_pred))\n",
    "                bid_pips_up_errors.append(abs(bid_pips_up_true - bid_pips_up_pred))\n",
    "                bid_pips_down_errors.append(abs(bid_pips_down_true - bid_pips_down_pred))\n",
    "\n",
    "            \n",
    "            ask_pips_up_pred = ask_pips_up_pred + (ask_pips_up_error_avg * error_multiplier)\n",
    "            ask_pips_down_pred = ask_pips_down_pred + (ask_pips_down_error_avg * error_multiplier)\n",
    "            bid_pips_up_pred = bid_pips_up_pred + (bid_pips_up_error_avg * error_multiplier)\n",
    "            bid_pips_down_pred = bid_pips_down_pred + (bid_pips_down_error_avg * error_multiplier)\n",
    "\n",
    "            buy_signal = max([ask_pips_up_pred, ask_pips_down_pred, bid_pips_up_pred, bid_pips_down_pred]) == bid_pips_up_pred and bid_pips_up_pred >= pips_to_risk and bid_pips_down_pred < pips_to_risk\n",
    "            sell_signal = max([ask_pips_up_pred, ask_pips_down_pred, bid_pips_up_pred, bid_pips_down_pred]) == ask_pips_down_pred and ask_pips_down_pred >= pips_to_risk and ask_pips_up_pred < pips_to_risk\n",
    "\n",
    "            if invert:\n",
    "                buy_signal, sell_signal = sell_signal, buy_signal\n",
    "\n",
    "            if buy_signal:\n",
    "                open_price = float(curr_ao)\n",
    "                stop_loss = round(open_price - sl_pips, rounding)\n",
    "\n",
    "                if stop_loss < open_price:\n",
    "                    curr_pips_to_risk = open_price - stop_loss\n",
    "\n",
    "                    if spread <= curr_pips_to_risk * 0.1:\n",
    "                        n_units = get_n_units('buy', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n",
    "\n",
    "                        trade = {'start_index': i, 'open_price': open_price, 'trade_type': 'buy', 'stop_loss': stop_loss,\n",
    "                                'pips_risked': round(curr_pips_to_risk, 5), 'n_units': n_units, \n",
    "                                'original_units': n_units, 'start_date': curr_date, 'end_date': None, 'prev_profit_ratio': None}\n",
    "                        \n",
    "                        pips_risked.append(curr_pips_to_risk)\n",
    "                        n_buys += 1\n",
    "\n",
    "            elif sell_signal:\n",
    "                open_price = float(curr_bo)\n",
    "                stop_loss = round(open_price + sl_pips, rounding)\n",
    "\n",
    "                if stop_loss > open_price:\n",
    "                    curr_pips_to_risk = stop_loss - open_price\n",
    "\n",
    "                    if spread <= curr_pips_to_risk * 0.1:\n",
    "                        n_units = get_n_units('sell', stop_loss, curr_ao, curr_bo, curr_mid_open, currency_pair)\n",
    "\n",
    "                        trade = {'start_index': i, 'open_price': open_price, 'trade_type': 'sell', 'stop_loss': stop_loss,\n",
    "                                'pips_risked': round(curr_pips_to_risk, 5), 'n_units': n_units, \n",
    "                                'original_units': n_units, 'start_date': curr_date, 'end_date': None, 'prev_profit_ratio': None}\n",
    "                        \n",
    "                        pips_risked.append(curr_pips_to_risk)\n",
    "                        n_sells += 1\n",
    "\n",
    "        if trade is not None and trade['trade_type'] == 'buy' and curr_bid_low <= trade['stop_loss']:\n",
    "            trade_amount = (trade['stop_loss'] - trade['open_price']) * trade['n_units'] * value_per_pip\n",
    "            reward += trade_amount\n",
    "            day_fees += calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n",
    "\n",
    "            if trade_amount > 0:\n",
    "                win_amounts.append(trade_amount)\n",
    "\n",
    "            else:\n",
    "                loss_amounts.append(trade_amount)\n",
    "\n",
    "            n_wins += 1 if trade_amount > 0 else 0\n",
    "            n_losses += 1 if trade_amount < 0 else 0\n",
    "            curr_win_streak = 0 if trade_amount < 0 else curr_win_streak + 1\n",
    "            curr_loss_streak = 0 if trade_amount > 0 else curr_loss_streak + 1\n",
    "\n",
    "            if curr_win_streak > win_streak:\n",
    "                win_streak = curr_win_streak\n",
    "\n",
    "            if curr_loss_streak > loss_streak:\n",
    "                loss_streak = curr_loss_streak\n",
    "\n",
    "            trade = None\n",
    "\n",
    "        if trade is not None and trade['trade_type'] == 'buy' and curr_bid_close > trade['open_price']:\n",
    "            curr_profit_ratio = (curr_bid_close - trade['open_price']) / trade['pips_risked']\n",
    "\n",
    "            # Initial move\n",
    "            if curr_profit_ratio >= 1.0 and trade['prev_profit_ratio'] is None:\n",
    "                trade['stop_loss'] = trade['open_price']\n",
    "                trade['prev_profit_ratio'] = 0.0\n",
    "\n",
    "            # if curr_profit_ratio >= 1.5 and trade['prev_profit_ratio'] == 0.0:\n",
    "            #     trade['stop_loss'] = trade['open_price'] + (trade['pips_risked'] * 0.5)\n",
    "            #     trade['prev_profit_ratio'] = 0.5\n",
    "\n",
    "            # Subsequent moves\n",
    "            if curr_profit_ratio >= 2.0:\n",
    "                # while curr_profit_ratio >= trade['prev_profit_ratio'] + 1.5:\n",
    "                while curr_profit_ratio >= trade['prev_profit_ratio'] + 2.0:\n",
    "                    # trade['prev_profit_ratio'] += 0.5\n",
    "                    trade['prev_profit_ratio'] += 1.0\n",
    "                    trade['stop_loss'] = trade['open_price'] + (trade['pips_risked'] * trade['prev_profit_ratio'])\n",
    "\n",
    "        if trade is not None and trade['trade_type'] == 'sell' and curr_ask_high >= trade['stop_loss']:\n",
    "            trade_amount = (trade['open_price'] - trade['stop_loss']) * trade['n_units'] * value_per_pip\n",
    "            reward += trade_amount\n",
    "            day_fees += calculate_day_fees(trade['start_date'], curr_date, trade['n_units'])\n",
    "\n",
    "            if trade_amount > 0:\n",
    "                win_amounts.append(trade_amount)\n",
    "\n",
    "            else:\n",
    "                loss_amounts.append(trade_amount)\n",
    "\n",
    "            n_wins += 1 if trade_amount > 0 else 0\n",
    "            n_losses += 1 if trade_amount < 0 else 0\n",
    "            curr_win_streak = 0 if trade_amount < 0 else curr_win_streak + 1\n",
    "            curr_loss_streak = 0 if trade_amount > 0 else curr_loss_streak + 1\n",
    "\n",
    "            if curr_win_streak > win_streak:\n",
    "                win_streak = curr_win_streak\n",
    "\n",
    "            if curr_loss_streak > loss_streak:\n",
    "                loss_streak = curr_loss_streak\n",
    "\n",
    "            trade = None\n",
    "\n",
    "        if trade is not None and trade['trade_type'] == 'sell' and curr_ask_close < trade['open_price']:\n",
    "            curr_profit_ratio = (trade['open_price'] - curr_ask_close) / trade['pips_risked']\n",
    "\n",
    "            # Initial move\n",
    "            if curr_profit_ratio >= 1.0 and trade['prev_profit_ratio'] is None:\n",
    "                trade['stop_loss'] = trade['open_price']\n",
    "                trade['prev_profit_ratio'] = 0.0\n",
    "\n",
    "            # if curr_profit_ratio >= 1.5 and trade['prev_profit_ratio'] == 0.0:\n",
    "            #     trade['stop_loss'] = trade['open_price'] - (trade['pips_risked'] * 0.5)\n",
    "            #     trade['prev_profit_ratio'] = 0.5\n",
    "\n",
    "            # Subsequent moves\n",
    "            if curr_profit_ratio >= 2.0:\n",
    "                # while curr_profit_ratio >= trade['prev_profit_ratio'] + 1.5:\n",
    "                while curr_profit_ratio >= trade['prev_profit_ratio'] + 2.0:\n",
    "                    # trade['prev_profit_ratio'] += 0.5\n",
    "                    trade['prev_profit_ratio'] += 1.0\n",
    "                    trade['stop_loss'] = trade['open_price'] - (trade['pips_risked'] * trade['prev_profit_ratio'])\n",
    "\n",
    "    return reward, day_fees, n_buys, n_sells, n_wins, n_losses, win_streak, loss_streak, pips_risked, win_amounts, loss_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num runs: 1\n",
      "\n",
      "2249.9099999999717 -143.99424000000008 2105.9157599999717\n",
      "Num buys: 59\n",
      "Num sells: 56\n",
      "Num trades: 115\n",
      "Num wins: 34\n",
      "Num losses: 53\n",
      "Win streak: 10\n",
      "Loss streak: 8\n",
      "Avg pips risked: 0.002999999999999997\n",
      "Avg win amount: 144.11188235294043\n",
      "Min win amount: 49.99799999999819\n",
      "Max win amount: 399.9840000000004\n",
      "Avg loss amount: -32.714740740740794\n",
      "Min loss amount: -49.998000000001895\n",
      "Max loss amount: 0.0\n",
      "Remaining runs: 0\n",
      "Best reward so far: 2105.9157599999717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pips_to_risk_vals = [20, 30, 40, 50] \n",
    "# error_multipliers = [0.0, 0.5, 1.0, 1.5, 2.0]\n",
    "# adapt_errors_vals = [True, False]\n",
    "# error_array_lens = [5, 10, 20] \n",
    "# invert_vals = [True, False]\n",
    "\n",
    "# Best pips to risk: 30\n",
    "# Best adapt errors val: True\n",
    "# Best error array length: 10\n",
    "# Best best error multiplier: 1.5\n",
    "# Best best invert val: True\n",
    "\n",
    "pips_to_risk_vals = [30] \n",
    "error_multipliers = [1.5]\n",
    "adapt_errors_vals = [True]\n",
    "error_array_lens = [10] \n",
    "invert_vals = [True]\n",
    "\n",
    "all_combos = []\n",
    "\n",
    "for pips_to_risk in pips_to_risk_vals:\n",
    "    for error_multiplier in error_multipliers:\n",
    "        for invert in invert_vals:\n",
    "            for adapt_errors in adapt_errors_vals:\n",
    "                for err_array_len in error_array_lens:\n",
    "                    error_array_len = err_array_len if adapt_errors else 1\n",
    "                    all_combos.append((pips_to_risk, adapt_errors, error_array_len, error_multiplier, invert))\n",
    "\n",
    "                    if not adapt_errors:\n",
    "                        break\n",
    "\n",
    "best_pips_to_risk, best_adapt_errors, best_error_array_len, best_error_multiplier, best_invert_val = None, None, None, None, None\n",
    "top_n_results, best_rewards, best_reward, runs_finished = 10, [], -np.inf, 0\n",
    "\n",
    "percentage_to_try = 1.0\n",
    "n_runs = int(percentage_to_try * len(all_combos))\n",
    "combos_to_try = random.sample(all_combos, n_runs)\n",
    "print('Num runs: '+ str(len(combos_to_try)) + '\\n')\n",
    "\n",
    "for pips_to_risk, adapt_errors, error_array_len, error_multiplier, invert in combos_to_try:\n",
    "    reward, day_fees, n_buys, n_sells, n_wins, n_losses, win_streak, loss_streak, pips_risked, win_amounts, loss_amounts = run_simulation(pips_to_risk, adapt_errors, error_array_len, error_multiplier, invert)\n",
    "    runs_finished += 1\n",
    "\n",
    "    print(reward, day_fees, reward + day_fees)\n",
    "    print('Num buys: ' + str(n_buys))\n",
    "    print('Num sells: ' + str(n_sells))\n",
    "    print('Num trades: ' + str(n_buys + n_sells))\n",
    "    print('Num wins: ' + str(n_wins))\n",
    "    print('Num losses: ' + str(n_losses))\n",
    "    print('Win streak: ' + str(win_streak))\n",
    "    print('Loss streak: ' + str(loss_streak))\n",
    "    if len(pips_risked) > 0:\n",
    "        print('Avg pips risked: ' + str(np.array(pips_risked).mean()))\n",
    "    if len(win_amounts) > 0:\n",
    "        print('Avg win amount: ' + str(np.array(win_amounts).mean()))\n",
    "        print('Min win amount: ' +  str(min(win_amounts)))\n",
    "        print('Max win amount: ' + str(max(win_amounts)))\n",
    "    if len(loss_amounts) > 0:\n",
    "        print('Avg loss amount: ' + str(np.array(loss_amounts).mean()))\n",
    "        print('Min loss amount: ' +  str(min(loss_amounts)))\n",
    "        print('Max loss amount: ' + str(max(loss_amounts)))\n",
    "\n",
    "    print('Remaining runs: ' + str(n_runs - runs_finished))\n",
    "\n",
    "    total_profit = reward + day_fees\n",
    "\n",
    "    min_item = min(best_rewards, key=lambda entry: entry['reward']) if len(best_rewards) >= top_n_results else None\n",
    "\n",
    "    if min_item is None or total_profit > min_item['reward']:\n",
    "        if min_item is not None:\n",
    "            best_rewards.remove(min_item)\n",
    "            \n",
    "        best_rewards.append({'reward': int(total_profit), 'pips_to_risk': pips_to_risk, 'adapt_errors': adapt_errors, 'error_array_len': error_array_len, 'error_multiplier': error_multiplier, 'invert': invert})\n",
    "\n",
    "    if total_profit > best_reward:\n",
    "        best_reward = total_profit\n",
    "        best_pips_to_risk, best_adapt_errors, best_error_array_len, best_error_multiplier, best_invert_val = pips_to_risk, adapt_errors, error_array_len, error_multiplier, invert\n",
    " \n",
    "    print('Best reward so far: ' + str(best_reward))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ FINAL RESULTS ------------\n",
      "Best reward: 2105.9157599999717\n",
      "Best pips to risk: 30\n",
      "Best adapt errors val: True\n",
      "Best error array length: 10\n",
      "Best best error multiplier: 1.5\n",
      "Best best invert val: True\n",
      "-----------------------\n",
      "Top results:\n",
      "{'reward': 2105, 'pips_to_risk': 30, 'adapt_errors': True, 'error_array_len': 10, 'error_multiplier': 1.5, 'invert': True}\n"
     ]
    }
   ],
   "source": [
    "print('------------ FINAL RESULTS ------------')\n",
    "print('Best reward: ' + str(best_reward))\n",
    "print('Best pips to risk: ' + str(best_pips_to_risk))\n",
    "print('Best adapt errors val: ' + str(best_adapt_errors))\n",
    "print('Best error array length: ' + str(best_error_array_len))\n",
    "print('Best best error multiplier: ' + str(best_error_multiplier))\n",
    "print('Best best invert val: ' + str(best_invert_val))\n",
    "print('-----------------------')\n",
    "print('Top results:')\n",
    "\n",
    "for entry in best_rewards:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
